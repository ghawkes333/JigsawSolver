{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Jigsaw solver\n"
      ],
      "metadata": {
        "id": "a1TZOBhM0pjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This method predicts the position and rotation of individual tiles"
      ],
      "metadata": {
        "id": "ynWaFV649NOw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLA-NhdviTpN"
      },
      "source": [
        "# Generate permutations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jigsaw_puzzle_size = 4\n",
        "num_permuts_saved = 10000\n",
        "images_dir = \"extraimages\""
      ],
      "metadata": {
        "id": "wjgwzfjuoZD5"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4vvH8PQ3x1u"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "8Khk-czxiTpP"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy.spatial.distance import hamming\n",
        "\n",
        "# Build list of permutations such that each position is equally likely for each piece\n",
        "piece_indicies = [i for i in range(jigsaw_puzzle_size ** 2)]\n",
        "num_permuts = num_permuts_saved\n",
        "permuts = np.zeros((num_permuts_saved, jigsaw_puzzle_size ** 2), dtype=np.long)\n",
        "permuts_hash = {}\n",
        "count = 0\n",
        "while count < num_permuts:\n",
        "  x = np.array(np.random.permutation(piece_indicies))\n",
        "  y = np.array(np.random.permutation(piece_indicies), dtype=np.int32)\n",
        "  hd = hamming(x, y) > 0.9\n",
        "  x_hashcode = np.sum([10**(-1 * i) * x[i] for i in range(len(x))])\n",
        "  y_hashcode = np.sum([10**(-1 * i) * y[i] for i in range(len(y))])\n",
        "  if hd > 0.9 and (not x_hashcode in permuts_hash) and (not y_hashcode in permuts_hash):\n",
        "    permuts[count] = x\n",
        "    permuts[count + 1] = y\n",
        "    permuts_hash[x_hashcode] = True\n",
        "    permuts_hash[y_hashcode] = True\n",
        "    count = count + 2\n",
        "\n",
        "\n",
        "\n",
        "# Build the array for selected permutation indices above\n",
        "np.save('selected_permuts.npy', permuts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "xQj55rQfiTpQ"
      },
      "outputs": [],
      "source": [
        "from ctypes import ArgumentError\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "\n",
        "def_data_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "hflip_data_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=1.0),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "darkness_jitter_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ColorJitter(brightness=[0.5, 0.9]),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "lightness_jitter_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ColorJitter(brightness=[1.1, 1.5]),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "rotations_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "all_in_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "def crop_from_center(pil_image, new_h, new_w):\n",
        "\n",
        "    width, height = pil_image.size  # Get dimensions\n",
        "\n",
        "    left = (width - new_w) / 2\n",
        "    top = (height - new_h) / 2\n",
        "    right = (width + new_w) / 2\n",
        "    bottom = (height + new_h) / 2\n",
        "\n",
        "    # Crop the center of the image\n",
        "    pil_image = pil_image.crop((left, top, right, bottom))\n",
        "\n",
        "    return pil_image\n",
        "\n",
        "\n",
        "def get_nine_crops(pil_image):\n",
        "    \"\"\"\n",
        "    Get nine crops for a square pillow image. That is height and width of the image should be same.\n",
        "    :param pil_image: pillow image\n",
        "    :return: List of pillow images. The nine crops\n",
        "    \"\"\"\n",
        "    w, h = pil_image.size\n",
        "    diff = int(w/3)\n",
        "\n",
        "    r_vals = [0, diff, 2 * diff]\n",
        "    c_vals = [0, diff, 2 * diff]\n",
        "\n",
        "    list_patches = []\n",
        "\n",
        "    for r in r_vals:\n",
        "        for c in c_vals:\n",
        "\n",
        "            left = c\n",
        "            top = r\n",
        "            right = c + diff\n",
        "            bottom = r + diff\n",
        "\n",
        "            patch = pil_image.crop((left, top, right, bottom))\n",
        "            list_patches.append(patch)\n",
        "\n",
        "    return list_patches\n",
        "\n",
        "\n",
        "def get_several_crops(pil_image, jig_size):\n",
        "    \"\"\"\n",
        "    Get several crops for a square pillow image. That is height and width of the image should be same.\n",
        "    :param pil_image: pillow image\n",
        "    :param jig_size: number of rows and columns for jigsaw\n",
        "    :return: List of pillow images. The nine crops\n",
        "    \"\"\"\n",
        "    w, h = pil_image.size\n",
        "    diff = int(w/jig_size)\n",
        "\n",
        "    r_vals = [i * diff for i in range(jig_size)]\n",
        "    c_vals = [i * diff for i in range(jig_size)]\n",
        "\n",
        "    list_patches = []\n",
        "\n",
        "    for r in r_vals:\n",
        "        for c in c_vals:\n",
        "\n",
        "            left = c\n",
        "            top = r\n",
        "            right = c + diff\n",
        "            bottom = r + diff\n",
        "\n",
        "            patch = pil_image.crop((left, top, right, bottom))\n",
        "            list_patches.append(patch)\n",
        "\n",
        "    return list_patches\n",
        "\n",
        "\n",
        "def split_train_into_train_val(train_file_ids, train_file_paths, train_labels, test_size=0.1):\n",
        "    \"\"\"\n",
        "    Split train_file_paths and train_labels to train_file_paths, val_file_paths and\n",
        "    train_labels, val_labels\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a mapping between image_id and file_path\n",
        "    image_id_name_map = dict(zip(train_file_ids, train_file_paths))\n",
        "\n",
        "    # Get validation files and validation labels separate\n",
        "    train_file_ids, val_file_ids, train_labels, val_labels = train_test_split(\n",
        "        train_file_ids, train_labels, test_size=test_size, random_state=5, shuffle=True\n",
        "    )\n",
        "    train_file_paths = [image_id_name_map[image_id] for image_id in train_file_ids]\n",
        "    val_file_paths = [image_id_name_map[image_id] for image_id in val_file_ids]\n",
        "\n",
        "    print (\"Length of train files list\", len(train_file_paths))\n",
        "    print (\"Length of train labels\", len(train_labels))\n",
        "    print (\"Length of val files list\", len(val_file_paths))\n",
        "    print (\"Length of val labels\", len(val_labels))\n",
        "\n",
        "    return train_file_ids, val_file_ids, train_file_paths, val_file_paths, train_labels, val_labels\n",
        "\n",
        "def get_paths():\n",
        "    data_dir = images_dir\n",
        "    file_paths_to_return = []\n",
        "\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(\".jpg\"):\n",
        "                file_paths_to_return.append(data_dir+'/'+file)\n",
        "\n",
        "    if len(file_paths_to_return) == 0:\n",
        "      raise ArgumentError(\"Data was not found. Ensure that a data folder is present\")\n",
        "\n",
        "    return file_paths_to_return\n",
        "\n",
        "def get_train_test_file_paths_n_labels():\n",
        "    \"\"\"\n",
        "    Get array train_file_paths, train_labels, test_file_paths and test_labels\n",
        "    \"\"\"\n",
        "\n",
        "    # Data loading and data generators set up\n",
        "    #par_data_dir = 'train'\n",
        "    images_data_dir = 'train'\n",
        "    train_test_split_file = 'train_test_split.txt'\n",
        "    images_file = 'images.txt'\n",
        "    labels_file = 'image_class_labels.txt'\n",
        "\n",
        "    # Read the images_file which stores image-id and image-name mapping\n",
        "    image_file_id_df = pd.read_csv(images_file, sep=' ', header=None)\n",
        "    image_file_id_mat = image_file_id_df.values\n",
        "    image_id_name_map = dict(zip(image_file_id_mat[:, 0], image_file_id_mat[:, 1]))\n",
        "\n",
        "    # Read the train_test_split file which stores image-id and train-test split mapping\n",
        "    image_id_train_test_split_df = pd.read_csv(train_test_split_file, sep=' ', header=None)\n",
        "    image_id_train_test_split_mat = image_id_train_test_split_df.values\n",
        "    image_id_train_test_split_map = dict(zip(image_id_train_test_split_mat[:, 0],\n",
        "                                             image_id_train_test_split_mat[:, 1]))\n",
        "\n",
        "    # Read the image class labels file\n",
        "    image_id_label_df = pd.read_csv(labels_file, sep=' ', header=None)\n",
        "    image_id_label_mat = image_id_label_df.values\n",
        "    image_id_label_map = dict(zip(image_id_label_mat[:, 0], image_id_label_mat[:, 1]))\n",
        "\n",
        "    # Put together train_files train_labels test_files and test_labels lists\n",
        "    train_image_ids, test_image_ids = [], []\n",
        "    train_file_paths, test_file_paths = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    for file_id in image_id_name_map.keys():\n",
        "        file_name = image_id_name_map[file_id]\n",
        "        is_train = image_id_train_test_split_map[file_id]\n",
        "        label = image_id_label_map[file_id] - 1  # To ensure labels start from 0\n",
        "\n",
        "        if is_train:\n",
        "            train_image_ids.append(file_id)\n",
        "            train_file_paths.append(os.path.join(images_data_dir, file_name))\n",
        "            train_labels.append(label)\n",
        "        else:\n",
        "            test_image_ids.append(file_id)\n",
        "            test_file_paths.append(os.path.join(images_data_dir, file_name))\n",
        "            test_labels.append(label)\n",
        "\n",
        "    print (\"Length of train files list\", len(train_file_paths))\n",
        "    print (\"Length of train labels list\", len(train_labels))\n",
        "    print (\"Length of test files list\", len(test_file_paths))\n",
        "    print (\"Length of test labels list\", len(test_labels))\n",
        "\n",
        "    return train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpAZGXKmiTpR"
      },
      "source": [
        "# Generate Jigsaw from permutations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "sm_sOs8piTpR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms.functional import rotate\n",
        "import torch.nn.functional\n",
        "\n",
        "\n",
        "class GetDataset(Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        'Initialization'\n",
        "        self.imgs = [(img_path, label) for img_path, label in zip(file_paths, labels)]\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "\n",
        "        # Select sample\n",
        "        file_path = self.file_paths[index]\n",
        "        label = self.labels[index]\n",
        "        pil_image = Image.open(file_path)\n",
        "\n",
        "        # Check if image has only single channel. If True, then swap with 0th image\n",
        "        # Assumption 0th image has got 3 number of channels\n",
        "        if len(pil_image.getbands()) != 3:\n",
        "            file_path = self.file_paths[0]\n",
        "            label = self.labels[0]\n",
        "            pil_image = Image.open(file_path)\n",
        "\n",
        "        # Convert image to torch tensor\n",
        "        tr_image = self.transform(pil_image)\n",
        "\n",
        "        return tr_image, label\n",
        "\n",
        "\n",
        "class GetJigsawPuzzleDataset(Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, file_paths, avail_permuts_file_path, range_permut_indices=None, jig_size=4):\n",
        "        'Initialization'\n",
        "        self.file_paths = file_paths\n",
        "        self.permuts_avail = np.load(avail_permuts_file_path)\n",
        "        self.jig_size = jig_size\n",
        "        if range_permut_indices != None:\n",
        "          self.range_permut_indices = range_permut_indices\n",
        "        else:\n",
        "          self.range_permut_indices = (0, len(self.permuts_avail) - 1)\n",
        "\n",
        "\n",
        "        self.data_transform = transforms.Compose([\n",
        "            # transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        self.size = len(self.file_paths) * (self.jig_size ** 2) * 4\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        num_tiles = self.jig_size ** 2\n",
        "        num_rotations = 4\n",
        "        file_index = index // (num_tiles * num_rotations)\n",
        "        rest = index % (num_tiles * num_rotations)\n",
        "        rotation_index = rest // num_tiles\n",
        "        patch_index = rest % num_tiles\n",
        "\n",
        "        # Select sample\n",
        "        file_path = self.file_paths[file_index]\n",
        "        pil_image = Image.open(file_path)\n",
        "\n",
        "        # Check if image has only single channel. If True, then swap with 0th image\n",
        "        # Assumption 0th image has got 3 number of channels\n",
        "        if len(pil_image.getbands()) != 3:\n",
        "            file_path = self.file_paths[0]\n",
        "            pil_image = Image.open(file_path)\n",
        "\n",
        "        # Convert image to torch tensor\n",
        "        pil_image = pil_image.resize((256, 256))\n",
        "        new_size = 256 - (256 % self.jig_size) # Ensure that the number of pixels fits the number of jigsaw pieces\n",
        "        pil_image = crop_from_center(pil_image, new_size, new_size)\n",
        "        solution_tensor = self.data_transform(pil_image)\n",
        "\n",
        "        # Split image into tiles (patches)\n",
        "        crops = get_several_crops(pil_image, self.jig_size)\n",
        "\n",
        "        # Generate a rotation sequence\n",
        "        rot_config = np.random.randint(4, size=self.jig_size ** 2)\n",
        "\n",
        "        # Find a single patch in the image and transform\n",
        "        patch_im = crops[patch_index]\n",
        "        patch_tensor = self.data_transform(patch_im)\n",
        "        patch_tensor = rotate(patch_tensor, 90 * rotation_index)\n",
        "\n",
        "        pad_size_right = solution_tensor.shape[2] - patch_tensor.shape[2]\n",
        "        pad_size_bottom = solution_tensor.shape[1] - patch_tensor.shape[1]\n",
        "        patch_tensor_extended = torch.nn.functional.pad(patch_tensor, (0, pad_size_right, 0, pad_size_bottom))\n",
        "\n",
        "        # Concanate selected patch along channel to form a 6 channel image\n",
        "        original_plus_patch = torch.cat((solution_tensor, patch_tensor_extended), dim=0)\n",
        "\n",
        "\n",
        "        return original_plus_patch, patch_index, rotation_index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itXKzIqhiTpT"
      },
      "source": [
        "# Defining Resnet model\n",
        "Credit: https://github.com/aniket03/self_supervised_bird_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "BEYNDi47iTpT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, jigsaw_size=3, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None, siamese_deg=9, train_contrastive=False):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.siamese_deg = siamese_deg\n",
        "        self.train_contrastive = train_contrastive\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
        "\n",
        "        self.pos_head = nn.Linear(2048 * block.expansion, jigsaw_size ** 2)\n",
        "        self.rot_head = nn.Linear(2048 * block.expansion, 4)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def get_feature_vectors(self, input_batch):\n",
        "        # Each input_batch would be of shape (batch_size, color_channels, h, w)\n",
        "        x = self.conv1(input_batch)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input_batch):\n",
        "        B, N, C, H, W = input_batch.shape\n",
        "        patch_features = []\n",
        "\n",
        "        for i in range(N):\n",
        "            feat = self.get_feature_vectors(input_batch[:, i, :, :, :])\n",
        "            patch_features.append(feat)\n",
        "        patch_features = torch.stack(patch_features, dim=1)  # [B, 9, feat_dim]\n",
        "\n",
        "        # Predict position and rotation for each patch\n",
        "        pos_logits = self.pos_head(patch_features)  # [B, 9, 9]\n",
        "        rot_logits = self.rot_head(patch_features)  # [B, 9, 4]\n",
        "\n",
        "        return pos_logits, rot_logits\n",
        "\n",
        "\n",
        "\n",
        "def _resnet(block, layers, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(**kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    \"\"\"\n",
        "    return _resnet(BasicBlock, [2, 2, 2, 2], **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and test"
      ],
      "metadata": {
        "id": "o20sbcY7fdYw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "O02gxDG-iTpU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "\n",
        "def get_count_correct_preds(network_output, target):\n",
        "\n",
        "    output = network_output\n",
        "    pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "    pred.data = pred.data.view_as(target.data)\n",
        "    correct = target.eq(pred).sum().item()\n",
        "\n",
        "    return correct\n",
        "\n",
        "\n",
        "class ModelTrainTest():\n",
        "\n",
        "    def __init__(self, network, device, model_file_path, threshold=1e-4):\n",
        "        super(ModelTrainTest, self).__init__()\n",
        "        self.network = network\n",
        "        self.device = device\n",
        "        self.model_file_path = model_file_path\n",
        "        self.threshold = threshold\n",
        "        self.train_loss = 1e9\n",
        "        self.val_loss = 1e9\n",
        "\n",
        "    def train(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader):\n",
        "        self.network.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        cnt_batches = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
        "            data, target = Variable(data).to(self.device), Variable(target).to(self.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = self.network(data)\n",
        "\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "\n",
        "            clip_grad_norm_(self.network.parameters(), params_max_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            correct += get_count_correct_preds(output, target)\n",
        "            train_loss += loss.item()\n",
        "            cnt_batches += 1\n",
        "\n",
        "            del data, target, output\n",
        "\n",
        "        train_loss /= cnt_batches\n",
        "        val_loss, val_acc = self.test(epoch, val_data_loader)\n",
        "\n",
        "        if val_loss < self.val_loss - self.threshold:\n",
        "            self.val_loss = val_loss\n",
        "            torch.save(self.network.state_dict(), self.model_file_path)\n",
        "\n",
        "        train_acc = correct / len(train_data_loader.dataset)\n",
        "\n",
        "        print('\\nAfter epoch {} - Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, train_loss, correct, len(train_data_loader.dataset),\n",
        "            100. * correct / len(train_data_loader.dataset)))\n",
        "\n",
        "        return train_loss, train_acc, val_loss, val_acc\n",
        "\n",
        "\n",
        "\n",
        "    def test(self, epoch, test_data_loader):\n",
        "        self.network.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(test_data_loader):\n",
        "            data, target = Variable(data, volatile=True).to(self.device), Variable(target).to(self.device)\n",
        "            output = self.network(data)\n",
        "            test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
        "\n",
        "            correct += get_count_correct_preds(output, target)\n",
        "\n",
        "            del data, target, output\n",
        "\n",
        "        test_loss /= len(test_data_loader.dataset)\n",
        "        test_acc = correct / len(test_data_loader.dataset)\n",
        "        print('\\nAfter epoch {} - Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, test_loss, correct, len(test_data_loader.dataset),\n",
        "            100. * correct / len(test_data_loader.dataset)))\n",
        "\n",
        "        return  test_loss, test_acc\n",
        "\n",
        "\n",
        "class JigsawModelTrainTest():\n",
        "\n",
        "    def __init__(self, network, device, model_file_path, threshold=1e-4):\n",
        "        super(JigsawModelTrainTest, self).__init__()\n",
        "        self.network = network\n",
        "        self.device = device\n",
        "        self.model_file_path = model_file_path\n",
        "        self.threshold = threshold\n",
        "        self.train_loss = 1e9\n",
        "        self.val_loss = 1e9\n",
        "\n",
        "    def train(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader):\n",
        "        self.network.train()\n",
        "        train_loss = 0\n",
        "        cnt_batches = 0\n",
        "        pos_correct = 0\n",
        "        rot_correct = 0\n",
        "        total_pred_pos = 0\n",
        "        total_pred_rot = 0\n",
        "        batch_size = 0\n",
        "\n",
        "        for batch_idx, (data, pos_vector, rot_vector) in enumerate(train_data_loader):\n",
        "            data, pos_vector, rot_vector = Variable(data).to(self.device), Variable(pos_vector).to(self.device), Variable(rot_vector).to(self.device)\n",
        "            batch_size = data.shape[0]\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pos_log, rot_log = self.network(data)\n",
        "\n",
        "            pos_pred = pos_log.argmax(dim=1)  # Shape (B)\n",
        "            rot_pred = rot_log.argmax(dim=1)\n",
        "\n",
        "\n",
        "            loss_pos = F.cross_entropy(pos_log, pos_vector) # Shape (B, 9)\n",
        "            loss_rot = F.cross_entropy(rot_log, rot_vector)\n",
        "            loss = loss_pos + loss_rot\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            pos_correct += pos_pred.eq(pos_vector).sum() # Single number\n",
        "            rot_correct += rot_pred.eq(rot_vector).sum() # Single number\n",
        "            total_pred_pos += pos_pred.shape[0]\n",
        "            total_pred_rot += rot_pred.shape[0]\n",
        "            cnt_batches += 1\n",
        "\n",
        "            del data, pos_vector, rot_vector, pos_log, rot_log\n",
        "\n",
        "        train_loss /= cnt_batches\n",
        "        val_loss, val_acc = self.test(epoch, val_data_loader)\n",
        "\n",
        "        if val_loss < self.val_loss - self.threshold:\n",
        "            self.val_loss = val_loss\n",
        "            torch.save(self.network.state_dict(), self.model_file_path)\n",
        "\n",
        "        correct = (pos_correct + rot_correct)\n",
        "        total_pred = total_pred_pos\n",
        "\n",
        "        train_acc = correct / (total_pred_pos + total_pred_rot)\n",
        "\n",
        "        print('\\nAfter epoch {} - Train set: Number of batches: {}, Batch size: {}, Average loss: {:.4f}, Train accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, cnt_batches, batch_size, train_loss, correct, (total_pred_pos + total_pred_rot),\n",
        "            100. * train_acc))\n",
        "        print(f'Position accuracy: {pos_correct}/{total_pred_pos}, Rotation accuracy: {rot_correct}/{total_pred_rot}')\n",
        "\n",
        "\n",
        "\n",
        "        return train_loss, train_acc, val_loss, val_acc\n",
        "\n",
        "    def test(self, epoch, test_data_loader):\n",
        "        self.network.eval()\n",
        "        test_loss = 0\n",
        "        pos_correct = 0\n",
        "        rot_correct = 0\n",
        "        total_pred_pos = 0\n",
        "        total_pred_rot = 0\n",
        "        batch_size = 0\n",
        "        cnt_batches = 0\n",
        "\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, (data, pos_vector, rot_vector) in enumerate(test_data_loader):\n",
        "            data, pos_vector, rot_vector = Variable(data).to(self.device), Variable(pos_vector).to(self.device), Variable(rot_vector).to(self.device)\n",
        "            pos_log, rot_log = self.network(data)\n",
        "            batch_size = data.shape[0]\n",
        "\n",
        "            pos_log, rot_log = self.network(data)\n",
        "            pos_pred = pos_log.argmax(dim=1)\n",
        "            rot_pred = rot_log.argmax(dim=1)\n",
        "\n",
        "            loss_pos = F.cross_entropy(pos_log, pos_vector).item()\n",
        "            loss_rot = F.cross_entropy(rot_log, rot_vector).item()\n",
        "            test_loss += loss_pos + loss_rot\n",
        "\n",
        "\n",
        "            pos_correct += pos_pred.eq(pos_vector).sum() # Single number\n",
        "            rot_correct += rot_pred.eq(rot_vector).sum() # Single number\n",
        "\n",
        "\n",
        "            total_pred_pos += pos_pred.shape[0]\n",
        "            total_pred_rot += rot_pred.shape[0]\n",
        "            cnt_batches += 1\n",
        "\n",
        "\n",
        "            del data, pos_vector, rot_vector, pos_log, rot_log\n",
        "\n",
        "        correct = (pos_correct + rot_correct)\n",
        "        total_pred = total_pred_pos * cnt_batches\n",
        "\n",
        "        test_loss /= cnt_batches\n",
        "        test_acc = correct /  (total_pred_pos + total_pred_rot)\n",
        "        print('\\nAfter epoch {} - Test set: Number of batches: {}, Batch size: {}, Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, len(test_data_loader), batch_size, test_loss, correct, (total_pred_pos + total_pred_rot),\n",
        "            100. * test_acc))\n",
        "\n",
        "        return  test_loss, test_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use pretrained model"
      ],
      "metadata": {
        "id": "q4LcSIu5Q6p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "class PretrainedResNet(nn.Module):\n",
        "    def __init__(self, num_positions=16):\n",
        "        super().__init__()\n",
        "        # Use 6 input channels instead of 3\n",
        "        self.backbone = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Set requires_grad to False\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        old_conv = self.backbone.conv1\n",
        "\n",
        "        self.backbone.conv1 = nn.Conv2d(\n",
        "            in_channels=6,\n",
        "            out_channels=old_conv.out_channels,\n",
        "            kernel_size=old_conv.kernel_size,\n",
        "            stride=old_conv.stride,\n",
        "            padding=old_conv.padding,\n",
        "            bias=old_conv.bias is not None\n",
        "        )\n",
        "\n",
        "        # Copy pretrained 3-channel weights into first 3 channels\n",
        "        with torch.no_grad():\n",
        "            self.backbone.conv1.weight[:, :3] = old_conv.weight\n",
        "\n",
        "\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        self.pos_head = nn.Linear(512, num_positions)  # classification\n",
        "        self.rot_head = nn.Linear(512, 4)              # 0째, 90째, 180째, 270째\n",
        "\n",
        "        self.pos_head.requires_grad = True\n",
        "        self.rot_head.requires_grad = True\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x)        # [B, 512]\n",
        "        pos = self.pos_head(f)      # [B, 16]\n",
        "        rot = self.rot_head(f)      # [B, 4]\n",
        "        return pos, rot"
      ],
      "metadata": {
        "id": "LIrdktKTQ57u"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv25ckxKiTpV"
      },
      "source": [
        "# Jigsaw as pretext task training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "qB6edlUIiTpV",
        "outputId": "4f27b988-5bdf-4e9f-8c74-cc28e69b39ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaders done\n",
            "torch.Size([4, 6, 256, 256])\n",
            "torch.Size([4])\n",
            "Model ready\n",
            "Started training\n",
            "Epoch no 0 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 0 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.8410, Accuracy: 3349/19584 (17%)\n",
            "\n",
            "\n",
            "After epoch 0 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 4.5232, Train accuracy: 30227/161024 (19%)\n",
            "\n",
            "Position accuracy: 8535/80512, Rotation accuracy: 21692/80512\n",
            "Train loss 4.523180061190231 \n",
            " Val loss 4.840976008402756 \n",
            " Train Acc 0.18771736323833466 \n",
            " Val Acc 0.1710069477558136\n",
            "Epoch no 1 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 1 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.8303, Accuracy: 3791/19584 (19%)\n",
            "\n",
            "\n",
            "After epoch 1 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 4.3490, Train accuracy: 34982/161024 (22%)\n",
            "\n",
            "Position accuracy: 11546/80512, Rotation accuracy: 23436/80512\n",
            "Train loss 4.349025079693249 \n",
            " Val loss 4.830332548047106 \n",
            " Train Acc 0.2172471135854721 \n",
            " Val Acc 0.1935763955116272\n",
            "Epoch no 2 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 2 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.9718, Accuracy: 3859/19584 (20%)\n",
            "\n",
            "\n",
            "After epoch 2 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 4.2840, Train accuracy: 36894/161024 (23%)\n",
            "\n",
            "Position accuracy: 12894/80512, Rotation accuracy: 24000/80512\n",
            "Train loss 4.283959111397189 \n",
            " Val loss 4.971829720024092 \n",
            " Train Acc 0.2291211187839508 \n",
            " Val Acc 0.1970486044883728\n",
            "Epoch no 3 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 3 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 5.1858, Accuracy: 3927/19584 (20%)\n",
            "\n",
            "\n",
            "After epoch 3 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 4.2244, Train accuracy: 38674/161024 (24%)\n",
            "\n",
            "Position accuracy: 13662/80512, Rotation accuracy: 25012/80512\n",
            "Train loss 4.224417703057416 \n",
            " Val loss 5.1858148283562535 \n",
            " Train Acc 0.24017538130283356 \n",
            " Val Acc 0.2005208283662796\n",
            "Epoch no 4 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 4 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.9440, Accuracy: 3570/19584 (18%)\n",
            "\n",
            "\n",
            "After epoch 4 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 4.1812, Train accuracy: 39733/161024 (25%)\n",
            "\n",
            "Position accuracy: 14428/80512, Rotation accuracy: 25305/80512\n",
            "Train loss 4.181244490754055 \n",
            " Val loss 4.9440071131376655 \n",
            " Train Acc 0.2467520385980606 \n",
            " Val Acc 0.1822916716337204\n",
            "Epoch no 5 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 5 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.4794, Accuracy: 4165/19584 (21%)\n",
            "\n",
            "\n",
            "After epoch 5 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 3.6537, Train accuracy: 48706/161024 (30%)\n",
            "\n",
            "Position accuracy: 19230/80512, Rotation accuracy: 29476/80512\n",
            "Train loss 3.653689035953323 \n",
            " Val loss 4.4794431603909315 \n",
            " Train Acc 0.3024766445159912 \n",
            " Val Acc 0.2126736044883728\n",
            "Epoch no 6 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 6 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.5270, Accuracy: 3978/19584 (20%)\n",
            "\n",
            "\n",
            "After epoch 6 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 3.6136, Train accuracy: 50196/161024 (31%)\n",
            "\n",
            "Position accuracy: 20080/80512, Rotation accuracy: 30116/80512\n",
            "Train loss 3.61358593371719 \n",
            " Val loss 4.526965017193088 \n",
            " Train Acc 0.31172993779182434 \n",
            " Val Acc 0.203125\n",
            "Epoch no 7 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 7 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.4782, Accuracy: 3842/19584 (20%)\n",
            "\n",
            "\n",
            "After epoch 7 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 3.5986, Train accuracy: 50650/161024 (31%)\n",
            "\n",
            "Position accuracy: 20312/80512, Rotation accuracy: 30338/80512\n",
            "Train loss 3.5986414709097345 \n",
            " Val loss 4.478248905901816 \n",
            " Train Acc 0.31454938650131226 \n",
            " Val Acc 0.1961805522441864\n",
            "Epoch no 8 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 8 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.5290, Accuracy: 3638/19584 (19%)\n",
            "\n",
            "\n",
            "After epoch 8 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 3.5877, Train accuracy: 51266/161024 (32%)\n",
            "\n",
            "Position accuracy: 20625/80512, Rotation accuracy: 30641/80512\n",
            "Train loss 3.5877483542564375 \n",
            " Val loss 4.528988735275526 \n",
            " Train Acc 0.318374902009964 \n",
            " Val Acc 0.1857638955116272\n",
            "Epoch no 9 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 9 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.5200, Accuracy: 3961/19584 (20%)\n",
            "\n",
            "\n",
            "After epoch 9 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 3.5855, Train accuracy: 51058/161024 (32%)\n",
            "\n",
            "Position accuracy: 20566/80512, Rotation accuracy: 30492/80512\n",
            "Train loss 3.5854689128850903 \n",
            " Val loss 4.520017434398528 \n",
            " Train Acc 0.3170831799507141 \n",
            " Val Acc 0.2022569477558136\n",
            "Epoch no 10 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 10 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.5093, Accuracy: 3944/19584 (20%)\n",
            "\n",
            "\n",
            "After epoch 10 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 3.5721, Train accuracy: 51479/161024 (32%)\n",
            "\n",
            "Position accuracy: 20806/80512, Rotation accuracy: 30673/80512\n",
            "Train loss 3.5721268213408837 \n",
            " Val loss 4.509262745993005 \n",
            " Train Acc 0.31969767808914185 \n",
            " Val Acc 0.2013888955116272\n",
            "Epoch no 11 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 1e-05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 11 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.5606, Accuracy: 3706/19584 (19%)\n",
            "\n",
            "\n",
            "After epoch 11 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 3.5182, Train accuracy: 54157/161024 (34%)\n",
            "\n",
            "Position accuracy: 22152/80512, Rotation accuracy: 32005/80512\n",
            "Train loss 3.518206420823908 \n",
            " Val loss 4.56061352100345 \n",
            " Train Acc 0.33632874488830566 \n",
            " Val Acc 0.1892361044883728\n",
            "Epoch no 12 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 1e-05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 12 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.4990, Accuracy: 3638/19584 (19%)\n",
            "\n",
            "\n",
            "After epoch 12 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 3.5182, Train accuracy: 54123/161024 (34%)\n",
            "\n",
            "Position accuracy: 21987/80512, Rotation accuracy: 32136/80512\n",
            "Train loss 3.5181517986216493 \n",
            " Val loss 4.498953574355326 \n",
            " Train Acc 0.33611759543418884 \n",
            " Val Acc 0.1857638955116272\n",
            "Epoch no 13 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 1e-05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n",
            "\n",
            "After epoch 13 - Test set: Number of batches: 2448, Batch size: 4, Average loss: 4.5422, Accuracy: 3740/19584 (19%)\n",
            "\n",
            "\n",
            "After epoch 13 - Train set: Number of batches: 20128, Batch size: 4, Average loss: 3.5163, Train accuracy: 54044/161024 (34%)\n",
            "\n",
            "Position accuracy: 21907/80512, Rotation accuracy: 32137/80512\n",
            "Train loss 3.5163086380969455 \n",
            " Val loss 4.5421559914362195 \n",
            " Train Acc 0.3356269896030426 \n",
            " Val Acc 0.1909722238779068\n",
            "Epoch no 14 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 1e-05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dab880b0380>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7dabb5685280>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3676634120.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         train_loss, train_acc, val_loss, val_acc = model_train_test_obj.train(\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_max_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-36004698.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mloss_rot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrot_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_pos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_rot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#for jigsaw ssl task\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import ConcatDataset\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    Cexperiment_name = 'e1_js'\n",
        "    Cdataset_config = 'js_d1'\n",
        "    Cweight_decay = 5e-4\n",
        "    Clr = 1e-3\n",
        "    Cepochs = 20\n",
        "    Cbatch_size = 4 # 4 to overfit single image\n",
        "\n",
        "    # Data files which will get referred\n",
        "    permuts_file_path = 'selected_permuts.npy'\n",
        "\n",
        "    # Set device to use to gpu if available and declare model_file_path\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #par_weights_dir = 'weights/'\n",
        "    model_file_path = 'resnet_jigsaw_solver_{}_trained.pt'.format(Cexperiment_name)\n",
        "\n",
        "    all_file_paths = get_paths()\n",
        "\n",
        "    # Get validation files separate\n",
        "    train_file_paths, val_file_paths = train_test_split(all_file_paths, test_size=0.1, shuffle=True, random_state=3)\n",
        "\n",
        "    # Compute channel means\n",
        "    channel_means = np.array([124.09, 127.67, 110.50]) / 256.0\n",
        "\n",
        "    # Define data loaders\n",
        "    batch_size = Cbatch_size\n",
        "    jig_size = 4\n",
        "\n",
        "    if Cdataset_config == 'js_d1':\n",
        "        n = jig_size**2 + 1\n",
        "        train_data_loader = DataLoader(\n",
        "            ConcatDataset(\n",
        "                [GetJigsawPuzzleDataset(train_file_paths, permuts_file_path,\n",
        "                                        jig_size=jig_size)\n",
        "                 for st_perm_ind in range(0, n**2, n)\n",
        "                ]\n",
        "            ),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=2\n",
        "        )\n",
        "        val_data_loader = DataLoader(\n",
        "            ConcatDataset(\n",
        "                [GetJigsawPuzzleDataset(val_file_paths, permuts_file_path,\n",
        "                                        jig_size=jig_size)\n",
        "                 for st_perm_ind in range(0, n**2, n)\n",
        "                 ]\n",
        "            ),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=2\n",
        "        )\n",
        "    else:\n",
        "        train_data_loader = DataLoader(\n",
        "            GetJigsawPuzzleDataset(train_file_paths, permuts_file_path, jig_size=jig_size),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=2\n",
        "        )\n",
        "        val_data_loader = DataLoader(\n",
        "            GetJigsawPuzzleDataset(val_file_paths, permuts_file_path, jig_size=jig_size),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=2\n",
        "        )\n",
        "    print(\"Loaders done\")\n",
        "    # Print sample batches that would be returned by the train_data_loader\n",
        "    dataiter = iter(train_data_loader)\n",
        "    X, y, r = dataiter.__next__() # Returns patches, positions, rotations\n",
        "    print (X.size())\n",
        "    print (y.size())\n",
        "\n",
        "    # Train required model defined above on CUB200 data\n",
        "    num_outputs = num_permuts_saved#200\n",
        "    epochs = Cepochs\n",
        "    lr = Clr\n",
        "    weight_decay_const = Cweight_decay\n",
        "\n",
        "    # If using Resnet18\n",
        "    # model_to_train = resnet18(num_classes=num_outputs, siamese_deg=jig_size**2, jigsaw_size=jigsaw_puzzle_size)\n",
        "    model_to_train = PretrainedResNet(num_positions=jig_size**2)\n",
        "    print('Model ready')\n",
        "    # Set device on which training is done. Plus optimizer to use.\n",
        "    model_to_train.to(device)\n",
        "    optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
        "    # scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, min_lr=1e-5)\n",
        "\n",
        "    # Start training\n",
        "    print('Started training')\n",
        "    model_train_test_obj = JigsawModelTrainTest(model_to_train, device, model_file_path)\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    for epoch_no in range(epochs):\n",
        "        print(\"Epoch no {} #######################\".format(epoch_no))\n",
        "        print(optimizer)\n",
        "        print(train_data_loader)\n",
        "        print(val_data_loader)\n",
        "        train_loss, train_acc, val_loss, val_acc = model_train_test_obj.train(\n",
        "            optimizer, epoch_no, params_max_norm=4,\n",
        "            train_data_loader = train_data_loader, val_data_loader = val_data_loader\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        print(\"Train loss {} \\n Val loss {} \\n Train Acc {} \\n Val Acc {}\".format(train_loss,val_loss,train_acc,val_acc))\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    observations_df = pd.DataFrame()\n",
        "    observations_df['epoch count'] = [i for i in range(1, Cepochs + 1)]\n",
        "    observations_df['train loss'] = train_losses\n",
        "    print(f\"val_losses: {val_losses}\")\n",
        "    print(f\"type val loss: {type(val_losses)}\")\n",
        "    observations_df['val loss'] = val_losses\n",
        "    observations_df['train acc'] = train_accs\n",
        "    observations_df['val acc'] = val_accs\n",
        "    observations_file_path = Cexperiment_name + '_observations.csv'\n",
        "    observations_df.to_csv(observations_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_file_paths)"
      ],
      "metadata": {
        "id": "WrbRVKMY6qmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0330c587-c2cd-49f4-a623-2ab81a217411"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['extraimages/extra-image-93.jpg', 'extraimages/extra-image-86.jpg', 'extraimages/extra-image-44.jpg', 'extraimages/extra-image-75.jpg', 'extraimages/extra-image-80.jpg', 'extraimages/extra-image-17.jpg', 'extraimages/extra-image-90.jpg', 'extraimages/extra-image-8.jpg', 'extraimages/extra-image-58.jpg', 'extraimages/extra-image-40.jpg', 'extraimages/extra-image-20.jpg', 'extraimages/extra-image-94.jpg', 'extraimages/extra-image-76.jpg', 'extraimages/extra-image-61.jpg', 'extraimages/extra-image-5.jpg', 'extraimages/extra-image-12.jpg', 'extraimages/extra-image-71.jpg', 'extraimages/extra-image-54.jpg', 'extraimages/extra-image-97.jpg', 'extraimages/extra-image-42.jpg', 'extraimages/extra-image-28.jpg', 'extraimages/extra-image-43.jpg', 'extraimages/extra-image-67.jpg', 'extraimages/extra-image-25.jpg', 'extraimages/extra-image-22.jpg', 'extraimages/extra-image-89.jpg', 'extraimages/extra-image-57.jpg', 'extraimages/extra-image-69.jpg', 'extraimages/extra-image-79.jpg', 'extraimages/extra-image-96.jpg', 'extraimages/extra-image-26.jpg', 'extraimages/extra-image-60.jpg', 'extraimages/extra-image-100.jpg', 'extraimages/extra-image-37.jpg', 'extraimages/extra-image-9.jpg', 'extraimages/extra-image-68.jpg', 'extraimages/extra-image-36.jpg', 'extraimages/extra-image-51.jpg', 'extraimages/extra-image-52.jpg', 'extraimages/extra-image-31.jpg', 'extraimages/extra-image-35.jpg', 'extraimages/extra-image-63.jpg', 'extraimages/extra-image-85.jpg', 'extraimages/extra-image-16.jpg', 'extraimages/extra-image-34.jpg', 'extraimages/extra-image-73.jpg', 'extraimages/extra-image-18.jpg', 'extraimages/extra-image-3.jpg', 'extraimages/extra-image-92.jpg', 'extraimages/extra-image-24.jpg', 'extraimages/extra-image-59.jpg', 'extraimages/extra-image-41.jpg', 'extraimages/extra-image-78.jpg', 'extraimages/extra-image-23.jpg', 'extraimages/extra-image-27.jpg', 'extraimages/extra-image-6.jpg', 'extraimages/extra-image-19.jpg', 'extraimages/extra-image-99.jpg', 'extraimages/extra-image-64.jpg', 'extraimages/extra-image-91.jpg', 'extraimages/extra-image-38.jpg', 'extraimages/extra-image-4.jpg', 'extraimages/extra-image-83.jpg', 'extraimages/extra-image-53.jpg', 'extraimages/extra-image-62.jpg', 'extraimages/extra-image-47.jpg', 'extraimages/extra-image-98.jpg', 'extraimages/extra-image-77.jpg', 'extraimages/extra-image-87.jpg', 'extraimages/extra-image-10.jpg', 'extraimages/extra-image-81.jpg', 'extraimages/extra-image-95.jpg', 'extraimages/extra-image-66.jpg', 'extraimages/extra-image-46.jpg', 'extraimages/extra-image-82.jpg', 'extraimages/extra-image-45.jpg', 'extraimages/extra-image-39.jpg', 'extraimages/extra-image-15.jpg', 'extraimages/extra-image-70.jpg', 'extraimages/extra-image-55.jpg', 'extraimages/extra-image-1.jpg', 'extraimages/extra-image-74.jpg', 'extraimages/extra-image-49.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lbE1N98iTpV"
      },
      "source": [
        "# Plot loss and accuracy curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "XAuZaAkCiTpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "31381258-9aaf-4ac6-acdd-8ab2d2edcca3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.title('Loss plots')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "#plt.show()\n",
        "plt.savefig('loss.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "R5VXGhp7iTpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "2b887c4d-b8b3-4add-9c51-39f0f097703a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdglJREFUeJzt3XlcVPX+x/HXDLuALCIoioJLLuWOkq2amFnZprlcu6h1q1+llVbXrOtS3sLMvGaWtq+WZml7lpJLi6lpZu67uAEqAgKyzZzfH0dHARdQ8LC8n4/HPJw5c+bMZ0aYefM938VmGIaBiIiIiLjYrS5AREREpKJRQBIREREpQgFJREREpAgFJBEREZEiFJBEREREilBAEhERESlCAUlERESkCAUkERERkSIUkERERESKUEASEamAunTpQpcuXawuQ6TaUkASkVJ77bXXsNlsxMTEWF2KFJGdnc24ceNYvHix1aWIVGoKSCJSajNnziQyMpIVK1awbds2q8uRU2RnZ/PMM88oIIlcIAUkESmVnTt38ttvvzF58mRq167NzJkzrS7pjLKysqwuQUQqKQUkESmVmTNnEhQUxE033USfPn3OGJDS0tIYPnw4kZGReHl5Ub9+feLi4jh06JBrn5ycHMaNG8cll1yCt7c3devW5Y477mD79u0ALF68GJvNVqw1ZNeuXdhsNt577z3XtsGDB+Pn58f27du58cYb8ff3Z+DAgQD8/PPP3HnnnTRo0AAvLy8iIiIYPnw4x44dK1b3pk2b6Nu3L7Vr18bHx4dmzZrx9NNPA7Bo0SJsNhvz5s0r9riPP/4Ym83GsmXLzvjevffee9hsNpYuXcr9999PrVq1qFmzJnFxcRw5cuSMjzshJSWFe+65h7CwMLy9vWnTpg3vv/9+ofeldu3aADzzzDPYbDZsNhvjxo0DICkpiSFDhlC/fn28vLyoW7cut956K7t27Trnc4tUN+5WFyAilcvMmTO544478PT0ZMCAAUyfPp2VK1fSsWNH1z6ZmZlcffXVbNy4kbvvvpv27dtz6NAhvvrqK/bu3UtISAgOh4Obb76ZhIQE+vfvzyOPPMLRo0dZsGAB69ato3HjxqWuraCggB49enDVVVcxadIkatSoAcCcOXPIzs7mgQceoFatWqxYsYJXXnmFvXv3MmfOHNfj165dy9VXX42Hhwf33XcfkZGRbN++na+//prnnnuOLl26EBERwcyZM7n99tuLvS+NGzemc+fO56xz6NChBAYGMm7cODZv3sz06dPZvXu3KxCezrFjx+jSpQvbtm1j6NChREVFMWfOHAYPHkxaWhqPPPIItWvXZvr06TzwwAPcfvvt3HHHHQC0bt0agN69e7N+/XqGDRtGZGQkKSkpLFiwgMTERCIjI0v9fotUaYaISAn98ccfBmAsWLDAMAzDcDqdRv369Y1HHnmk0H5jxowxAGPu3LnFjuF0Og3DMIx33nnHAIzJkyefcZ9FixYZgLFo0aJC9+/cudMAjHfffde1bdCgQQZgPPnkk8WOl52dXWxbfHy8YbPZjN27d7u2XXPNNYa/v3+hbafWYxiGMWrUKMPLy8tIS0tzbUtJSTHc3d2NsWPHFnueU7377rsGYHTo0MHIy8tzbZ84caIBGF9++aVr27XXXmtce+21rttTpkwxAOOjjz5ybcvLyzM6d+5s+Pn5GRkZGYZhGMbBgwcNoFgtR44cMQDjxRdfPGuNImLSKTYRKbGZM2cSFhZG165dAbDZbPTr149Zs2bhcDhc+33++ee0adOmWCvLicec2CckJIRhw4adcZ/z8cADDxTb5uPj47qelZXFoUOHuOKKKzAMgz///BOAgwcPsnTpUu6++24aNGhwxnri4uLIzc3ls88+c22bPXs2BQUF3HXXXSWq8b777sPDw6NQze7u7nz33XdnfMx3331HnTp1GDBggGubh4cHDz/8MJmZmSxZsuSsz+nj44OnpyeLFy8u0ek8kepOAUlESsThcDBr1iy6du3Kzp072bZtG9u2bSMmJobk5GQSEhJc+27fvp3LLrvsrMfbvn07zZo1w9297M70u7u7U79+/WLbExMTGTx4MMHBwfj5+VG7dm2uvfZaANLT0wHYsWMHwDnrbt68OR07dizU92rmzJlcfvnlNGnSpER1Nm3atNBtPz8/6tate9a+QLt376Zp06bY7YU/tlu0aOG6/2y8vLx44YUX+P777wkLC+Oaa65h4sSJJCUllahmkepGAUlESuSnn37iwIEDzJo1i6ZNm7ouffv2BSiX0Wxnakk6tbXqVF5eXsUChMPhoHv37nz77beMHDmSL774ggULFrg6eDudzlLXFRcXx5IlS9i7dy/bt2/n999/L3HrkZUeffRRtmzZQnx8PN7e3owePZoWLVq4WtFE5CR10haREpk5cyahoaG8+uqrxe6bO3cu8+bNY8aMGfj4+NC4cWPWrVt31uM1btyY5cuXk5+fX+h006mCgoIAc0Tcqc7VWnKqv//+my1btvD+++8TFxfn2r5gwYJC+zVq1AjgnHUD9O/fnxEjRvDJJ59w7NgxPDw86NevX4lr2rp1q+s0JZid2g8cOMCNN954xsc0bNiQtWvX4nQ6C4XATZs2ue6Hc5+ebNy4MY899hiPPfYYW7dupW3btrz00kt89NFHJa5fpDpQC5KInNOxY8eYO3cuN998M3369Cl2GTp0KEePHuWrr74CzNFSf/3112mHwxuG4drn0KFDTJs27Yz7NGzYEDc3N5YuXVro/tdee63Etbu5uRU65onrL7/8cqH9ateuzTXXXMM777xDYmLiaes5ISQkhJ49e/LRRx8xc+ZMbrjhBkJCQkpc0xtvvEF+fr7r9vTp0ykoKKBnz55nfMyNN95IUlISs2fPdm0rKCjglVdewc/Pz3XK8MTIvaKhMjs7m5ycnELbGjdujL+/P7m5uSWuXaS6UAuSiJzTV199xdGjR7nllltOe//ll1/umjSyX79+PPHEE3z22Wfceeed3H333XTo0IHU1FS++uorZsyYQZs2bYiLi+ODDz5gxIgRrFixgquvvpqsrCwWLlzIgw8+yK233kpAQAB33nknr7zyCjabjcaNG/PNN9+QkpJS4tqbN29O48aNefzxx9m3bx81a9bk888/P21H5alTp3LVVVfRvn177rvvPqKioti1axfffvsta9asKbRvXFwcffr0AWD8+PElfzOBvLw8unXrRt++fdm8eTOvvfYaV1111RnfXzA7dr/++usMHjyYVatWERkZyWeffcavv/7KlClT8Pf3B8zO2C1btmT27NlccsklBAcHc9lll1FQUOB6zpYtW+Lu7s68efNITk6mf//+papfpFqwcgidiFQOvXr1Mry9vY2srKwz7jN48GDDw8PDOHTokGEYhnH48GFj6NChRr169QxPT0+jfv36xqBBg1z3G4Y5/P7pp582oqKiDA8PD6NOnTpGnz59jO3bt7v2OXjwoNG7d2+jRo0aRlBQkHH//fcb69atO+0wf19f39PWtmHDBiM2Ntbw8/MzQkJCjHvvvdf466+/ih3DMAxj3bp1xu23324EBgYa3t7eRrNmzYzRo0cXO2Zubq4RFBRkBAQEGMeOHSvJ2+ga5r9kyRLjvvvuM4KCggw/Pz9j4MCBxuHDhwvtW3SYv2EYRnJysjFkyBAjJCTE8PT0NFq1alWsfsMwjN9++83o0KGD4enp6Rryf+jQIeOhhx4ymjdvbvj6+hoBAQFGTEyM8emnn5aodpHqxmYYRdqORUTknAoKCggPD6dXr168/fbbJXrMe++9x5AhQ1i5ciXR0dHlXKGIXAj1QRIROQ9ffPEFBw8eLNTxW0SqDvVBEhEpheXLl7N27VrGjx9Pu3btXJ2jRaRqUQuSiEgpnFjrLDQ0lA8++MDqckSknKgPkoiIiEgRakESERERKUIBSURERKQIddI+T06nk/379+Pv739BK4+LiIjIxWMYBkePHiU8PLzY2o2nUkA6T/v37yciIsLqMkREROQ87Nmzh/r165/xfgWk83RiWv89e/ZQs2ZNi6sRERGRksjIyCAiIsL1PX4mCkjn6cRptZo1ayogiYiIVDLn6h6jTtoiIiIiRSggiYiIiBShgCQiIiJShAKSiIiISBEKSCIiIiJFKCCJiIiIFKGAJCIiIlKEApKIiIhIEQpIIiIiIkUoIImIiIgUoYAkIiIiUoQCkoiIiEgRWqxWRETEQjn5Dg5n5eFms2G3g7vd7rruZrdht9lws9twt9vOucCqlB0FJBEREYss236Y//toFenH8ku0v83G8fBkw+14cDpxMYPUyfvd7YX3sxfZ/9QQ5ma342YDN7sdT3cbnm52vNzd8HS34+lux8v1b+FtXu52c18PO55ubkX2tZ+yr5trX7u9coQ8BSQREREL/Lz1IPd+8Ac5+U7c7TYMwOE0zvoYw4ACw4Bz7FeRebiZAex0gevkv254utl5pFtTWtUPsKROBSQREZGLbNGmFO7/aBV5BU66NqvN9Ls64O3hBoDTaeAwDBzO4xfDMLcV2e50Ung/p4HTKPyYAqdR6HhOw6DAcWI/Ch/7+P75Did5BU5yCxzmvw4nuflO8lzbneSduK/A3JZXbB+H677cAmeh157vMMh3OMjKcwBnbzkbdEXD8vovOCcFJBERkYvox/VJPPTxavIdBt1bhjHtH+3wcndz3W+327Bjw8PtLAepRAzDIN9hHA9RjiJBy/z3RBgrGrqahvpbVrcCkoiIyEXy7doDPDLrTwqcBje1qsuU/m3xcKvaA8ptNpvZr8ndjp9X5YkdladSERGRSuzLNfsYPnsNTgNuaxvOpDvb4F7Fw1FlpoAkIiJSzj5btZcnPvsLw4A+HerzQu/WuFWS0VzVlQKSiIhIOfpkRSJPzfsbw4ABnRrw3G2XVZqh7tWZApKIiEg5+WDZLsZ8uR6AQZ0bMu6WSzXZYyWhgCQiIlIO3vp5B//9diMA/7oqiqdvaqFwVIkoIImIiJSx1xZvY+L8zQA82KUxT/RopnBUySggiYiIlBHDMJiasI3/LdwCwKOxTXmkW1OFo0pIAUlERKQMGIbBSz9uYdqibQA80aMZD3VtYnFVcr4UkERERC6QYRjEf7+JN5buAODpG1tw7zWNLK5KLoQCkoiIyAUwDINnvt7Ae7/tAmBcr5YMvjLK2qLkgikgiYiInCen0+A/X67j4+WJADx/eyv+EdPA4qqkLCggiYiInAeH0+DJz9cyZ9VebDZ4oXdr+kZHWF2WlBEFJBERkVIqcDh54rO1zPtzH3YbvNS3Dbe3q291WVKGFJBERERKId/h5NHZa/h27QHc7DZe7t+Wm1uHW12WlDEFJBERkRLKK3Ay7JPV/LA+GQ83G9P+0Z4el9axuiwpB3arCwB49dVXiYyMxNvbm5iYGFasWHHGfefOnUt0dDSBgYH4+vrStm1bPvzwQ9f9+fn5jBw5klatWuHr60t4eDhxcXHs37+/0HEiIyOx2WyFLhMmTCi31ygiIpVbTr6DBz5axQ/rk/F0s/P6PzsoHFVhlgek2bNnM2LECMaOHcvq1atp06YNPXr0ICUl5bT7BwcH8/TTT7Ns2TLWrl3LkCFDGDJkCD/88AMA2dnZrF69mtGjR7N69Wrmzp3L5s2bueWWW4od69lnn+XAgQOuy7Bhw8r1tYqISOWUk+/g3g/+IGFTCl7udt4aFM11zcOsLkvKkc0wDMPKAmJiYujYsSPTpk0DwOl0EhERwbBhw3jyySdLdIz27dtz0003MX78+NPev3LlSjp16sTu3btp0MAcfhkZGcmjjz7Ko48+el51Z2RkEBAQQHp6OjVr1jyvY4iISMWXnVfAv97/g9+2H8bHw423B0VzRZMQq8uS81TS729LW5Dy8vJYtWoVsbGxrm12u53Y2FiWLVt2zscbhkFCQgKbN2/mmmuuOeN+6enp2Gw2AgMDC22fMGECtWrVol27drz44osUFBSc8Ri5ublkZGQUuoiISNWWmVvA4HdW8tv2w/h6uvH+3Z0UjqoJSztpHzp0CIfDQVhY4WbKsLAwNm3adMbHpaenU69ePXJzc3Fzc+O1116je/fup903JyeHkSNHMmDAgEJJ8eGHH6Z9+/YEBwfz22+/MWrUKA4cOMDkyZNPe5z4+HieeeaZ83iVIiJSGWXk5DP4nRWsTkzD38ud9+7uRIeGQVaXJRdJpRzF5u/vz5o1a8jMzCQhIYERI0bQqFEjunTpUmi//Px8+vbti2EYTJ8+vdB9I0aMcF1v3bo1np6e3H///cTHx+Pl5VXsOUeNGlXoMRkZGUREaEIwEZGqKC07j7h3VrB2bzoBPh58eE8nWtcPtLosuYgsDUghISG4ubmRnJxcaHtycjJ16px5ZIDdbqdJE3OF5LZt27Jx40bi4+MLBaQT4Wj37t389NNP5+wnFBMTQ0FBAbt27aJZs2bF7vfy8jptcBIRkaolNSuPu95azoYDGQT7evLhPZ24NDzA6rLkIrO0D5KnpycdOnQgISHBtc3pdJKQkEDnzp1LfByn00lubq7r9olwtHXrVhYuXEitWrXOeYw1a9Zgt9sJDQ0t3YsQEZEq4+DRXAa88TsbDmQQ4ufJJ/dernBUTVl+im3EiBEMGjSI6OhoOnXqxJQpU8jKymLIkCEAxMXFUa9ePeLj4wGzL1B0dDSNGzcmNzeX7777jg8//NB1Ci0/P58+ffqwevVqvvnmGxwOB0lJSYA5RYCnpyfLli1j+fLldO3aFX9/f5YtW8bw4cO56667CArS+WURkeooOSOHf7z5O9sPZhHq78XH915Ok1A/q8sSi1gekPr168fBgwcZM2YMSUlJtG3blvnz57s6bicmJmK3n2zoysrK4sEHH2Tv3r34+PjQvHlzPvroI/r16wfAvn37+OqrrwDz9NupFi1aRJcuXfDy8mLWrFmMGzeO3NxcoqKiGD58eKE+RiIiUn3sTzvGP978nV2Hs6kb4M3H915OVIiv1WWJhSyfB6my0jxIIiJVw57UbP7x1u/sST1GvUAfZt13ORHBNawuS8pJSb+/LW9BEhERscruw1n8483l7Es7RsNaNfj43supF+hjdVlSASggiYhItbT9YCb/ePN3kjNyaVTbl4//dTl1ArytLksqCAUkERGpVlKz8li3L50Rn/7Focxcmob6MfPeGEL9FY7kJAUkERGpcvIKnCSmZrH9YBY7Dmax/WAmOw5msuNQFmnZ+a79mtfxZ+a/Yqjlp3nupDAFJBERqZQMw+BwVh7bU8zgs+NgpisM7TlyDIfzzGOQwgO86RAZzLO3XEqQr+dFrFoqCwUkEZEqyDAMdh3OZvXuI6zdm4bDMAiu4UlgDU+CfD0IquF58uLrgZ+XOzabzeqyTyu3wMHuw9nsOJjJdldrkBmIMnLOvMh4DU83GtX2pVGIH41r+5nXa/sSFeJLDU99/cnZ6SdERKQKOJbn4K+9aazafYQ/E4+wOjGN1Ky8Ej/ew81mhqcaHgTW8CS4SJAKrOFBsK+na59gX09qentgt5dNqDIMg4OZuWxPyWLHoZMBaPvBLPYeyeZMjUE2G9QL9KFRbT8ahfjSuLYvjWqbgSispleFDX1S8SkgiYhUMoZhsPfIMVYnHmH1bjMMbTiQUeyUkqe7nVb1AmgXEUgNTzeOZOeTmp1HWnYeR7LyOZKdx5HsPHLyneQ7DA4ezeXg0dwzPGtxdhsEHg9PJ1ukCgepIN+T24N8PfHxcGPPkWzzVFiRU2NHc8/cGuTn5U6j2r5mS1CIGYJOtAZ5e7id93spciYKSCIiFVxOvoN1+9KPB6I0ViUeOW2QqVPTm/YNA2nfIIj2DYO4NLwmXu7nDg/H8hyusHQiOKVl55F66vXs/OPb8kjLzicztwCnYY4IM1uqsi74ddptUD+oxsnTYqEnTo/5UttfrUFycSkgiYhUMAfSj7F6dxqrE4+wavcR1u9PJ99RuHXI3W7j0vCatG8YRPsGQXRoGET4eU5w6OPpho+nT6ken1fgNFuiso+3RGWd4Xq2GahSs/JIP2aOHvP3dnf1CTrRItQ41I8GwTXUGiQVhgKSiIiF8gqcbDiQwerdR1iVeIQ/dx9hf3pOsf1C/DxdLUPtGwTRun6ApWHC091OaE1vQmuWfO6gAoeTY/mOCt0hXOQEBSQRkYvo4NHcU/oOHWHt3nRyC5yF9rHboEXdmq6WofYNgogI9qn0ocLdzY6/m/3cO4pUAApIIiLlpMDhZFPSUVcgWpV4hD2px4rtF1jDw2wdahBI+4ZBtKkfiK+XPp5FrKTfQBGRC2QYBkkZOWxNzmRrSiZbk4+yNSWTjQcyyM5zFNrXZoNLQv0LdaZuFOJb6VuHRKoaBSQRkRIyDIP96TlmAErOZGuKGYS2JWeecYi6v5c7bRsEuk6VtW0QSE1vj4tcuYiUlgKSiEgRTqfBvrRjbEvJZMvx1iAzCB0lq0iL0AludhuRtWrQNNSfpmF+NA3zp3kdf5rU9iuzyRRF5OJRQBKRasvpNCdcPBmCjrItJZNtKZnFTo2d4G63ERXia4agE2Eo1J+oEF883dUBWaSqUEASkSrP4TTYk5rtCkInWoa2H8wkJ9952sd4uNloFOJXKAhdEuZHw1q+eGgklkiVp4AkIlXGiQVaNycdZVvKUbYc7zS9/WAmeQWnD0Ke7nYa1/ajaejxy/HTYw2Da+CuICRSbSkgiUiVsGp3KvHfbeKP3UdOe7+Xu50mrhDk7/o3IshHQUhEilFAEpFKbVtKJhPnb+LHDckAeLrZaVbHv0gQ8qN+UA3c1FlaREpIAUlEKqWUjBz+t3Arn/6xB4fTwG6DOztEMLz7JdQJKPnyFyIip6OAJCKVytGcfF5fsoO3f9nJsXxzpFlsizD+fUMzLgnzt7g6EakqFJBEpFLIK3Ayc/luXvlpG6lZeQC0axDIqJ4t6BQVbHF1IlLVKCCJSIXmdBp88/cBJv2wmcTUbAAahfjy7xua0ePSOlqiQ0TKhQKSiFRYv247xITvN/H3vnQAQvy8eDS2Kf06RmguIhEpVwpIIlLhbNifwYT5m1i65SAAvp5u3H9tY+65Kkqr3IvIRaFPGhGpMPYeyWbyj1uYt2YfhmEu6zEwpgHDujUlxM/L6vJEpBpRQBIRy6Vl5/Hqom28/9tu8hzmjNc3ta7LE9c3IzLE1+LqRKQ6UkASEcvk5Dt499ddvLZ4G0dzCgDo3KgWT/ZsTpuIQGuLE5FqTQFJRC46h9Pg89V7+d+CLRxIzwGgeR1/RvZsTpdLamtkmohYTgFJRC4awzBYtDmFF77fzObkowCEB3jz2PXNuK1dPS0FIiIVhgKSiFwUfyYeYcL3m1i+MxWAAB8PHuramLjOkXh7uFlcnYhIYQpIIlKudh7K4sUfNvHd30kAeLrbGXJFJA92aUJADQ+LqxMROT0FJBEpFweP5vJywhZmrdhDgdPAZoPe7eszvPsl1Av0sbo8EZGzUkASkTKVmVvAm0t38ObPO8jOMxeT7dqsNiN7Nqd5nZoWVyciUjIKSCJSJvIdTmatSOTlhK0cyjQXk21TP4Ane7agc+NaFlcnIlI6CkgicsF+WJ/EhO83sfNQFgCRtWrwRI/m3NhKi8mKSOWkgCQiF2TlrlTu/3AVALV8PXkktikDOjXQYrIiUqlViE+wV199lcjISLy9vYmJiWHFihVn3Hfu3LlER0cTGBiIr68vbdu25cMPPyy0j2EYjBkzhrp16+Lj40NsbCxbt24ttE9qaioDBw6kZs2aBAYGcs8995CZmVkur0+kKvtqzX4AujUPZcm/uxLXOVLhSEQqPcs/xWbPns2IESMYO3Ysq1evpk2bNvTo0YOUlJTT7h8cHMzTTz/NsmXLWLt2LUOGDGHIkCH88MMPrn0mTpzI1KlTmTFjBsuXL8fX15cePXqQk5Pj2mfgwIGsX7+eBQsW8M0337B06VLuu+++cn+9IlWJYRgs3JgMwMDLG+DnpUZpEakabIZhGFYWEBMTQ8eOHZk2bRoATqeTiIgIhg0bxpNPPlmiY7Rv356bbrqJ8ePHYxgG4eHhPPbYYzz++OMApKenExYWxnvvvUf//v3ZuHEjLVu2ZOXKlURHRwMwf/58brzxRvbu3Ut4ePg5nzMjI4OAgADS09OpWVMjc6R6WrcvnZtf+QUfDzf+HNNdEz6KSIVX0u9vS1uQ8vLyWLVqFbGxsa5tdrud2NhYli1bds7HG4ZBQkICmzdv5pprrgFg586dJCUlFTpmQEAAMTExrmMuW7aMwMBAVzgCiI2NxW63s3z58rJ6eSJV3oINZuvR1U1DFI5EpEqxtD380KFDOBwOwsLCCm0PCwtj06ZNZ3xceno69erVIzc3Fzc3N1577TW6d+8OQFJSkusYRY954r6kpCRCQ0ML3e/u7k5wcLBrn6Jyc3PJzc113c7IyCjhqxSpuk6cXuveMuwce4qIVC6VssOAv78/a9asITMzk4SEBEaMGEGjRo3o0qVLuT1nfHw8zzzzTLkdX6Sy2Zd2jPX7M7Db4Lrmoed+gIhIJWLpKbaQkBDc3NxITk4utD05OZk6deqc8XF2u50mTZrQtm1bHnvsMfr06UN8fDyA63FnO2adOnWKdQIvKCggNTX1jM87atQo0tPTXZc9e/aU7sWKVDEJx1uPOjQMopafl8XViIiULUsDkqenJx06dCAhIcG1zel0kpCQQOfOnUt8HKfT6Tr9FRUVRZ06dQodMyMjg+XLl7uO2blzZ9LS0li1apVrn59++gmn00lMTMxpn8PLy4uaNWsWuohUZyf6H8W20Ok1Eal6LD/FNmLECAYNGkR0dDSdOnViypQpZGVlMWTIEADi4uKoV6+eq4UoPj6e6OhoGjduTG5uLt999x0ffvgh06dPB8Bms/Hoo4/y3//+l6ZNmxIVFcXo0aMJDw/ntttuA6BFixbccMMN3HvvvcyYMYP8/HyGDh1K//79SzSCTaS6y8jJ5/cdhwGIVf8jEamCLA9I/fr14+DBg4wZM4akpCTatm3L/PnzXZ2sExMTsdtPNnRlZWXx4IMPsnfvXnx8fGjevDkfffQR/fr1c+3z73//m6ysLO677z7S0tK46qqrmD9/Pt7e3q59Zs6cydChQ+nWrRt2u53evXszderUi/fCRSqxpVsOku8waFTbl8a1/awuR0SkzFk+D1JlpXmQpDp7ZNaffLlmP/df04hRN7awuhwRkRKrFPMgiUjlk+9wsmiTOchBw/tFpKpSQBKRUlm5K5WMnAJq+XrSrkGQ1eWIiJQLBSQRKZUTo9euax6Km91mcTUiIuVDAUlESuzUxWk1ek1EqjIFJBEpsc3JR9mTegwvdztXNw2xuhwRkXKjgCQiJbbw+Om1q5qEUMPT8llCRETKjQKSiJTYgo3m6DWdXhORqk4BSURKJDkjh7/2pAHQrYUWpxWRqk0BSURKJOF461HbiEBC/b3PsbeISOWmgCQiJbJgQxKgySFFpHpQQBKRc8rKLeDX7ebitApIIlIdKCCJyDn9vPUQeQVOGgTXoGmoFqcVkapPAUlEzunE7NndW4Zhs2n2bBGp+hSQROSsHE6DnzYdnz27hU6viUj1oIAkIme1avcRjmTnE+DjQcdILU4rItWDApKInNWJtdeuax6Ku5s+MkSketCnnYic1YnlRXR6TUSqEwUkETmjbSmZ7DiUhaebnWub1ba6HBGRi0YBSUTO6MTptcsb18LPS4vTikj1oYAkImd04vRad629JiLVjAKSiJzWocxcViUeASBWs2eLSDWjgCQip/XTphQMAy6rV5O6AT5WlyMiclEpIInIablmz25Rx+JKREQuPgUkESkmJ9/Bz1sPAhDbUv2PRKT6UUASkWJ+3XaInHwn9QJ9aFm3ptXliIhcdApIIlLMAtfkkKFanFZEqiUFJBEpxOk0WLgxBdDoNRGpvhSQRKSQNXvTOJSZi7+XOzFRtawuR0TEEgpIIlLIickhr21WG093fUSISPWkTz8RKeTE8iLddXpNRKoxBSQRcdl9OIstyZm42210uUTD+0Wk+lJAEhGXE6PXOkUFE1DDw+JqRESso4AkIi6u2bN1ek1EqjkFJBEB4EhWHn/sPr44bQsFJBGp3hSQRASAxVtScDgNmtfxJyK4htXliIhYSgFJRACdXhMROZUCkoiQW+Bgyebji9Pq9JqIiAKSiMCy7YfJynMQVtOLVvUCrC5HRMRyCkgi4pocsluLMOx2LU4rIqKAJFLNGYbBwg3m4rTqfyQiYqoQAenVV18lMjISb29vYmJiWLFixRn3ffPNN7n66qsJCgoiKCiI2NjYYvvbbLbTXl588UXXPpGRkcXunzBhQrm9RpGKat2+DJIycqjh6UbnRlqcVkQEKkBAmj17NiNGjGDs2LGsXr2aNm3a0KNHD1JSUk67/+LFixkwYACLFi1i2bJlREREcP3117Nv3z7XPgcOHCh0eeedd7DZbPTu3bvQsZ599tlC+w0bNqxcX6tIRbTg+Om1a5rWxtvDzeJqREQqBnerC5g8eTL33nsvQ4YMAWDGjBl8++23vPPOOzz55JPF9p85c2ah22+99Raff/45CQkJxMXFAVCnTp1C+3z55Zd07dqVRo0aFdru7+9fbF+R6kbD+0VEirO0BSkvL49Vq1YRGxvr2ma324mNjWXZsmUlOkZ2djb5+fkEBwef9v7k5GS+/fZb7rnnnmL3TZgwgVq1atGuXTtefPFFCgoKzu+FiFRSe49ks/FABnYbdG2uxWlFRE6wtAXp0KFDOBwOwsIK/+UaFhbGpk2bSnSMkSNHEh4eXihkner999/H39+fO+64o9D2hx9+mPbt2xMcHMxvv/3GqFGjOHDgAJMnTz7tcXJzc8nNzXXdzsjIKFF9IhVZwkbzVHZ0ZDDBvp4WVyMiUnFYfortQkyYMIFZs2axePFivL29T7vPO++8w8CBA4vdP2LECNf11q1b4+npyf333098fDxeXl7FjhMfH88zzzxTti9AxGKu02uaHFJEpBBLT7GFhITg5uZGcnJyoe3Jycnn7Bs0adIkJkyYwI8//kjr1q1Pu8/PP//M5s2b+de//nXOWmJiYigoKGDXrl2nvX/UqFGkp6e7Lnv27DnnMUUqsoycfH7fcRiAWPU/EhEpxNKA5OnpSYcOHUhISHBtczqdJCQk0Llz5zM+buLEiYwfP5758+cTHR19xv3efvttOnToQJs2bc5Zy5o1a7Db7YSGnr4fhpeXFzVr1ix0EanMFm8+SIHToEmoH1EhvlaXIyJSoVh+im3EiBEMGjSI6OhoOnXqxJQpU8jKynKNaouLi6NevXrEx8cD8MILLzBmzBg+/vhjIiMjSUpKAsDPzw8/Pz/XcTMyMpgzZw4vvfRSsedctmwZy5cvp2vXrvj7+7Ns2TKGDx/OXXfdRVBQ0EV41SLWW3j89JrWXhMRKc7ygNSvXz8OHjzImDFjSEpKom3btsyfP9/VcTsxMRG7/WRD1/Tp08nLy6NPnz6FjjN27FjGjRvnuj1r1iwMw2DAgAHFntPLy4tZs2Yxbtw4cnNziYqKYvjw4YX6JYlUZfkOJ4s2a/ZsEZEzsRmGYVhdRGWUkZFBQEAA6enpOt0mlc6v2w4x8K3lhPh5svypWNy0/pqIVBMl/f62fCZtEbn4Toxe69Y8TOFIROQ0FJBEqhnDMFwBSaPXREROTwFJpJrZlHSUfWnH8Pawc1WTEKvLERGpkBSQRKqZE6PXrmpSGx9PLU4rInI6Ckgi1cyCjScWp9XaayIiZ6KAJFKNJKXnsHZvOjYbXNdc/Y9ERM5EAUmkGll4vPWoXUQgtf2LrzkoIiImBSSRauREQNLoNRGRsyt1QIqMjOTZZ58lMTGxPOoRkXKSlVvAb9vMxWmvV0ASETmrUgekRx99lLlz59KoUSO6d+/OrFmzyM3NLY/aRKQMLd1ykDyHk8haNWhc2+/cDxARqcbOKyCtWbOGFStW0KJFC4YNG0bdunUZOnQoq1evLo8aRaQMnBy9FobNptmzRUTO5rz7ILVv356pU6eyf/9+xo4dy1tvvUXHjh1p27Yt77zzDlriTaTiKHA4+WmTuThtbAudXhMRORf3831gfn4+8+bN491332XBggVcfvnl3HPPPezdu5ennnqKhQsX8vHHH5dlrSJynlbtPkJadj6BNTzo0DDI6nJERCq8Ugek1atX8+677/LJJ59gt9uJi4vjf//7H82bN3ftc/vtt9OxY8cyLVREzt+J0WvXNQ/F3U2DV0VEzqXUAaljx450796d6dOnc9ttt+Hh4VFsn6ioKPr3718mBYrIhTl1cdruOr0mIlIipQ5IO3bsoGHDhmfdx9fXl3ffffe8ixKRsrP9YCa7Dmfj6WbnmktqW12OiEilUOq29pSUFJYvX15s+/Lly/njjz/KpCgRKTs/Hm89uqJJLXy9zrvboYhItVLqgPTQQw+xZ8+eYtv37dvHQw89VCZFiUjZWbjh5PB+EREpmVIHpA0bNtC+ffti29u1a8eGDRvKpCgRKRsHj+by5540ALppcVoRkRIrdUDy8vIiOTm52PYDBw7g7q7me5GK5KdNyRgGtK4fQJ0Ab6vLERGpNEodkK6//npGjRpFenq6a1taWhpPPfUU3bt3L9PiROTCLNhgTg6p0WsiIqVT6iafSZMmcc0119CwYUPatWsHwJo1awgLC+PDDz8s8wJF5Pwcy3Pwy7aDAMSq/5GISKmUOiDVq1ePtWvXMnPmTP766y98fHwYMmQIAwYMOO2cSCJijV+2HSIn30n9IB+a1/G3uhwRkUrlvDoN+fr6ct9995V1LSJShk6MXottocVpRURK67x7VW/YsIHExETy8vIKbb/lllsuuCgRuTAOp0HCJg3vFxE5X+c1k/btt9/O33//jc1mwzAMANdfqA6Ho2wrFJFSW7MnjUOZefh7u9MpKtjqckREKp1Sj2J75JFHiIqKIiUlhRo1arB+/XqWLl1KdHQ0ixcvLocSRaS0Tqy91rVZKB5anFZEpNRK3YK0bNkyfvrpJ0JCQrDb7djtdq666iri4+N5+OGH+fPPP8ujThEphYUbdXpNRORClPpPS4fDgb+/OSImJCSE/fv3A9CwYUM2b95cttWJSKntPJTFtpRM3O02rm2mxWlFRM5HqVuQLrvsMv766y+ioqKIiYlh4sSJeHp68sYbb9CoUaPyqFFESuHE6LXLG9Wiprem3hAROR+lDkj/+c9/yMrKAuDZZ5/l5ptv5uqrr6ZWrVrMnj27zAsUkdJZoNNrIiIXrNQBqUePHq7rTZo0YdOmTaSmphIUFKS5VkQslpqVxx+7UgHo1iLU4mpERCqvUvVBys/Px93dnXXr1hXaHhwcrHAkUgEs2pSC04CWdWtSP6iG1eWIiFRapQpIHh4eNGjQQHMdiVRQJ0avae01EZELU+pRbE8//TRPPfUUqamp5VGPiJynnHwHS7aYi9N2b6GAJCJyIUrdB2natGls27aN8PBwGjZsiK+vb6H7V69eXWbFiUjJLdtxmOw8B3VqenNZvZpWlyMiUqmVOiDddttt5VCGiFyoE7Nnx7YMVZ9AEZELVOqANHbs2PKoQ0QugNNpkOAa3l/H4mpERCo/LdIkUgWs259OckYufl7uXN5Ii9OKiFyoUrcg2e32szbfa4SbyMV34vTatZfUxsvdzeJqREQqv1K3IM2bN4+5c+e6LrNnz+bJJ5+kbt26vPHGG+dVxKuvvkpkZCTe3t7ExMSwYsWKM+775ptvcvXVVxMUFERQUBCxsbHF9h88eDA2m63Q5YYbbii0T2pqKgMHDqRmzZoEBgZyzz33kJmZeV71i1jt1P5HIiJy4UrdgnTrrbcW29anTx8uvfRSZs+ezT333FOq482ePZsRI0YwY8YMYmJimDJlCj169GDz5s2Ehhb/sF+8eDEDBgzgiiuuwNvbmxdeeIHrr7+e9evXU69ePdd+N9xwA++++67rtpeXV6HjDBw4kAMHDrBgwQLy8/MZMmQI9913Hx9//HGp6hex2p7UbDYlHcXNbqNrMwUkEZGyYDMMwyiLA+3YsYPWrVuXuhUmJiaGjh07Mm3aNACcTicREREMGzaMJ5988pyPdzgcBAUFMW3aNOLi4gCzBSktLY0vvvjitI/ZuHEjLVu2ZOXKlURHRwMwf/58brzxRvbu3Ut4ePg5nzcjI4OAgADS09OpWVNDqsU67/66k2e+3sDljYKZdV9nq8sREanQSvr9XSadtI8dO8bUqVMLteCURF5eHqtWrSI2NvZkQXY7sbGxLFu2rETHyM7OJj8/n+Dgwh1TFy9eTGhoKM2aNeOBBx7g8OHDrvuWLVtGYGCgKxwBxMbGYrfbWb58+WmfJzc3l4yMjEIXkYrANXu2JocUESkzpT7FVnRRWsMwOHr0KDVq1OCjjz4q1bEOHTqEw+EgLKzwB3tYWBibNm0q0TFGjhxJeHh4oZB1ww03cMcddxAVFcX27dt56qmn6NmzJ8uWLcPNzY2kpKRip+/c3d0JDg4mKSnptM8THx/PM888U6rXJ1Le0o/ls3yHOat9dy0vIiJSZkodkP73v/8VCkh2u53atWsTExNDUFBQmRZ3LhMmTGDWrFksXrwYb29v1/b+/fu7rrdq1YrWrVvTuHFjFi9eTLdu3c7ruUaNGsWIESNctzMyMoiIiDj/4kXKwOLNKRQ4DS4J86NhLd9zP0BEREqk1AFp8ODBZfbkISEhuLm5kZycXGh7cnIydeqcfbK7SZMmMWHCBBYuXEjr1q3Pum+jRo0ICQlh27ZtdOvWjTp16pCSklJon4KCAlJTU8/4vF5eXsU6eotYzTV6TafXRETKVKn7IL377rvMmTOn2PY5c+bw/vvvl+pYnp6edOjQgYSEBNc2p9NJQkICnTufubPpxIkTGT9+PPPnzy/Uj+hM9u7dy+HDh6lbty4AnTt3Ji0tjVWrVrn2+emnn3A6ncTExJTqNYhYJa/AyZLNxxen1ek1EZEyVeqAFB8fT0hISLHtoaGhPP/886UuYMSIEbz55pu8//77bNy4kQceeICsrCyGDBkCQFxcHKNGjXLt/8ILLzB69GjeeecdIiMjSUpKIikpyTV6LjMzkyeeeILff/+dXbt2kZCQwK233kqTJk3o0aMHAC1atOCGG27g3nvvZcWKFfz6668MHTqU/v37l2gEm0hFsGJnKkdzC6jt70Wb+oFWlyMiUqWU+hRbYmIiUVFRxbY3bNiQxMTEUhfQr18/Dh48yJgxY0hKSqJt27bMnz/f1XE7MTERu/1kjps+fTp5eXn06dOn0HHGjh3LuHHjcHNzY+3atbz//vukpaURHh7O9ddfz/jx4wudIps5cyZDhw6lW7du2O12evfuzdSpU0tdv4hVFmwwBxTEtgjFbtfitCIiZanU8yA1aNCAadOmccsttxTa/uWXX/LQQw+xd+/eMi2wotI8SGKVbSmZzPljDzOXJ5KZW8Dbg6Lppj5IIiIlUtLv71K3IA0YMICHH34Yf39/rrnmGgCWLFnCI488Umj0mIiUnazcAr5de4DZf+xh1e4jru2X1avJlU2Kn/IWEZELU+qANH78eHbt2kW3bt1wdzcf7nQ6iYuLO68+SCJyeoZhsDrxCLNX7uGbtQfIzjMXgjaXFKlN3+gIujYPxcOtTOZ7FRGRU5z3UiNbt25lzZo1+Pj40KpVKxo2bFjWtVVoOsUm5eXg0Vzmrt7Lp3/sYfvBLNf2RiG+3BkdQe/29Qit6X2WI4iIyJmU2ym2E5o2bUrTpk3P9+EicooCh5PFmw8y+489LNpkTv4I4OPhxk2t69KvYwTRDQvPYi8iIuWn1AGpd+/edOrUiZEjRxbaPnHiRFauXHnaOZJE5PR2HMzk0z/28vnqvRw8muva3q5BIP2iI7ipdV38vT0srFBEpHoqdUBaunQp48aNK7a9Z8+evPTSS2VRk0iVlp1ndrie88deVuxKdW2v5evJ7e3q0bdjBJeE+VtYoYiIlDogZWZm4unpWWy7h4eHVrgXOQPDMPhzTxqfrtzD13/tJ+t4h2u7Dbo0C6VvdH2uax6Gp7s6XIuIVASlDkitWrVi9uzZjBkzptD2WbNm0bJlyzIrTKQqOJSZy7zV+/j0jz1sTcl0bW9YqwZ9oyPo3b4+dQLU4VpEpKIpdUAaPXo0d9xxB9u3b+e6664DICEhgY8//pjPPvuszAsUqWwKHE6Wbj3Ipyv3snBjsqvDtbeHnRsvq0vfjhHERAWrw7WISAVW6oDUq1cvvvjiC55//nk+++wzfHx8aNOmDT/99BPBwcHlUaNIpbDrUBZzVu3hs1V7Sc442eG6Tf0A+naMoFebcGqqw7WISKVw3vMgnZCRkcEnn3zC22+/zapVq3A4HGVVW4WmeZAE4Fieg+/+PsCnf+xh+c6THa6Danhwe7v69O1Yn+Z19PMhIlJRlPs8SEuXLuXtt9/m888/Jzw8nDvuuINXX331fA8nUmkYhsFfe9P59I89fL1mP0dzCwCw2eCaprXp1zGCbi1C8XJ3s7hSERE5X6UKSElJSbz33nu8/fbbZGRk0LdvX3Jzc/niiy/UQVuqPMMw+H5dElMTtrIp6ahre0SwD307RNC7Q33CA30srFBERMpKiQNSr169WLp0KTfddBNTpkzhhhtuwM3NjRkzZpRnfSIVQnJGDqO/WMePG5IB8HK30/OyOvSNjuDyRrWw29XhWkSkKilxQPr+++95+OGHeeCBB7TEiFQbhmEwe+UenvtuI0dzCnC323igS2P+dVUjAmqow7WISFVV4lnpfvnlF44ePUqHDh2IiYlh2rRpHDp0qDxrE7HU7sNZDHxrOU/O/ZujOQW0rh/A18Ou4rHrmykciYhUcSUOSJdffjlvvvkmBw4c4P7772fWrFmEh4fjdDpZsGABR48ePfdBRCoBh9PgrZ930GPKUn7bfhhvDztP39iCuQ9cQYu6GpEmIlIdXNAw/82bN/P222/z4YcfkpaWRvfu3fnqq6/Ksr4KS8P8q6ZNSRmM/Pxv/tqTBkDnRrWY0LsVDWv5WluYiIiUiZJ+f1/Qwk/NmjVj4sSJ7N27l08++eRCDiViqdwCB5MXbOHmqb/w1540/L3cmXBHKz6+N0bhSESkGrrgiSKrK7UgVR2rE48w8rO1rrXSYluE8d/bLtMaaSIiVVC5TxQpUtll5xUw6YctvPvbTgwDQvw8GXfLpdzUqq7WSRMRqeYUkKRa+mXrIZ6cu5a9R44BcEf7eoy+qSVBvp4WVyYiIhWBApJUK+nZ+fz32w3MWbUXgHqBPjx3+2V0aRZqcWUiIlKRKCBJtTF/3QFGf7meg0dzsdkg7vKGPHFDc/y89GsgIiKF6ZtBqryUozmM/XI9369LAqBxbV9e6N2a6MhgiysTEZGKSgFJqizDMPhs1V7Gf7OBjOPLhPzftY0Zel0TvD3crC5PREQqMAUkqZL2pGbz1Ly/+XmruRzOZfVq8kLv1lwaHmBxZSIiUhkoIEmV4nAavP/bLl78YTPH8h14udsZ0f0S7rkqCne3C5oXVUREqhEFJKkytiYf5d+fr+XPxDQAYqKCmdC7NVEhmglbRERKRwFJKr28AifTF29n2qKt5DsM/LzcGXVjcwZ0bIDdrgkfRUSk9BSQpFL7a08a//5sLZuTjwLQrXko/739MuoG+FhcmYiIVGYKSFIpHctzMHnBZt7+ZSdOA4J9zWVCerXWMiEiInLhFJCk0vlt2yGenPs3ianZANzWNpwxvS4lWMuEiIhIGVFAkkoj/Vg+8d9tZNbKPQDUDfDm+dtb0bW5lgkREZGypYAklcKP65P4zxfrSDmaC8A/L2/Iv29ohr+3h8WViYhIVaSAJBVaRk4+475cz9w/9wEQFeLLhDtaEdOolsWViYhIVaaAJBXW7zsO89inf7Ev7Rh2G9x3TWMejW2qZUJERKTcKSBJhZNb4OClH7fw5s87MAxoEFyD//VrQ4eGWlxWREQuDgUkqVA2Hshg+Ow1bEoy5zUa0CmC/9zUEl8v/aiKiMjFo28dqRAcToO3ft7BSz9uIc/hJMTPkwl3tCa2ZZjVpYmISDVUIVbvfPXVV4mMjMTb25uYmBhWrFhxxn3ffPNNrr76aoKCgggKCiI2NrbQ/vn5+YwcOZJWrVrh6+tLeHg4cXFx7N+/v9BxIiMjsdlshS4TJkwot9coZ7YnNZsBb/5O/PebyHM4iW0RxvxHr1E4EhERy1gekGbPns2IESMYO3Ysq1evpk2bNvTo0YOUlJTT7r948WIGDBjAokWLWLZsGREREVx//fXs22eOcsrOzmb16tWMHj2a1atXM3fuXDZv3swtt9xS7FjPPvssBw4ccF2GDRtWrq9VCjMMg89X7aXnyz+zYmcqNTzdeKF3K96M60CIn5fV5YmISDVmMwzDsLKAmJgYOnbsyLRp0wBwOp1EREQwbNgwnnzyyXM+3uFwEBQUxLRp04iLizvtPitXrqRTp07s3r2bBg0aAGYL0qOPPsqjjz56XnVnZGQQEBBAeno6NWvWPK9jVGepWXk8Pe9vvl+XBECHhkFM7tuGhrV8La5MRESqspJ+f1vagpSXl8eqVauIjY11bbPb7cTGxrJs2bISHSM7O5v8/HyCg888wik9PR2bzUZgYGCh7RMmTKBWrVq0a9eOF198kYKCgjMeIzc3l4yMjEIXOT+LNqfQY8pSvl+XhLvdxhM9mvHp/Z0VjkREpMKwtJP2oUOHcDgchIUV7msSFhbGpk2bSnSMkSNHEh4eXihknSonJ4eRI0cyYMCAQknx4Ycfpn379gQHB/Pbb78xatQoDhw4wOTJk097nPj4eJ555pkSvjI5ney8Ap7/biMf/Z4IQJNQP6b0a8tl9QIsrkxERKSwSj2KbcKECcyaNYvFixfj7e1d7P78/Hz69u2LYRhMnz690H0jRoxwXW/dujWenp7cf//9xMfH4+VVvP/LqFGjCj0mIyODiIiIMnw1VdufiUcY8elf7DyUBcCQKyMZeUNzTfooIiIVkqUBKSQkBDc3N5KTkwttT05Opk6dOmd97KRJk5gwYQILFy6kdevWxe4/EY52797NTz/9dM5+QjExMRQUFLBr1y6aNWtW7H4vL6/TBic5u3yHk2k/bWPaom04nAZ1anoz6c42XNU0xOrSREREzsjSPkienp506NCBhIQE1zan00lCQgKdO3c+4+MmTpzI+PHjmT9/PtHR0cXuPxGOtm7dysKFC6lV69zrdq1Zswa73U5oqFaGLys7DmbSZ/pvvJywFYfT4JY24fzw6DUKRyIiUuFZfoptxIgRDBo0iOjoaDp16sSUKVPIyspiyJAhAMTFxVGvXj3i4+MBeOGFFxgzZgwff/wxkZGRJCWZo6D8/Pzw8/MjPz+fPn36sHr1ar755hscDodrn+DgYDw9PVm2bBnLly+na9eu+Pv7s2zZMoYPH85dd91FUFCQNW9EFWIYBh8tT+S5bzeQk++kprc742+7jFvb1rO6NBERkRKxPCD169ePgwcPMmbMGJKSkmjbti3z5893ddxOTEzEbj/Z0DV9+nTy8vLo06dPoeOMHTuWcePGsW/fPr766isA2rZtW2ifRYsW0aVLF7y8vJg1axbjxo0jNzeXqKgohg8fXqiPkZyflIwc/v35WhZvPgjAlU1qMenONtQN8LG4MhERkZKzfB6kykrzIBX3/d8HeGre3xzJzsfL3c6TPZszqHMkdrvN6tJERESAkn9/W96CJJVfRk4+475az9zV5mzml4bXZEq/tjQN87e4MhERkfOjgCQX5Pcdh3ns07/Yl3YMuw0e6NKYR7pdgqe75avYiIiInDcFJDkvuQUOJv+4hTd+3oFhQIPgGkzu24boyDPPaC4iIlJZKCBJqW08kMHw2WvYlHQUgP4dI/jPzS3x89KPk4iIVA36RpMSczgN3v5lB5N+2EKew0ktX08m9G5N95Zh536wiIhIJaKAJCWy90g2j336F8t3pgIQ2yKU+DtaU9tfs4uLiEjVo4AkZ2UYBnNX72PcV+s5mltADU83xtzckn4dI7DZNHxfRESqJgUkOaMjWXk8Ne9vvl9nzkTevkEg/+vXloa1fC2uTEREpHwpIMlpZeUWcOurv5KYmo273cbw7pdw/zWNcHfT8H0REan6FJDktF5bvI3E1GzqBnjzxj+jaVU/wOqSRERELho1B0gxiYezefPnnQA8c8ulCkciIlLtKCBJMc9/t5G8AidXNQnREH4REamWFJCkkN+2HWL++iTsNhh9c0uNVBMRkWpJAUlcChxOnv1mAwB3Xd6QZnW02KyIiFRPCkji8snKPWxKOkqAjwfDYy+xuhwRERHLKCAJAGnZeUz+cTMAI7pfQpCvp8UViYiIWEcBSQCYsnArR7LzuSTMj4ExDawuR0RExFIKSMLW5KN8+PtuAMbcfKkmg5TSyU6FTwfBwmfgWJrV1YiIlAlNFFnNGYbBs99swOE06N4yjKuahlhdklQ2Cc/Chi/M66veg65PQYfB4OZhYVEiIhdGTQXVXMLGFH7eeghPNztP39jC6nKkskneAKvfN68HRcKxVPjucXitM2z+HgzD0vJERM6XAlI1llvg4L/fmsP6774qisgQLUIrpfTjf8BwQotbYOgfcOMkqFELDm+FT/rD+73gwF9WVykiUmoKSNXY+7/tYtfhbGr7ezH0uiZWlyOVzdaFsD0B7B7Q/RnzlFqne+HhP+HKR8HNC3b9DK9fC188CBn7ra5YRKTEFJCqqYNHc5masA2Af/dohp+XuqNJKTgKzNYjgJj7IbjRyfu8A8zANHQlXNYbMGDNTHilAyx6HnIzLSlZRKQ0FJCqqUk/bCYzt4DW9QPo3b6+1eVIZfPnB3BwI/gEwTWPn36foIbQ5x34VwJExEB+Nix5wQxKqz8Ep+Pi1iwiUgoKSNXQ33vT+XTVHgDG9roUu13rrUkp5GTAT8+Z17uMMkPS2dSPhrt/gDvfNztyZybBV0Ph9Wtg+6JyL1dE5HwoIFUzhmHwzNfrMQy4rW04HRqe48tNpKhfJkP2IajVBKLvLtljbDa49DZ4aAVc/1/wCoDkdfDhbTDzTkjZVJ4Vi4iUmgJSNfP12gP8sfsIPh5ujOzZ3OpypLI5shuWvWZev/6/pZ/ryN0LrhgGj6yBmP8Duzts/RGmXwHfjIDMg2VesojI+VBAqkaO5TmI/24jAA92aUzdAB+LK5JKJ+FZcORC5NVwyQ3nf5wawdDzBXhwOTS7CQwH/PE2TG0HP0+G/Jyyq1lE5DwoIFUjM5Zs50B6DvUCfbj3mkbnfoDIqfashHWfATbo8Zx52uxChTSBAR/DoG+gbhvIOwoJz8C0jvD3Z5poUkQso4BUTexLO8aMJdsBePqmFnh7uFlckVQqhgE/PGVebzvQDDNlKepquHcx3P46+IdDeiJ8fg+81Q0Sfy/b5xIRKQEFpGoi/ruN5BY4iYkKpudldawuRyqb9fNg7wrwqAHX/ad8nsNuhzb9Ydgq6Pof8PCFfavgnR7waRyk7iif5xUROQ0FpGpgxc5Uvll7ALsNxvRqia0sTo1I9ZGfAwvHmtevfBRq1i3f5/OsAdc+Yc7I3X4Q2Oyw4UuY1gl+eBqOHSnf5xcRQQGpynM4zWH9AP07NeDS8ACLK5JKZ8XrkJYI/nXhiqEX73n9w+CWqfB/v0Dj68CZD8ummR25f58OBXkXrxYRqXYUkKq4OX/sYf3+DPy93Xms+yVWlyOVTdYhWDrJvN5tDHhasKBx2KXwz3kw8HOo3cJsQZr/JLx2OWz8Rh25RaRcKCBVYRk5+bz4w2YAHunWlFp+XhZXJJXO4njIzTA7Zbfub20tTWPN1qSb/we+tSF1O8weCO/dBPv/tLY2EalyFJCqsFcStnI4K49GtX2J6xxpdTlS2aRsgj/eNa9f/5zZidpqbu7m7N3DVsPVj4G7N+z+Fd7oAnPvh/S9VlcoIlVEBfjEk/Kw/WAm7/66C4DRN7fE013/1VJKC0abEzg2v9kchl+ReNc0T/kN/QNa9zO3rZ1lLoSbMB6yDltbn4hUevrWrKKe+3YjBU6Drs1q07VZqNXlSGWz/SdzCRC7O8Q+Y3U1ZxYYAXe8Aff+BA2ugIIc+HkSTG4On98Lu5epj5KInBd3qwuQsrdocwo/bUrB3W7jPze3tLocqWycDvjh+FxHHe81Z7uu6Op1gCHfwaZvzE7lB9bA35+al9otzNNybfqBt0ZxWurQVljxhvkz5uUHnv7H//U7+2139Z+Ui08BqYrJdzgZ/80GAAZfEUnj2n4WVySVzp8fQcp68A6Ea/9tdTUlZ7NBi17mZd9q+OMdc7mSgxvh+yfMuZxa9THDUng7q6utfg78BR/cBsdSS/9Yu8cZApQfePmfvO267n+W0OUHdq0kIOdWIQLSq6++yosvvkhSUhJt2rThlVdeoVOnTqfd98033+SDDz5g3bp1AHTo0IHnn3++0P6GYTB27FjefPNN0tLSuPLKK5k+fTpNmzZ17ZOamsqwYcP4+uuvsdvt9O7dm5dffhk/v8odKD5YtpsdB7Oo5evJsG5Nz/0AkVPlHoWf/mtev3akuahsZVSvvXm5/r+w9lNzIdyDm2D1B+YlvJ0ZlC7rbc3UBdXN3lXw0e2Qk26OiLzkBsjNNNfey82EvMzT3y44Zj7emW9O71BWk4R61DCDUq0m0HNC2S+dI1WCzTCsPUE/e/Zs4uLimDFjBjExMUyZMoU5c+awefNmQkOL950ZOHAgV155JVdccQXe3t688MILzJs3j/Xr11OvXj0AXnjhBeLj43n//feJiopi9OjR/P3332zYsAFvb28AevbsyYEDB3j99dfJz89nyJAhdOzYkY8//rhEdWdkZBAQEEB6ejo1a9YsuzfkAhzOzKXLpMUczSkg/o5WDOjUwOqSqh6nE/KzzL9Qq6KE8WYfnuBG8OBycPe0uqKyYRjmmm5/vAMbvgDH8UkmvWqay5tE3w2hLSwtscravQxm3mmGn4gYGDin5Kc6HQVmWHIFqEwzxBe9XWhb0dB1ymOcBcWfw+5hdvjvPLRijNSUclfS72/LA1JMTAwdO3Zk2rRpADidTiIiIhg2bBhPPvnkOR/vcDgICgpi2rRpxMXFYRgG4eHhPPbYYzz++OMApKenExYWxnvvvUf//v3ZuHEjLVu2ZOXKlURHRwMwf/58brzxRvbu3Ut4ePg5n7ciBqSn5/3NzOWJtKxbk6+HXYWbXUuKXBDDgCO7zDl29q+G/WvMS34W3DQZoodYXGAZS99rjgIryIF+H5mnqqqirEOwZqY5hcGRnSe3N7jCDEotb1Gfl7KyYwl80h/ysyHyahgwyzzNZQXDgILck4EpJx2Wvmj2WwOIuhZunwE1z/35L5VbSb+/LT3FlpeXx6pVqxg1apRrm91uJzY2lmXLlpXoGNnZ2eTn5xMcbJ4K2LlzJ0lJScTGxrr2CQgIICYmhmXLltG/f3+WLVtGYGCgKxwBxMbGYrfbWb58Obfffnux58nNzSU3N9d1OyMjo9Svtzxt2J/BJysSARjbq6XCUWkZhhkQ9v9Z+JKTdvr9vxlutiK16nNRyyxXCc+a4ajhlebQ/qrKNwSufAQ6D4Odi81WpU3fQeJv5mV+LWg7EDoMhlqNra628tq60JzIsyDHXCqm30xznT2r2Gzg4W1efEPMbf0+gtXvw/xRsHMJTL8Cbnml6v5xIKViaUA6dOgQDoeDsLCwQtvDwsLYtGlTiY4xcuRIwsPDXYEoKSnJdYyixzxxX1JSUrHTd+7u7gQHB7v2KSo+Pp5nnqmYw50Nw+DZb9bjNOCm1nWJaVTL6pIqvowDxcNQ9qHi+7l5QthlZp+Veu3Nf1e+bfZpmXe/eYrmkusvfv1lbd8qWDvbvN7jOfPLpKqz280v7sbXQcZ+WP2h+WWZsQ9+m2peGl9ntipd0tOcpFJKZtO38Okgs+/QJT2h7/sVs1XOZjODcMMr4fN7zI7ks++C9nFwwwT1T6vmKvVv/IQJE5g1axaLFy929S0qL6NGjWLEiBGu2xkZGURERJTrc5bU/HVJ/L4jFS93O6N6Nre6nIon82DxMJR5miBsd4fQlmYIOnEJbVm8H86Nk8zlN/6eA5/+E+6aC5FXXpzXUh4MA3542rzeZkD1HOFVMxy6jDRn5976o9mqtG2hOR/U9p/MhXrbx5mXgPpWV1uxrZsLc+81+/u0vBXueKvi92ULaQr3LIRFz8GvL5sd+Xf/Bne8af5hJNWSpQEpJCQENzc3kpOTC21PTk6mTp06Z33spEmTmDBhAgsXLqR169au7Scel5ycTN26dQsds23btq59UlJSCh2voKCA1NTUMz6vl5cXXl4V7y+gnHwHz323EYD7r21M/SALm7ArguxUcw4cVxhaA+l7iu9ns0Pt5hDeHsLbmv+GXWo2v5+L3Q63TTf7MWyZDx/3g8FfV95gsfErSFwG7j5w3Wirq7GWmzs0v9G8pO40W5RWfwhHD8CSF8w+K5f0NFuVGl+nTr1FrfkEvnwQDCe06mv+nlSWljd3T+j+DDTpZi5bc3gbvN0duj5tnpLV1ADVjqU/uZ6ennTo0IGEhARuu+02wOyknZCQwNChQ8/4uIkTJ/Lcc8/xww8/FOpHBBAVFUWdOnVISEhwBaKMjAyWL1/OAw88AEDnzp1JS0tj1apVdOjQAYCffvoJp9NJTExM2b/QcvTWzzvYe+QYdQO8+b9rG1ldzsWVk242iZ/aMnRk12l2tJl/IZ7aMlSn1YU1n7t5wJ3vwUd9YPcv8FFvGPI91G52/se0QkEuLBhrXr9iGATUs7aeiiQ4CmLHQZenYNPXZqfuXT/D5m/NS2BD8/RMu3+CX22rq7XeH++affMwzPek18uVM1REXQMP/ApfP2L+8ZDwjNmKePsMtR5WM5aPYps9ezaDBg3i9ddfp1OnTkyZMoVPP/2UTZs2ERYWRlxcHPXq1SM+Ph4wh/CPGTOGjz/+mCuvPHlaw8/PzzWH0QsvvMCECRMKDfNfu3ZtsWH+ycnJzJgxwzXMPzo6ulIN809Kz6HrpMUcy3fwcv+23Nq2Cn+55WZC0t/HR5MdD0OHt51+3+BGRcJQa3PtrvKQkwEf3GLW4x8Od8+HoIbl81zl4bdp8OPT4BdmLgBr1QijyuLgZjMI/PWxGdDBHCbeohd0vMfsy1Id+m8Vtfx1+P74pKId/wU9X6z8rWuGYY52/O7f5shV70DoNQUuLT6IRyqXSjPMH2DatGmuiSLbtm3L1KlTXS05Xbp0ITIykvfeew+AyMhIdu/eXewYY8eOZdy4ccDJiSLfeOMN0tLSuOqqq3jttde45JJLXPunpqYydOjQQhNFTp06tcQTRVaEgDR89hrm/bmP6IZBzPm/ztiqygdz/jFIWle4ZejQZrPZvqiABsdPkZ0IRG3BJ+ji1pt1GN670ZyIMCgK7v4B/MPO/TirZR2Gqe0gNx1umQbt/2l1RZVHXjasn2f2Vdr3x8ntIZccX9ak/8X/ObTKry/DgjHm9c5Dzck5q8pnEcDh7fD5v8w/zgDa3mVOLllV50KrBipVQKqMrA5Iq3Yfoff037DZ4KuHrqJV/Uq6xlRBLiSvL9xnKGWDuYp8Uf7hhVuGwtueHK5rtYz98E4PSEuE0EthyLcV/wvyu3/DitchrBXcv6Ryng6pCA78ZQaltXPMlgYAd29zlu5O91bevmnnYhhmn6xFz5m3r3nC7K9TlcLRCY58WDwBfn4JMMw/hHq/BfWjz/lQqXgUkMqZlQHJ6TS4/bVf+WtvOn2j6zOxTyWZJt+Rb7aynNoylLz+5KzGp6oRcnJY/YmL/9k77lsudQe8cwNkJkP9jvDPLyruKatDW+G1y82RRnFfQqMuVldU+eVkmIvjrnzHXMvuhLYDofuzFSfMlwXDMOfN+mWyefu6/5gBqarb9SvMvQ8y9oLNDbqOgqtG6I+LSkYBqZxZGZA+W7WXx+f8hZ+XOz89fi2h/uU7xcF5cTrg0JbCYSjpb3PSuKJ8goq0DLWDmvUq51+iyRvg3Z7mBJNR15rLKlTE+V8+GQCbvzPXxPrHbKurqVoMA/auNFet/3uOuc070Ozw3X5Q1eib88NT8Ptr5u3rn4Mrzjyopso5lmZ2Rl8/17zd4Aq443UI1NJOlYUCUjmzKiBl5hbQddJiDh7NZVTP5tx/bQWY6dfpNFtPTg1DB/46ebrhVF41zYUhT514MbBh5QxDZ7L3D3j/FvP1N78Z7ny/Yg113rHE7Fhuc4MHf4fal5z7MXJ+9qw0v0yT/zZv14uGmydX3sVRnU747jHzlCKYc4J1utfamqxgGObEqt8+bq795hVg/r9WpZn1qzAFpHJmVUB6Yf4mpi/eTmStGvww/Bq83C9y026h9clOCUO5p1l6xcP3ZBg6cQluVPn/gi6JHUvMBTodudDmH3DrqxXjdTsd8Ma1Zmtep/vgxhetrqjqcxTAyrfgp/+aX6Y2O3S8F657uuSLtlYETgd8Ncwc2YXNXJKjunfsT91pToq5d6V5u3V/83eqvEbNSplQQCpnVgSk3Yez6D55KXkOJ2/FRRPbspxHShmGuexC0Vmojx0pvq+7tzm3UPgp/YZCmlbvc/ObvoXZ/zQ7nMf8n7l0gdUtZX9+BF8+ZP7F+/Cf4KtlaS6ajAPmlArrPjdv+4VBj+fNztxW/1yciyMf5v0frPvMDHi3vw6t+1pdVcXgKDA7qy+daI60DWxozsDdoHLNqVedKCCVMysC0n0f/MGPG5K5umkIH9zdqXyH9edmwsw+5gzLRdk9oM5lhVuGajc3J0+Uwv6aDfPuM69f+6TZqdMquZnwSgdzmZXr/2tODCkX3/afzFMzqdvN21HXwk0vmX9QVEQFefDZEHPVe7s79H4bLr3N6qoqnsTfzdaktETz9PW1/4arH69Yp9cFUEAqdxc7IP2y9RB3vb0cN7uN7x+5mkvCynEODsMwf9H/nmP+ooe2PDnXUL32x9cnq4Adjyuq5W/A98dH+PR4Hjo/ZE0di+JhyQQIioSHVuj/0EoFufDrVPh5kjlwwe5hLmdx9WPWrnhfVH4OfBoHW38wF27u+wE062l1VRVXTjp898TJhZ8jYuCON8zfOakwFJDK2cUMSAUOJzdO/ZktyZkMviKScbdcWq7PZy4Z8KgZjgZ/Aw2vKN/nqw6Wvmj2QQFrJmXM2A9T20PBMbPTuFoAKobUneYM1Ft/NG8HNjBnoW52g7V1gTkZ5qx/wI5F5in0/jOhSazVVVUOa+fAtyPMvpme/mYLYZt+Vlclx5X0+7sC9BqVc/l4RSJbkjMJrOHBo7Hl3Ax/4C/4fqR5vdtohaOycvXj5izDAF8/DBu+vLjPnzDeDEcRl5srrEvFEBwF//gU+n0ENeubp2c+6QezBkLaaRZZvlhyj5qn2HcsMgdbDPxM4ag0Wt8J//eL+fuWd9Q8zf75v8wpAqTSUECq4I5k5fHSj1sAeKz7JQTW8Cy/J8tJhzmDzZFXTXvAFY+U33NVNzab2e+n3T/Njpyf3QPbEi7Oc+//01w7DMxTfBW9Q3B1Y7OZa7k9tPz4qvHuZn+fVzvBL/8z+wBdTMfS4MPbYfev5rQc/5wHUVdf3BqqgqCGMPjb47OLu5ldFmZcDbtP069TKiQFpApuysItpB/Lp1mYPwM6leNEZIZhDuFN3QEBEebK1RVhWHpVYrOZK5y3vA2c+TD7LkhcXr7PaRjww3/M6636Qv0O5ft8cv68/MwZt+//2Zx8MD8bFo6D16+GXb9cnBqyU805svauNCe3jPtSo7EuhJu72Vn77h/Mfkjpiea6jT/91xwZKMU5neb8YQufgdeuMNeMtIi+ASuwzUlH+Wh5IgBjerXE3a0c/7tWvGme9rG7Q593oUZw+T1XdWZ3M4cAN4k1vwBn3mnOSVReNn8Hu38x+5B0G1N+zyNlJ6wlDPkObpthLrlzcBO8dxPMvR8yU8rveTNT4L2bzdPsNULM/of12pff81UnER3NU25t/mG2IC990VyWKHWH1ZVVDHnZsOk7+HIovNQM3o41l7FJWX+yf54F1En7PJV3J23DMPjn2yv4Zdshelwaxuv/LMdFEfetgrd7mK0aPeKh84Pl91xiysuGj+4wp1HwrQ1D5kNIk7J9joI8c7211O3m6CgFpMrn2BFzzbM/3gUMc/6qbqMh+u6ynWMsYz98cKu5PJBfHbPlKLR52R1fTlr3uTm7ek46ePpBz4nQ9h/V79R3ZgpsmW8Gox2LCi9D5VUTmnaHZjeaf0z6BJbpU2sUWzkr74C0YEMy937wB55udhaOuJYGtcpp6O+xI/D6NWbn0OY3m51Fq9svqlVy0s2/2JPWmqc1754PAfXL7vi/T4f5T5oB7OE/wascp4aQ8rV3FXw73GzdAXPKjZsml00LT1qiuTTOkZ3mGoiDvoZaFWAJo6osbQ/Mu9/s5wXmafcbJ4FfbUvLKleGYbaGbv4ONn9vLsnEKfEjoIE5hUTzG81TzO7l199WAamclWdAyi1wcP3/lrL7cDYPdmnMv28op7/kDMMcLbP5W3P21/uXlnlSl3PIPGgubnt4K9RqCkO+L5sPyexUmNrOXDS318vQYfCFH1Os5XSYa6AlPHt8aR8bdLwHrht9/r+3qTvMcJS+x/wMGPSV5uy5WJwO+PVlWPQcOAvMbcGNCk/AW7dN5f7DxpFvtpJv/t4MRkd2Fb4/vL3ZStSsJ4RdetH+OFdAKmflGZBmLNnOhO83EervxU+Pd8HPq5xmYv1tmrn0gZsn3POj+QspF1/6XrM/QvoeqNPa7PtxoWt0zR9lrrYeein838/Ve8mXquZoMvz4H/j7U/O2b224/jlz6Y/SfMEc2grv94KjByC4sdlyFFCvfGqWM9u3Cr5+pFhfRIebD/neIWZgDW0JoS3MS8glFWsy0aJyj5oj9Xb9DLt+hbxT1um0e0JEJ4i6BiKvAr/QcinBw8MDN7czf+YpIJWz8gpIKUdz6PriYrLyHLx0Zxt6dyjDUy6nSlxujqZwFlTfFbkrkkPb4N0bIOsgNOgMd809/w/Bw9vh1RizT9k/50Hj68q2VqkYdi6Fbx8z+w0BNLzKnJCwJH2HkjeYfY6yUsxlguK+BP865VuvnF12KhxYg7H/T5KOeZDmd8kZAq/NXNbJzcP849bNy7xuZdcIZwHkHzMvBbkUOnVmcwMPb/DwMQeL2C7O2LDAwEDq1Klz2iW5FJDKWXkFpCfm/MWcVXtpExHIvAeuwG4vhx/6rMPm0OGMfXDpHdDnHfU7qgiS/oZ3b4LcdLNjYv9Pzu88/KyB5jw6TbrDXZ+VfZ1ScRTkwbJXYMmL5kSgdndzQtJr/w2evqd/zP415jxHx1LNBab/+QX4hlzMquUsDhw4QFpaGqGhodTw8sDmyDP/b/NyzH+NgtM8ymYGJQ9vcD8eRDy8yi+MGIa5DE3eUXONR0dO4fvtnuDtb3ZC96hxUb9fDMMgOzublJQUAgMDqVu3brF9Svr9rVX0KpACh5P0Y+bcGGN7tSyfcOR0mp0DM/aZzeq9XlY4qijqtIKBc+DD22DbQnM9vD7vlO702K5fzHBkczMnppSqzd3THKF4WR9zBvwt38OvU8yRUj1fMPt3nPr7vfcP+PAOM4SHt4d/zgWfIMvKl8IcDocrHNWqVesMO+WZLTV52eZUIfnZx/sw5ZqtNwXpx3e0ma02HjXMi2eN4y045/l573RCXqY5uCQn3WyhPv40uNvMQO4dYI609PA+v+coIz4+PgCkpKQQGhp61tNtZ6OAVIG4u9l5Iy6azUlHaVannDrm/fo/2LbA/EXp+z54l/9Cu1IKDWLMkYQf94MNX8A3NaHX1JJ9qDmd8MNT5vUOgzVMuzoJagj/mGUOmf5+pDkh4ax/wCU3mEEpKBJ2/2bOu5WXaS6BMXCOfv8rmPx8M3TUqHGW0+tunublRD9FwzA7Q58ISyeCk+E4uc3FboYmzxonw9PZQpOjwAzTOelm3yLDefI+m93sQH4iFLlVrDhx4j3Mz89XQKpKyi0c7frl5IKpPSeaLRZS8TTpBn3eNpd9Wf2BOSfI9f89d0haO9scBu5VE7qMuiilSgXT/EZodC0snQS/vWLOM7NjCbSPgz8/NL8sI6+GAbPMmbulQjpdv5mz7Gy2JLp7nhzNaBjHW5pOCUz5x46Hpizz4nq8/WQrk4cPuHudbCnKyyr8XHYPMxB5B5inzyrwaguleg/PoOK+OilbmSnm+l+GE1r3Nz8wpeJqeSvc8op5fdk0+HnS2ffPyzaHf4N5yqUqz6ciZ+fpC7Fj4YFfzTBUcAxWvG5+STaJNVuOFI6qNpvNDDo+QebIxJCm5h/EtVuY0zn41jZ/Tmx28zshL9PssJ+22+z0n7H/ZDhy9zEnDw1pZg7FD4wwWx7LMRxFRkYyZcqUcjt+SakFqTpwOsz+LJlJ5g/5zZPV76gyaHcX5GTAD6PMlj/vwDOPNlw2DY7uNydbi/m/i1qmVFC1m5lD9/+eA4ueh/od4dZp5henVD822/HRZN7A8aWkDMOcwfrU03MFuWZrkneAGYRK+PPSpUsX2rZtWybBZuXKlfj6nmGQwUWkgFQdLH0Rdiw2f+j7fnDm0S1S8XR+0GzqXjIBvnvcPH3Wpl/hfTIOmKu+A3QfZ3kHSalAbDZzfqTWfa2uRCoi24mO3D7AGTqFlxHDMHA4HLi7nzt21K5dMVrAdYqtqtu+CBZPMK/fNFkddyujLk+ebBX64gGzI+6pFv3X/Ouvfkdz2gYRkYto8ODBLFmyhJdffhmbzYbNZuO9997DZrPx/fff06FDB7y8vPjll1/Yvn07t956K2FhYfj5+dGxY0cWLlxY6HhFT7HZbDbeeustbr/9dmrUqEHTpk356quvyv11KSBVZRkHzFNrGNDun9B2gNUVyfmw2cxFhNv8w+xkOWew2fEW4MBa+HOmeb1HvE6dilQxhmGQnVdgyaWk0yS+/PLLdO7cmXvvvZcDBw5w4MABIiIiAHjyySeZMGECGzdupHXr1mRmZnLjjTeSkJDAn3/+yQ033ECvXr1ITEw863M888wz9O3bl7Vr13LjjTcycOBAUlNTL/j9PRudYquqHAXw+T3mzMxhl8GNL1pdkVwIu93stJ2bYc5z9MkAs39JwjjAgMt6Q0RHq6sUkTJ2LN9ByzE/WPLcG57tQQ3Pc8eEgIAAPD09qVGjBnXqmDOyb9q0CYBnn32W7t27u/YNDg6mTZs2rtvjx49n3rx5fPXVVwwdOvSMzzF48GAGDDD/yH/++eeZOnUqK1as4IYbbjiv11YSakGqqhY/b64U7ekHd75//ByzVGpu7ubEkY26mMN037vJXG7CzQu6jbW6OhGRYqKjowvdzszM5PHHH6dFixYEBgbi5+fHxo0bz9mC1Lp1a9d1X19fatasSUpKSrnUfIJakKqirQvg55fM67dMhZAm1tYjZcfdC/rNNGfb3rvS3Hb5A+ZEgSJS5fh4uLHh2R6WPfeFKjoa7fHHH2fBggVMmjSJJk2a4OPjQ58+fcjLyzvrcTw8PArdttlsOJ3OM+xdNhSQqpr0vTD3PvN69D3mqRepWrz8zLlsZt5pzm579QirKxKRcmKz2Up0mstqnp6eOByOc+7366+/MnjwYG6//XbAbFHatWtXOVd3fir+uy4l58iHOUPMRSjrtoEez1tdkZQXnyC4Z4E6ZYtIhRAZGcny5cvZtWsXfn5+Z2zdadq0KXPnzqVXr17YbDZGjx5d7i1B50t9kKqShGdg7wpzrpw739N8OFWdwpGIVBCPP/44bm5utGzZktq1a5+xT9HkyZMJCgriiiuuoFevXvTo0YP27dtf5GpLxmaUdByfFJKRkUFAQADp6enUrFkBFnzc9K25OCVA3w+h5S3W1iMiIqWSk5PDzp07iYqKwttbf+BeiLO9lyX9/lYLUlVwZJc5gSDA5Q8qHImIiFwgBaTKriDX7HeUkw71OkDsM1ZXJCIiUukpIFV2P46G/avNhUzvfA/cPa2uSEREpNJTQKrM1n8BK143r9/+OgQ2sLQcERGRqkIBqbI6vB2+PD4t+5WPQLPym25dRESkulFAqozyc2DOIMg7ChGXw3Wjra5IRESkSlFAqozmPwlJf0ONWubaXG4e536MiIiIlJjlAenVV18lMjISb29vYmJiWLFixRn3Xb9+Pb179yYyMhKbzcaUKVOK7XPivqKXhx56yLVPly5dit3/f//3f+Xx8sre2jmw6l3ABne8CQH1rK5IRESkyrE0IM2ePZsRI0YwduxYVq9eTZs2bejRo8cZV+jNzs6mUaNGTJgwgTp16px2n5UrV3LgwAHXZcGCBQDceeedhfa79957C+03ceLEsn1x5eHgFvj6EfP6NY9Dk27W1iMiIlJFWRqQJk+ezL333suQIUNo2bIlM2bMoEaNGrzzzjun3b9jx468+OKL9O/fHy8vr9PuU7t2berUqeO6fPPNNzRu3Jhrr7220H41atQotF+FmA37bPKyzX5H+VkQeTV0GWV1RSIiImUiMjLytGeFrGRZQMrLy2PVqlXExsaeLMZuJzY2lmXLlpXZc3z00Ufcfffd2IqsWzVz5kxCQkK47LLLGDVqFNnZ2Wc9Vm5uLhkZGYUuF9V3T0DKBvANhd5vg93t4j6/iIhINeJu1RMfOnQIh8NBWFhYoe1hYWFs2rSpTJ7jiy++IC0tjcGDBxfa/o9//IOGDRsSHh7O2rVrGTlyJJs3b2bu3LlnPFZ8fDzPPGPRLNV/zoQ1H4HNDn3eBv+wcz9GREREzpvlnbTL09tvv03Pnj0JDw8vtP2+++6jR48etGrVioEDB/LBBx8wb948tm/ffsZjjRo1ivT0dNdlz5495V2+KXkDfPuYeb3LKIi65uI8r4iISAm88cYbhIeH43Q6C22/9dZbufvuu9m+fTu33norYWFh+Pn50bFjRxYuXGhRtSVnWUAKCQnBzc2N5OTkQtuTk5PP2AG7NHbv3s3ChQv517/+dc59Y2JiANi2bdsZ9/Hy8qJmzZqFLuUuN9Psd1RwDBpfB1c/Xv7PKSIiFYdhQF6WNRfDKFGJd955J4cPH2bRokWubampqcyfP5+BAweSmZnJjTfeSEJCAn/++Sc33HADvXr1IjExsbzetTJh2Sk2T09POnToQEJCArfddhsATqeThIQEhg4desHHf/fddwkNDeWmm246575r1qwBoG7duhf8vGXGMOCbR+HQFvAPN4f026t0g5+IiBSVnw3Ph597v/Lw1H7w9D3nbkFBQfTs2ZOPP/6Ybt3M0dWfffYZISEhdO3aFbvdTps2bVz7jx8/nnnz5vHVV1+Vyfd9ebH0G3fEiBG8+eabvP/++2zcuJEHHniArKwshgwZAkBcXByjRp0crZWXl8eaNWtYs2YNeXl57Nu3jzVr1hRr+XE6nbz77rsMGjQId/fCGXD79u2MHz+eVatWsWvXLr766ivi4uK45ppraN26dfm/6JJa9R78PQdsbuZkkL4hVlckIiJyWgMHDuTzzz8nNzcXMAdC9e/fH7vdTmZmJo8//jgtWrQgMDAQPz8/Nm7cqBaks+nXrx8HDx5kzJgxJCUl0bZtW+bPn+/quJ2YmIj9lFaT/fv3065dO9ftSZMmMWnSJK699loWL17s2r5w4UISExO5++67iz2np6cnCxcuZMqUKWRlZREREUHv3r35z3/+U34vtLQO/AXfjzSvdxsDDTtbW4+IiFjDo4bZkmPVc5dQr169MAyDb7/9lo4dO/Lzzz/zv//9D4DHH3+cBQsWMGnSJJo0aYKPjw99+vQhLy+vvCovE5YGJIChQ4eesYnt1NAD5jwJRgnOiV5//fVn3C8iIoIlS5aUus6LJicd5gwGRy407QFXPGx1RSIiYhWbrUSnuazm7e3NHXfcwcyZM9m2bRvNmjWjffv2APz6668MHjyY22+/HYDMzEx27dplYbUlY3lAklMYBnw1DFJ3QEAE3D5D/Y5ERKRSGDhwIDfffDPr16/nrrvucm1v2rQpc+fOpVevXthsNkaPHl1sxFtFpG/fisRZAN4BYHeHPu9CjWCrKxIRESmR6667juDgYDZv3sw//vEP1/bJkycTFBTEFVdcQa9evejRo4erdakisxklOWclxWRkZBAQEEB6enrZD/k/uAVqX1K2xxQRkQotJyeHnTt3EhUVhbe3t9XlVGpney9L+v2tFqSKSOFIRETEUgpIIiIiIkUoIImIiIgUoYAkIiIiUoQCkoiIiEgRCkgiIiIViAaXX7iyeA8VkERERCoADw8PALKzsy2upPI78R6eeE/Ph2bSFhERqQDc3NwIDAwkJSUFgBo1amCz2SyuqnIxDIPs7GxSUlIIDAzEzc3tvI+lgCQiIlJB1KlTB8AVkuT8BAYGut7L86WAJCIiUkHYbDbq1q1LaGgo+fn5VpdTKXl4eFxQy9EJCkgiIiIVjJubW5l8ycv5UydtERERkSIUkERERESKUEASERERKUJ9kM7TiUmoMjIyLK5ERERESurE9/a5JpNUQDpPR48eBSAiIsLiSkRERKS0jh49SkBAwBnvtxma0/y8OJ1O9u/fj7+/f5lO5JWRkUFERAR79uyhZs2aZXbcyk7vS3F6T4rTe3J6el+K03tyetXhfTEMg6NHjxIeHo7dfuaeRmpBOk92u5369euX2/Fr1qxZZX84L4Tel+L0nhSn9+T09L4Up/fk9Kr6+3K2lqMT1ElbREREpAgFJBEREZEiFJAqGC8vL8aOHYuXl5fVpVQoel+K03tSnN6T09P7Upzek9PT+3KSOmmLiIiIFKEWJBEREZEiFJBEREREilBAEhERESlCAUlERESkCAWkCubVV18lMjISb29vYmJiWLFihdUlWSY+Pp6OHTvi7+9PaGgot912G5s3b7a6rAplwoQJ2Gw2Hn30UatLsdy+ffu46667qFWrFj4+PrRq1Yo//vjD6rIs43A4GD16NFFRUfj4+NC4cWPGjx9/zvWnqpqlS5fSq1cvwsPDsdlsfPHFF4XuNwyDMWPGULduXXx8fIiNjWXr1q3WFHuRnO09yc/PZ+TIkbRq1QpfX1/Cw8OJi4tj//791hVsEQWkCmT27NmMGDGCsWPHsnr1atq0aUOPHj1ISUmxujRLLFmyhIceeojff/+dBQsWkJ+fz/XXX09WVpbVpVUIK1eu5PXXX6d169ZWl2K5I0eOcOWVV+Lh4cH333/Phg0beOmllwgKCrK6NMu88MILTJ8+nWnTprFx40ZeeOEFJk6cyCuvvGJ1aRdVVlYWbdq04dVXXz3t/RMnTmTq1KnMmDGD5cuX4+vrS48ePcjJybnIlV48Z3tPsrOzWb16NaNHj2b16tXMnTuXzZs3c8stt1hQqcUMqTA6depkPPTQQ67bDofDCA8PN+Lj4y2squJISUkxAGPJkiVWl2K5o0ePGk2bNjUWLFhgXHvttcYjjzxidUmWGjlypHHVVVdZXUaFctNNNxl33313oW133HGHMXDgQIsqsh5gzJs3z3Xb6XQaderUMV588UXXtrS0NMPLy8v45JNPLKjw4iv6npzOihUrDMDYvXv3xSmqglALUgWRl5fHqlWriI2NdW2z2+3ExsaybNkyCyurONLT0wEIDg62uBLrPfTQQ9x0002Ffl6qs6+++oro6GjuvPNOQkNDadeuHW+++abVZVnqiiuuICEhgS1btgDw119/8csvv9CzZ0+LK6s4du7cSVJSUqHfo4CAAGJiYvS5e4r09HRsNhuBgYFWl3JRabHaCuLQoUM4HA7CwsIKbQ8LC2PTpk0WVVVxOJ1OHn30Ua688kouu+wyq8ux1KxZs1i9ejUrV660upQKY8eOHUyfPp0RI0bw1FNPsXLlSh5++GE8PT0ZNGiQ1eVZ4sknnyQjI4PmzZvj5uaGw+HgueeeY+DAgVaXVmEkJSUBnPZz98R91V1OTg4jR45kwIABVXrx2tNRQJJK4aGHHmLdunX88ssvVpdiqT179vDII4+wYMECvL29rS6nwnA6nURHR/P8888D0K5dO9atW8eMGTOqbUD69NNPmTlzJh9//DGXXnopa9as4dFHHyU8PLzavidSOvn5+fTt2xfDMJg+fbrV5Vx0OsVWQYSEhODm5kZycnKh7cnJydSpU8eiqiqGoUOH8s0337Bo0SLq169vdTmWWrVqFSkpKbRv3x53d3fc3d1ZsmQJU6dOxd3dHYfDYXWJlqhbty4tW7YstK1FixYkJiZaVJH1nnjiCZ588kn69+9Pq1at+Oc//8nw4cOJj4+3urQK48Rnqz53izsRjnbv3s2CBQuqXesRKCBVGJ6ennTo0IGEhATXNqfTSUJCAp07d7awMusYhsHQoUOZN28eP/30E1FRUVaXZLlu3brx999/s2bNGtclOjqagQMHsmbNGtzc3Kwu0RJXXnllsSkgtmzZQsOGDS2qyHrZ2dnY7YU/4t3c3HA6nRZVVPFERUVRp06dQp+7GRkZLF++vNp+7sLJcLR161YWLlxIrVq1rC7JEjrFVoGMGDGCQYMGER0dTadOnZgyZQpZWVkMGTLE6tIs8dBDD/Hxxx/z5Zdf4u/v7+oTEBAQgI+Pj8XVWcPf379YHyxfX19q1apVrftmDR8+nCuuuILnn3+evn37smLFCt544w3eeOMNq0uzTK9evXjuuedo0KABl156KX/++SeTJ0/m7rvvtrq0iyozM5Nt27a5bu/cuZM1a9YQHBxMgwYNePTRR/nvf/9L06ZNiYqKYvTo0YSHh3PbbbdZV3Q5O9t7UrduXfr06cPq1av55ptvcDgcrs/e4OBgPD09rSr74rN6GJ0U9sorrxgNGjQwPD09jU6dOhm///671SVZBjjt5d1337W6tApFw/xNX3/9tXHZZZcZXl5eRvPmzY033njD6pIslZGRYTzyyCNGgwYNDG9vb6NRo0bG008/beTm5lpd2kW1aNGi036ODBo0yDAMc6j/6NGjjbCwMMPLy8vo1q2bsXnzZmuLLmdne0927tx5xs/eRYsWWV36RWUzjGo2raqIiIjIOagPkoiIiEgRCkgiIiIiRSggiYiIiBShgCQiIiJShAKSiIiISBEKSCIiIiJFKCCJiIiIFKGAJCJSBhYvXozNZiMtLc3qUkSkDCggiYiIiBShgCQiIiJShAKSiFQJTqeT+Ph4oqKi8PHxoU2bNnz22WfAydNf3377La1bt8bb25vLL7+cdevWFTrG559/zqWXXoqXlxeRkZG89NJLhe7Pzc1l5MiRRERE4OXlRZMmTXj77bcL7bNq1Sqio6OpUaMGV1xxBZs3by7fFy4i5UIBSUSqhPj4eD744ANmzJjB+vXrGT58OHfddRdLlixx7fPEE0/w0ksvsXLlSmrXrk2vXr3Iz88HzGDTt29f+vfvz99//824ceMYPXo07733nuvxcXFxfPLJJ0ydOpWNGzfy+uuv4+fnV6iOp59+mpdeeok//vgDd3d37r777ovy+kWkbGmxWhGp9HJzcwkODmbhwoV07tzZtf1f//oX2dnZ3HfffXTt2pVZs2bRr18/AFJTU6lfvz7vvfceffv2ZeDAgRw8eJAff/zR9fh///vffPvtt6xfv54tW7bQrFkzFixYQGxsbLEaFi9eTNeuXVm4cCHdunUD4LvvvuOmm27i2LFjeHt7l/O7ICJlSS1IIlLpbdu2jezsbLp3746fn5/r8sEHH7B9+3bXfqeGp+DgYJo1a8bGjRsB2LhxI1deeWWh41555ZVs3boVh8PBmjVrcHNz49prrz1rLa1bt3Zdr1u3LgApKSkX/BpF5OJyt7oAEZELlZmZCcC3335LvXr1Ct3n5eVVKCSdLx8fnxLt5+Hh4bpus9kAs3+UiFQuakESkUqvZcuWeHl5kZiYSJMmTQpdIiIiXPv9/vvvrutHjhxhy5YttGjRAoAWLVrw66+/Fjrur7/+yiWXXIKbmxutWrXC6XQW6tMkIlWXWpBEpNLz9/fn8ccfZ/jw4TidTq666irS09P59ddfqVmzJg0bNgTg2WefpVatWoSFhfH0008TEhLCbbfdBsBjjz1Gx44dGT9+PP369WPZsmVMmzaN1157DYDIyEgGDRrE3XffzdSpU2nTpg27d+8mJSWFvn37WvXSRaScKCCJSJUwfvx4ateuTXx8PDt27CAwMJD27dvz1FNPuU5xTZgwgUceeYStW7fStm1bvv76azw9PQFo3749n376KWPGjGH8+PHUrVuXZ599lsGDB7ueY/r06Tz11FM8+OCDHD58mAYNGvDUU09Z8XJFpJxpFJuIVHknRpgdOXKEwMBAq8sRkUpAfZBEREREilBAEhERESlCp9hEREREilALkoiIiEgRCkgiIiIiRSggiYiIiBShgCQiIiJShAKSiIiISBEKSCIiIiJFKCCJiIiIFKGAJCIiIlKEApKIiIhIEf8PTiOLuJTGUvIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_accs)\n",
        "plt.plot(val_accs)\n",
        "plt.title('Accuracy plots')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "#plt.show()\n",
        "\n",
        "plt.savefig('accuracy.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def get_image_loader():\n",
        "    'Generates one sample of data'\n",
        "    jig_size = 4\n",
        "\n",
        "\n",
        "    data_transform = transforms.Compose([\n",
        "        # transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Select sample\n",
        "    file_path = \"extraimages-turkey/turkey.jpg\"\n",
        "    pil_image = Image.open(file_path)\n",
        "\n",
        "    # Convert image to torch tensor\n",
        "    pil_image = pil_image.resize((256, 256))\n",
        "    new_size = 256 - (256 % jig_size) # Ensure that the number of pixels fits the number of jigsaw pieces\n",
        "    pil_image = crop_from_center(pil_image, new_size, new_size)\n",
        "    solution_tensor = data_transform(pil_image)\n",
        "\n",
        "    # Split image into tiles (patches)\n",
        "    crops = get_several_crops(pil_image, jig_size)\n",
        "\n",
        "    # Generate a rotation sequence\n",
        "    rot_config = np.random.randint(4, size=jig_size ** 2)\n",
        "\n",
        "    # Find a single patch in the image\n",
        "    rand_pos = np.random.randint(jig_size ** 2)\n",
        "    rand_rot = np.random.randint(4) # Set to 0 for debugging purposes\n",
        "    patch_im = crops[rand_pos]\n",
        "    patch_im = rotate(patch_im, rand_rot * 90)\n",
        "    patch_tensor = data_transform(patch_im)\n",
        "    pad_size_right = solution_tensor.shape[2] - patch_tensor.shape[2]\n",
        "    pad_size_bottom = solution_tensor.shape[1] - patch_tensor.shape[1]\n",
        "    patch_tensor_extended = torch.nn.functional.pad(patch_tensor, (0, pad_size_right, 0, pad_size_bottom))\n",
        "\n",
        "    # Concanate selected patch along channel to form a 6 channel image\n",
        "    original_plus_patch = torch.cat((solution_tensor, patch_tensor_extended), dim=0)\n",
        "\n",
        "    print(patch_im)\n",
        "\n",
        "\n",
        "    return original_plus_patch, rand_pos, rand_rot, patch_im, pil_image\n",
        "\n",
        "\n",
        "\n",
        "model = PretrainedResNet()       # create an *uninitialized* instance\n",
        "state = torch.load(\"resnet_jigsaw_solver_e1_js_trained.pt\", map_location=\"cpu\")\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "sing_im, pos, rot, patch, solution = get_image_loader()\n",
        "print(f\"Solution is {pos} and {rot}\")\n",
        "plt.subplot(1, 2, 1)\n",
        "# plt.axis((0, 64*4, 0, 64*4))\n",
        "plt.imshow(solution)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(patch)\n",
        "sing_im = sing_im.unsqueeze(0).to(device)\n",
        "pos_out, rot_out = model(sing_im)\n",
        "pos_pred = pos_out.argmax(dim=1)\n",
        "rot_pred = rot_out.argmax(dim=1)\n",
        "print(pos_pred, rot_pred)\n",
        "print(pos_out, rot_out)\n"
      ],
      "metadata": {
        "id": "HhAPPGK8kVHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "num_outputs = num_permuts_saved\n",
        "siamese_deg = jigsaw_puzzle_size ** 2\n",
        "\n",
        "# Use same transforms as training\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.RandomCrop((64, 64)),\n",
        "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "data_loader = GetDataset([\"mountain_Solution.jpg\"], [None], transform=data_transform)\n",
        "jig_loader = GetJigsawPuzzleDataset([\"mountain_Solution.jpg\"], 'selected_permuts.npy', transform=data_transform, jig_size=jigsaw_puzzle_size)\n",
        "\n",
        "\n",
        "model = resnet18(num_classes=num_outputs, siamese_deg=siamese_deg, jigsaw_size=jigsaw_puzzle_size)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"resnet_jigsaw_solver_e1_js_trained.pt\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "X, y = jig_loader[0]\n",
        "X = X.unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model(X)\n",
        "\n",
        "print(\"Output shape: \", output.shape)\n",
        "out_im = transforms.functional.to_pil_image(output)\n",
        "\n",
        "out_im.show()\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "t7bPiDL4x2ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqvSlGHSiTpW"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    pil_img = Image.open(path)\n",
        "    if pil_img.mode == \"L\":\n",
        "        return None\n",
        "    else:\n",
        "        return pil_img\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "    Cmodel_name = 'resnet_trained_ssl_e1_last_b_last_b_ft.pt'\n",
        "    Ctest_compact_bilinear = True\n",
        "    Ctest_imagenet_based = False\n",
        "    Ctest_on = 'test'\n",
        "\n",
        "    # Set device to use to gpu if available and declare model_file_path\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #par_weights_dir = 'weights/'\n",
        "    model_file_path = Cmodel_name\n",
        "\n",
        "    # Data loading and data generators set up\n",
        "    train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels = \\\n",
        "        get_train_test_file_paths_n_labels()\n",
        "\n",
        "    train_image_ids, val_image_ids, train_file_paths, val_file_paths, train_labels, val_labels = \\\n",
        "        split_train_into_train_val(train_image_ids, train_file_paths, train_labels, test_size=0.1)\n",
        "\n",
        "    if Ctest_imagenet_based:\n",
        "        model_to_train = models.resnet18(pretrained=True)\n",
        "        model_to_train.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
        "        model_to_train.fc = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 5),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "    else:\n",
        "        model_to_train = resnet18(num_classes=5, siamese_deg=None, jigsaw_size=jigsaw_puzzle_size)\n",
        "\n",
        "    # Check if saved model exists, and load if it does.\n",
        "    if os.path.exists(model_file_path):\n",
        "        model_to_train.load_state_dict(torch.load(model_file_path))\n",
        "    model_to_train.to(device)\n",
        "\n",
        "    # Setup on which set evaluation is to be carried out\n",
        "    if Ctest_on == 'train':\n",
        "        eval_file_paths, eval_labels = train_file_paths, train_labels\n",
        "    elif Ctest_on == 'val':\n",
        "        eval_file_paths, eval_labels = val_file_paths, val_labels\n",
        "    else:\n",
        "        eval_file_paths, eval_labels = test_file_paths, test_labels\n",
        "\n",
        "    # Start evaluation\n",
        "    model_to_train.eval()\n",
        "    correct = 0\n",
        "    preds = []\n",
        "    for f, label in zip(eval_file_paths, eval_labels):\n",
        "        pil_img = pil_loader(f)\n",
        "        if pil_img is None:\n",
        "            preds.append(0)\n",
        "            continue\n",
        "        data = def_data_transform(pil_img)\n",
        "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
        "        data = Variable(data, volatile=True).to(device)\n",
        "        output = model_to_train(data)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "\n",
        "        x = pred.data #prediction\n",
        "        preds.append(x)\n",
        "\n",
        "        if x == label:\n",
        "            correct += 1\n",
        "\n",
        "    print (correct, len(eval_file_paths), correct * 100 / len(eval_file_paths))\n",
        "    preds = np.array(preds).astype(np.float64)\n",
        "    conf_mat = np.array(confusion_matrix(preds, eval_labels))\n",
        "    conf_df = pd.DataFrame(conf_mat)\n",
        "    conf_df.columns = np.arange(0,5)\n",
        "    conf_df.to_csv('confusion_matrix.csv')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}