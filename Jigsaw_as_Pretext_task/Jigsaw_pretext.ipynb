{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Jigsaw solver\n"
      ],
      "metadata": {
        "id": "a1TZOBhM0pjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This method predicts the position and rotation of individual tiles"
      ],
      "metadata": {
        "id": "ynWaFV649NOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Drive"
      ],
      "metadata": {
        "id": "chonjepOFjj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from matplotlib import pyplot as plt\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjy-678oFjWa",
        "outputId": "98f96263-78af-40c1-acb5-058728cb3085"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLA-NhdviTpN"
      },
      "source": [
        "# Generate permutations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jigsaw_puzzle_size = 4\n",
        "num_permuts_saved = 10000\n",
        "images_dir =  \"/content/drive/MyDrive/Final Project/Temp2\""
      ],
      "metadata": {
        "id": "wjgwzfjuoZD5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4vvH8PQ3x1u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8Khk-czxiTpP"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy.spatial.distance import hamming\n",
        "\n",
        "# Build list of permutations such that each position is equally likely for each piece\n",
        "piece_indicies = [i for i in range(jigsaw_puzzle_size ** 2)]\n",
        "num_permuts = num_permuts_saved\n",
        "permuts = np.zeros((num_permuts_saved, jigsaw_puzzle_size ** 2), dtype=np.long)\n",
        "permuts_hash = {}\n",
        "count = 0\n",
        "while count < num_permuts:\n",
        "  x = np.array(np.random.permutation(piece_indicies))\n",
        "  y = np.array(np.random.permutation(piece_indicies), dtype=np.int32)\n",
        "  hd = hamming(x, y) > 0.9\n",
        "  x_hashcode = np.sum([10**(-1 * i) * x[i] for i in range(len(x))])\n",
        "  y_hashcode = np.sum([10**(-1 * i) * y[i] for i in range(len(y))])\n",
        "  if hd > 0.9 and (not x_hashcode in permuts_hash) and (not y_hashcode in permuts_hash):\n",
        "    permuts[count] = x\n",
        "    permuts[count + 1] = y\n",
        "    permuts_hash[x_hashcode] = True\n",
        "    permuts_hash[y_hashcode] = True\n",
        "    count = count + 2\n",
        "\n",
        "\n",
        "\n",
        "# Build the array for selected permutation indices above\n",
        "np.save('selected_permuts.npy', permuts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xQj55rQfiTpQ"
      },
      "outputs": [],
      "source": [
        "from ctypes import ArgumentError\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "\n",
        "def_data_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "hflip_data_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=1.0),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "darkness_jitter_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ColorJitter(brightness=[0.5, 0.9]),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "lightness_jitter_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ColorJitter(brightness=[1.1, 1.5]),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "rotations_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "all_in_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "def crop_from_center(pil_image, new_h, new_w):\n",
        "\n",
        "    width, height = pil_image.size  # Get dimensions\n",
        "\n",
        "    left = (width - new_w) / 2\n",
        "    top = (height - new_h) / 2\n",
        "    right = (width + new_w) / 2\n",
        "    bottom = (height + new_h) / 2\n",
        "\n",
        "    # Crop the center of the image\n",
        "    pil_image = pil_image.crop((left, top, right, bottom))\n",
        "\n",
        "    return pil_image\n",
        "\n",
        "\n",
        "def get_nine_crops(pil_image):\n",
        "    \"\"\"\n",
        "    Get nine crops for a square pillow image. That is height and width of the image should be same.\n",
        "    :param pil_image: pillow image\n",
        "    :return: List of pillow images. The nine crops\n",
        "    \"\"\"\n",
        "    w, h = pil_image.size\n",
        "    diff = int(w/3)\n",
        "\n",
        "    r_vals = [0, diff, 2 * diff]\n",
        "    c_vals = [0, diff, 2 * diff]\n",
        "\n",
        "    list_patches = []\n",
        "\n",
        "    for r in r_vals:\n",
        "        for c in c_vals:\n",
        "\n",
        "            left = c\n",
        "            top = r\n",
        "            right = c + diff\n",
        "            bottom = r + diff\n",
        "\n",
        "            patch = pil_image.crop((left, top, right, bottom))\n",
        "            list_patches.append(patch)\n",
        "\n",
        "    return list_patches\n",
        "\n",
        "\n",
        "def get_several_crops(pil_image, jig_size):\n",
        "    \"\"\"\n",
        "    Get several crops for a square pillow image. That is height and width of the image should be same.\n",
        "    :param pil_image: pillow image\n",
        "    :param jig_size: number of rows and columns for jigsaw\n",
        "    :return: List of pillow images. The nine crops\n",
        "    \"\"\"\n",
        "    w, h = pil_image.size\n",
        "    diff = int(w/jig_size)\n",
        "\n",
        "    r_vals = [i * diff for i in range(jig_size)]\n",
        "    c_vals = [i * diff for i in range(jig_size)]\n",
        "\n",
        "    list_patches = []\n",
        "\n",
        "    for r in r_vals:\n",
        "        for c in c_vals:\n",
        "\n",
        "            left = c\n",
        "            top = r\n",
        "            right = c + diff\n",
        "            bottom = r + diff\n",
        "\n",
        "            patch = pil_image.crop((left, top, right, bottom))\n",
        "            list_patches.append(patch)\n",
        "\n",
        "    return list_patches\n",
        "\n",
        "\n",
        "def split_train_into_train_val(train_file_ids, train_file_paths, train_labels, test_size=0.1):\n",
        "    \"\"\"\n",
        "    Split train_file_paths and train_labels to train_file_paths, val_file_paths and\n",
        "    train_labels, val_labels\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a mapping between image_id and file_path\n",
        "    image_id_name_map = dict(zip(train_file_ids, train_file_paths))\n",
        "\n",
        "    # Get validation files and validation labels separate\n",
        "    train_file_ids, val_file_ids, train_labels, val_labels = train_test_split(\n",
        "        train_file_ids, train_labels, test_size=test_size, random_state=5, shuffle=True\n",
        "    )\n",
        "    train_file_paths = [image_id_name_map[image_id] for image_id in train_file_ids]\n",
        "    val_file_paths = [image_id_name_map[image_id] for image_id in val_file_ids]\n",
        "\n",
        "    print (\"Length of train files list\", len(train_file_paths))\n",
        "    print (\"Length of train labels\", len(train_labels))\n",
        "    print (\"Length of val files list\", len(val_file_paths))\n",
        "    print (\"Length of val labels\", len(val_labels))\n",
        "\n",
        "    return train_file_ids, val_file_ids, train_file_paths, val_file_paths, train_labels, val_labels\n",
        "\n",
        "def get_paths():\n",
        "    data_dir = images_dir\n",
        "    file_paths_to_return = []\n",
        "\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(\".jpg\"):\n",
        "                file_paths_to_return.append(data_dir+'/'+file)\n",
        "\n",
        "    if len(file_paths_to_return) == 0:\n",
        "      raise ArgumentError(\"Data was not found. Ensure that a data folder is present\")\n",
        "\n",
        "    return file_paths_to_return\n",
        "\n",
        "def get_train_test_file_paths_n_labels():\n",
        "    \"\"\"\n",
        "    Get array train_file_paths, train_labels, test_file_paths and test_labels\n",
        "    \"\"\"\n",
        "\n",
        "    # Data loading and data generators set up\n",
        "    #par_data_dir = 'train'\n",
        "    images_data_dir = 'train'\n",
        "    train_test_split_file = 'train_test_split.txt'\n",
        "    images_file = 'images.txt'\n",
        "    labels_file = 'image_class_labels.txt'\n",
        "\n",
        "    # Read the images_file which stores image-id and image-name mapping\n",
        "    image_file_id_df = pd.read_csv(images_file, sep=' ', header=None)\n",
        "    image_file_id_mat = image_file_id_df.values\n",
        "    image_id_name_map = dict(zip(image_file_id_mat[:, 0], image_file_id_mat[:, 1]))\n",
        "\n",
        "    # Read the train_test_split file which stores image-id and train-test split mapping\n",
        "    image_id_train_test_split_df = pd.read_csv(train_test_split_file, sep=' ', header=None)\n",
        "    image_id_train_test_split_mat = image_id_train_test_split_df.values\n",
        "    image_id_train_test_split_map = dict(zip(image_id_train_test_split_mat[:, 0],\n",
        "                                             image_id_train_test_split_mat[:, 1]))\n",
        "\n",
        "    # Read the image class labels file\n",
        "    image_id_label_df = pd.read_csv(labels_file, sep=' ', header=None)\n",
        "    image_id_label_mat = image_id_label_df.values\n",
        "    image_id_label_map = dict(zip(image_id_label_mat[:, 0], image_id_label_mat[:, 1]))\n",
        "\n",
        "    # Put together train_files train_labels test_files and test_labels lists\n",
        "    train_image_ids, test_image_ids = [], []\n",
        "    train_file_paths, test_file_paths = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    for file_id in image_id_name_map.keys():\n",
        "        file_name = image_id_name_map[file_id]\n",
        "        is_train = image_id_train_test_split_map[file_id]\n",
        "        label = image_id_label_map[file_id] - 1  # To ensure labels start from 0\n",
        "\n",
        "        if is_train:\n",
        "            train_image_ids.append(file_id)\n",
        "            train_file_paths.append(os.path.join(images_data_dir, file_name))\n",
        "            train_labels.append(label)\n",
        "        else:\n",
        "            test_image_ids.append(file_id)\n",
        "            test_file_paths.append(os.path.join(images_data_dir, file_name))\n",
        "            test_labels.append(label)\n",
        "\n",
        "    print (\"Length of train files list\", len(train_file_paths))\n",
        "    print (\"Length of train labels list\", len(train_labels))\n",
        "    print (\"Length of test files list\", len(test_file_paths))\n",
        "    print (\"Length of test labels list\", len(test_labels))\n",
        "\n",
        "    return train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpAZGXKmiTpR"
      },
      "source": [
        "# Generate Jigsaw from permutations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sm_sOs8piTpR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms.functional import rotate\n",
        "import torch.nn.functional\n",
        "\n",
        "\n",
        "class GetDataset(Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        'Initialization'\n",
        "        self.imgs = [(img_path, label) for img_path, label in zip(file_paths, labels)]\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "\n",
        "        # Select sample\n",
        "        file_path = self.file_paths[index]\n",
        "        label = self.labels[index]\n",
        "        pil_image = Image.open(file_path)\n",
        "\n",
        "        # Check if image has only single channel. If True, then swap with 0th image\n",
        "        # Assumption 0th image has got 3 number of channels\n",
        "        if len(pil_image.getbands()) != 3:\n",
        "            file_path = self.file_paths[0]\n",
        "            label = self.labels[0]\n",
        "            pil_image = Image.open(file_path)\n",
        "\n",
        "        # Convert image to torch tensor\n",
        "        tr_image = self.transform(pil_image)\n",
        "\n",
        "        return tr_image, label\n",
        "\n",
        "\n",
        "class GetJigsawPuzzleDataset(Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, file_paths, avail_permuts_file_path, range_permut_indices=None, jig_size=4):\n",
        "        'Initialization'\n",
        "        self.file_paths = file_paths\n",
        "        self.permuts_avail = np.load(avail_permuts_file_path)\n",
        "        self.jig_size = jig_size\n",
        "        if range_permut_indices != None:\n",
        "          self.range_permut_indices = range_permut_indices\n",
        "        else:\n",
        "          self.range_permut_indices = (0, len(self.permuts_avail) - 1)\n",
        "\n",
        "\n",
        "        self.data_transform = transforms.Compose([\n",
        "            # transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        self.size = len(self.file_paths) * (self.jig_size ** 2) * 4\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        num_tiles = self.jig_size ** 2\n",
        "        num_rotations = 4\n",
        "        file_index = index // (num_tiles * num_rotations)\n",
        "        rest = index % (num_tiles * num_rotations)\n",
        "        rotation_index = rest // num_tiles\n",
        "        patch_index = rest % num_tiles\n",
        "\n",
        "        # Select sample\n",
        "        file_path = self.file_paths[file_index]\n",
        "        pil_image = Image.open(file_path)\n",
        "\n",
        "        # Check if image has only single channel. If True, then swap with 0th image\n",
        "        # Assumption 0th image has got 3 number of channels\n",
        "        if len(pil_image.getbands()) != 3:\n",
        "            file_path = self.file_paths[0]\n",
        "            pil_image = Image.open(file_path)\n",
        "\n",
        "        # Convert image to torch tensor\n",
        "        pil_image = pil_image.resize((256, 256))\n",
        "        new_size = 256 - (256 % self.jig_size) # Ensure that the number of pixels fits the number of jigsaw pieces\n",
        "        pil_image = crop_from_center(pil_image, new_size, new_size)\n",
        "        solution_tensor = self.data_transform(pil_image)\n",
        "\n",
        "        # Split image into tiles (patches)\n",
        "        crops = get_several_crops(pil_image, self.jig_size)\n",
        "\n",
        "        # Generate a rotation sequence\n",
        "        rot_config = np.random.randint(4, size=self.jig_size ** 2)\n",
        "\n",
        "        # Find a single patch in the image and transform\n",
        "        patch_im = crops[patch_index]\n",
        "        patch_tensor = self.data_transform(patch_im)\n",
        "        patch_tensor = rotate(patch_tensor, 90 * rotation_index)\n",
        "\n",
        "        pad_size_right = solution_tensor.shape[2] - patch_tensor.shape[2]\n",
        "        pad_size_bottom = solution_tensor.shape[1] - patch_tensor.shape[1]\n",
        "        patch_tensor_extended = torch.nn.functional.pad(patch_tensor, (0, pad_size_right, 0, pad_size_bottom))\n",
        "\n",
        "        # Concanate selected patch along channel to form a 6 channel image\n",
        "        original_plus_patch = torch.cat((solution_tensor, patch_tensor_extended), dim=0)\n",
        "\n",
        "\n",
        "        return original_plus_patch, patch_index, rotation_index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itXKzIqhiTpT"
      },
      "source": [
        "# Defining Resnet model\n",
        "Credit: https://github.com/aniket03/self_supervised_bird_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BEYNDi47iTpT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, jigsaw_size=3, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None, siamese_deg=9, train_contrastive=False):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.siamese_deg = siamese_deg\n",
        "        self.train_contrastive = train_contrastive\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
        "\n",
        "        self.pos_head = nn.Linear(2048 * block.expansion, jigsaw_size ** 2)\n",
        "        self.rot_head = nn.Linear(2048 * block.expansion, 4)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def get_feature_vectors(self, input_batch):\n",
        "        # Each input_batch would be of shape (batch_size, color_channels, h, w)\n",
        "        x = self.conv1(input_batch)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input_batch):\n",
        "        B, N, C, H, W = input_batch.shape\n",
        "        patch_features = []\n",
        "\n",
        "        for i in range(N):\n",
        "            feat = self.get_feature_vectors(input_batch[:, i, :, :, :])\n",
        "            patch_features.append(feat)\n",
        "        patch_features = torch.stack(patch_features, dim=1)  # [B, 9, feat_dim]\n",
        "\n",
        "        # Predict position and rotation for each patch\n",
        "        pos_logits = self.pos_head(patch_features)  # [B, 9, 9]\n",
        "        rot_logits = self.rot_head(patch_features)  # [B, 9, 4]\n",
        "\n",
        "        return pos_logits, rot_logits\n",
        "\n",
        "\n",
        "\n",
        "def _resnet(block, layers, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(**kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    \"\"\"\n",
        "    return _resnet(BasicBlock, [2, 2, 2, 2], **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and test"
      ],
      "metadata": {
        "id": "o20sbcY7fdYw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O02gxDG-iTpU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "\n",
        "def get_count_correct_preds(network_output, target):\n",
        "\n",
        "    output = network_output\n",
        "    pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "    pred.data = pred.data.view_as(target.data)\n",
        "    correct = target.eq(pred).sum().item()\n",
        "\n",
        "    return correct\n",
        "\n",
        "\n",
        "class ModelTrainTest():\n",
        "\n",
        "    def __init__(self, network, device, model_file_path, threshold=1e-4):\n",
        "        super(ModelTrainTest, self).__init__()\n",
        "        self.network = network\n",
        "        self.device = device\n",
        "        self.model_file_path = model_file_path\n",
        "        self.threshold = threshold\n",
        "        self.train_loss = 1e9\n",
        "        self.val_loss = 1e9\n",
        "\n",
        "    def train(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader):\n",
        "        self.network.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        cnt_batches = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
        "            data, target = Variable(data).to(self.device), Variable(target).to(self.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = self.network(data)\n",
        "\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "\n",
        "            clip_grad_norm_(self.network.parameters(), params_max_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            correct += get_count_correct_preds(output, target)\n",
        "            train_loss += loss.item()\n",
        "            cnt_batches += 1\n",
        "\n",
        "            del data, target, output\n",
        "\n",
        "        train_loss /= cnt_batches\n",
        "        val_loss, val_acc = self.test(epoch, val_data_loader)\n",
        "\n",
        "        if val_loss < self.val_loss - self.threshold:\n",
        "            self.val_loss = val_loss\n",
        "            torch.save(self.network.state_dict(), self.model_file_path)\n",
        "\n",
        "        train_acc = correct / len(train_data_loader.dataset)\n",
        "\n",
        "        print('\\nAfter epoch {} - Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, train_loss, correct, len(train_data_loader.dataset),\n",
        "            100. * correct / len(train_data_loader.dataset)))\n",
        "\n",
        "        return train_loss, train_acc, val_loss, val_acc\n",
        "\n",
        "\n",
        "\n",
        "    def test(self, epoch, test_data_loader):\n",
        "        self.network.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(test_data_loader):\n",
        "            data, target = Variable(data, volatile=True).to(self.device), Variable(target).to(self.device)\n",
        "            output = self.network(data)\n",
        "            test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
        "\n",
        "            correct += get_count_correct_preds(output, target)\n",
        "\n",
        "            del data, target, output\n",
        "\n",
        "        test_loss /= len(test_data_loader.dataset)\n",
        "        test_acc = correct / len(test_data_loader.dataset)\n",
        "        print('\\nAfter epoch {} - Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, test_loss, correct, len(test_data_loader.dataset),\n",
        "            100. * correct / len(test_data_loader.dataset)))\n",
        "\n",
        "        return  test_loss, test_acc\n",
        "\n",
        "\n",
        "class JigsawModelTrainTest():\n",
        "\n",
        "    def __init__(self, network, device, model_file_path, threshold=1e-4):\n",
        "        super(JigsawModelTrainTest, self).__init__()\n",
        "        self.network = network\n",
        "        self.device = device\n",
        "        self.model_file_path = model_file_path\n",
        "        self.threshold = threshold\n",
        "        self.train_loss = 1e9\n",
        "        self.val_loss = 1e9\n",
        "\n",
        "    def train(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader):\n",
        "        self.network.train()\n",
        "        train_loss = 0\n",
        "        cnt_batches = 0\n",
        "        pos_correct = 0\n",
        "        rot_correct = 0\n",
        "        total_pred_pos = 0\n",
        "        total_pred_rot = 0\n",
        "        batch_size = 0\n",
        "\n",
        "        for batch_idx, (data, pos_vector, rot_vector) in enumerate(train_data_loader):\n",
        "            data, pos_vector, rot_vector = Variable(data).to(self.device), Variable(pos_vector).to(self.device), Variable(rot_vector).to(self.device)\n",
        "            batch_size = data.shape[0]\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pos_log, rot_log = self.network(data)\n",
        "\n",
        "            pos_pred = pos_log.argmax(dim=1)  # Shape (B)\n",
        "            rot_pred = rot_log.argmax(dim=1)\n",
        "\n",
        "\n",
        "            loss_pos = F.cross_entropy(pos_log, pos_vector) # Shape (B, 9)\n",
        "            loss_rot = F.cross_entropy(rot_log, rot_vector)\n",
        "            loss = loss_pos + loss_rot\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            pos_correct += pos_pred.eq(pos_vector).sum() # Single number\n",
        "            rot_correct += rot_pred.eq(rot_vector).sum() # Single number\n",
        "            total_pred_pos += pos_pred.shape[0]\n",
        "            total_pred_rot += rot_pred.shape[0]\n",
        "            cnt_batches += 1\n",
        "\n",
        "            del data, pos_vector, rot_vector, pos_log, rot_log\n",
        "\n",
        "        train_loss /= cnt_batches\n",
        "        val_loss, val_acc = self.test(epoch, val_data_loader)\n",
        "\n",
        "        if val_loss < self.val_loss - self.threshold:\n",
        "            self.val_loss = val_loss\n",
        "            torch.save(self.network.state_dict(), self.model_file_path)\n",
        "\n",
        "        correct = (pos_correct + rot_correct)\n",
        "        total_pred = total_pred_pos\n",
        "\n",
        "        train_acc = correct / (total_pred_pos + total_pred_rot)\n",
        "\n",
        "        print('\\nAfter epoch {} - Train set: Number of batches: {}, Batch size: {}, Average loss: {:.4f}, Train accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, cnt_batches, batch_size, train_loss, correct, (total_pred_pos + total_pred_rot),\n",
        "            100. * train_acc))\n",
        "        print(f'Position accuracy: {pos_correct}/{total_pred_pos}, Rotation accuracy: {rot_correct}/{total_pred_rot}')\n",
        "\n",
        "\n",
        "\n",
        "        return train_loss, train_acc, val_loss, val_acc\n",
        "\n",
        "    def test(self, epoch, test_data_loader):\n",
        "        self.network.eval()\n",
        "        test_loss = 0\n",
        "        pos_correct = 0\n",
        "        rot_correct = 0\n",
        "        total_pred_pos = 0\n",
        "        total_pred_rot = 0\n",
        "        batch_size = 0\n",
        "        cnt_batches = 0\n",
        "\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, (data, pos_vector, rot_vector) in enumerate(test_data_loader):\n",
        "            data, pos_vector, rot_vector = Variable(data).to(self.device), Variable(pos_vector).to(self.device), Variable(rot_vector).to(self.device)\n",
        "            pos_log, rot_log = self.network(data)\n",
        "            batch_size = data.shape[0]\n",
        "\n",
        "            pos_log, rot_log = self.network(data)\n",
        "            pos_pred = pos_log.argmax(dim=1)\n",
        "            rot_pred = rot_log.argmax(dim=1)\n",
        "\n",
        "            loss_pos = F.cross_entropy(pos_log, pos_vector).item()\n",
        "            loss_rot = F.cross_entropy(rot_log, rot_vector).item()\n",
        "            test_loss += loss_pos + loss_rot\n",
        "\n",
        "\n",
        "            pos_correct += pos_pred.eq(pos_vector).sum() # Single number\n",
        "            rot_correct += rot_pred.eq(rot_vector).sum() # Single number\n",
        "\n",
        "\n",
        "            total_pred_pos += pos_pred.shape[0]\n",
        "            total_pred_rot += rot_pred.shape[0]\n",
        "            cnt_batches += 1\n",
        "\n",
        "\n",
        "            del data, pos_vector, rot_vector, pos_log, rot_log\n",
        "\n",
        "        correct = (pos_correct + rot_correct)\n",
        "        total_pred = total_pred_pos * cnt_batches\n",
        "\n",
        "        test_loss /= cnt_batches\n",
        "        test_acc = correct /  (total_pred_pos + total_pred_rot)\n",
        "        print('\\nAfter epoch {} - Test set: Number of batches: {}, Batch size: {}, Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, len(test_data_loader), batch_size, test_loss, correct, (total_pred_pos + total_pred_rot),\n",
        "            100. * test_acc))\n",
        "\n",
        "        return  test_loss, test_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use pretrained model"
      ],
      "metadata": {
        "id": "q4LcSIu5Q6p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "class PretrainedResNet(nn.Module):\n",
        "    def __init__(self, num_positions=16):\n",
        "        super().__init__()\n",
        "        # Use 6 input channels instead of 3\n",
        "        self.backbone = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Set requires_grad to False\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        old_conv = self.backbone.conv1\n",
        "\n",
        "        self.backbone.conv1 = nn.Conv2d(\n",
        "            in_channels=6,\n",
        "            out_channels=old_conv.out_channels,\n",
        "            kernel_size=old_conv.kernel_size,\n",
        "            stride=old_conv.stride,\n",
        "            padding=old_conv.padding,\n",
        "            bias=old_conv.bias is not None\n",
        "        )\n",
        "\n",
        "        # Copy pretrained 3-channel weights into first 3 channels\n",
        "        with torch.no_grad():\n",
        "            self.backbone.conv1.weight[:, :3] = old_conv.weight\n",
        "\n",
        "\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        self.pos_head = nn.Linear(512, num_positions)  # classification\n",
        "        self.rot_head = nn.Linear(512, 4)              # 0째, 90째, 180째, 270째\n",
        "\n",
        "        self.pos_head.requires_grad = True\n",
        "        self.rot_head.requires_grad = True\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x)        # [B, 512]\n",
        "        pos = self.pos_head(f)      # [B, 16]\n",
        "        rot = self.rot_head(f)      # [B, 4]\n",
        "        return pos, rot"
      ],
      "metadata": {
        "id": "LIrdktKTQ57u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv25ckxKiTpV"
      },
      "source": [
        "# Jigsaw as pretext task training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qB6edlUIiTpV",
        "outputId": "bcebc8ca-189a-4682-d20e-347104094608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaders done\n",
            "Model ready\n",
            "Started training\n",
            "Epoch no 0 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4075a30>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4076c30>\n",
            "\n",
            "After epoch 0 - Test set: Number of batches: 272, Batch size: 4, Average loss: 4.2753, Accuracy: 425/2176 (20%)\n",
            "\n",
            "\n",
            "After epoch 0 - Train set: Number of batches: 272, Batch size: 4, Average loss: 4.3789, Train accuracy: 424/2176 (19%)\n",
            "\n",
            "Position accuracy: 109/1088, Rotation accuracy: 315/1088\n",
            "Train loss 4.378872131600099 \n",
            " Val loss 4.275274624938474 \n",
            " Train Acc 0.19485294818878174 \n",
            " Val Acc 0.1953125\n",
            "Epoch no 1 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4075a30>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4076c30>\n",
            "\n",
            "After epoch 1 - Test set: Number of batches: 272, Batch size: 4, Average loss: 3.0313, Accuracy: 918/2176 (42%)\n",
            "\n",
            "\n",
            "After epoch 1 - Train set: Number of batches: 272, Batch size: 4, Average loss: 3.7126, Train accuracy: 700/2176 (32%)\n",
            "\n",
            "Position accuracy: 254/1088, Rotation accuracy: 446/1088\n",
            "Train loss 3.7126409258036053 \n",
            " Val loss 3.0312720884514204 \n",
            " Train Acc 0.3216911852359772 \n",
            " Val Acc 0.421875\n",
            "Epoch no 2 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4075a30>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4076c30>\n",
            "\n",
            "After epoch 2 - Test set: Number of batches: 272, Batch size: 4, Average loss: 3.3922, Accuracy: 867/2176 (40%)\n",
            "\n",
            "\n",
            "After epoch 2 - Train set: Number of batches: 272, Batch size: 4, Average loss: 2.9928, Train accuracy: 1009/2176 (46%)\n",
            "\n",
            "Position accuracy: 433/1088, Rotation accuracy: 576/1088\n",
            "Train loss 2.9927550400881207 \n",
            " Val loss 3.3922122618840898 \n",
            " Train Acc 0.46369484066963196 \n",
            " Val Acc 0.3984375\n",
            "Epoch no 3 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4075a30>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4076c30>\n",
            "\n",
            "After epoch 3 - Test set: Number of batches: 272, Batch size: 4, Average loss: 1.2497, Accuracy: 1904/2176 (88%)\n",
            "\n",
            "\n",
            "After epoch 3 - Train set: Number of batches: 272, Batch size: 4, Average loss: 2.1064, Train accuracy: 1430/2176 (66%)\n",
            "\n",
            "Position accuracy: 654/1088, Rotation accuracy: 776/1088\n",
            "Train loss 2.106419065200231 \n",
            " Val loss 1.2497214014258455 \n",
            " Train Acc 0.6571691036224365 \n",
            " Val Acc 0.875\n",
            "Epoch no 4 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4075a30>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4076c30>\n",
            "\n",
            "After epoch 4 - Test set: Number of batches: 272, Batch size: 4, Average loss: 1.3424, Accuracy: 1717/2176 (79%)\n",
            "\n",
            "\n",
            "After epoch 4 - Train set: Number of batches: 272, Batch size: 4, Average loss: 1.6237, Train accuracy: 1673/2176 (77%)\n",
            "\n",
            "Position accuracy: 809/1088, Rotation accuracy: 864/1088\n",
            "Train loss 1.6236957348883152 \n",
            " Val loss 1.3423517497174222 \n",
            " Train Acc 0.7688419222831726 \n",
            " Val Acc 0.7890625\n",
            "Epoch no 5 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4075a30>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4076c30>\n",
            "\n",
            "After epoch 5 - Test set: Number of batches: 272, Batch size: 4, Average loss: 1.1208, Accuracy: 1734/2176 (80%)\n",
            "\n",
            "\n",
            "After epoch 5 - Train set: Number of batches: 272, Batch size: 4, Average loss: 1.1170, Train accuracy: 1882/2176 (86%)\n",
            "\n",
            "Position accuracy: 937/1088, Rotation accuracy: 945/1088\n",
            "Train loss 1.1170231285778915 \n",
            " Val loss 1.1208140174584353 \n",
            " Train Acc 0.8648896813392639 \n",
            " Val Acc 0.796875\n",
            "Epoch no 6 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4075a30>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4076c30>\n",
            "\n",
            "After epoch 6 - Test set: Number of batches: 272, Batch size: 4, Average loss: 0.2850, Accuracy: 2159/2176 (99%)\n",
            "\n",
            "\n",
            "After epoch 6 - Train set: Number of batches: 272, Batch size: 4, Average loss: 0.8815, Train accuracy: 1967/2176 (90%)\n",
            "\n",
            "Position accuracy: 988/1088, Rotation accuracy: 979/1088\n",
            "Train loss 0.8815444695270237 \n",
            " Val loss 0.2849545664571719 \n",
            " Train Acc 0.9039521813392639 \n",
            " Val Acc 0.9921875\n",
            "Epoch no 7 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4075a30>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4076c30>\n",
            "\n",
            "After epoch 7 - Test set: Number of batches: 272, Batch size: 4, Average loss: 0.8392, Accuracy: 1870/2176 (86%)\n",
            "\n",
            "\n",
            "After epoch 7 - Train set: Number of batches: 272, Batch size: 4, Average loss: 0.8395, Train accuracy: 1976/2176 (91%)\n",
            "\n",
            "Position accuracy: 1018/1088, Rotation accuracy: 958/1088\n",
            "Train loss 0.8395319955752176 \n",
            " Val loss 0.8391626971629996 \n",
            " Train Acc 0.9080882668495178 \n",
            " Val Acc 0.859375\n",
            "Epoch no 8 #######################\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4075a30>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79d3a4076c30>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-209497183.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         train_loss, train_acc, val_loss, val_acc = model_train_test_obj.train(\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_max_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-36004698.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mcnt_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-36004698.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, epoch, test_data_loader)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_vector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrot_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mpos_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#for jigsaw ssl task\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import ConcatDataset\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    Cexperiment_name = 'e1_js'\n",
        "    Cdataset_config = 'js_d1'\n",
        "    Cweight_decay = 5e-4\n",
        "    Clr = 1e-3\n",
        "    Cepochs = 15\n",
        "    Cbatch_size = 4 # 4 to overfit single image\n",
        "\n",
        "    # Data files which will get referred\n",
        "    permuts_file_path = 'selected_permuts.npy'\n",
        "\n",
        "    # Set device to use to gpu if available and declare model_file_path\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #par_weights_dir = 'weights/'\n",
        "    model_file_path = 'resnet_jigsaw_solver_{}_trained.pt'.format(Cexperiment_name)\n",
        "\n",
        "    all_file_paths = get_paths()\n",
        "\n",
        "    # Get validation files separate\n",
        "    train_file_paths, val_file_paths = train_test_split(all_file_paths, test_size=0.1, shuffle=True, random_state=3)\n",
        "\n",
        "    # Compute channel means\n",
        "    channel_means = np.array([124.09, 127.67, 110.50]) / 256.0\n",
        "\n",
        "    # Define data loaders\n",
        "    batch_size = Cbatch_size\n",
        "    jig_size = 4\n",
        "\n",
        "    if Cdataset_config == 'js_d1':\n",
        "        n = jig_size**2 + 1\n",
        "        train_data_loader = DataLoader(\n",
        "            ConcatDataset(\n",
        "                [GetJigsawPuzzleDataset(train_file_paths, permuts_file_path,\n",
        "                                        jig_size=jig_size)\n",
        "                 for st_perm_ind in range(0, n**2, n)\n",
        "                ]\n",
        "            ),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=2\n",
        "        )\n",
        "        val_data_loader = DataLoader(\n",
        "            ConcatDataset(\n",
        "                [GetJigsawPuzzleDataset(val_file_paths, permuts_file_path,\n",
        "                                        jig_size=jig_size)\n",
        "                 for st_perm_ind in range(0, n**2, n)\n",
        "                 ]\n",
        "            ),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=2\n",
        "        )\n",
        "    else:\n",
        "        train_data_loader = DataLoader(\n",
        "            GetJigsawPuzzleDataset(train_file_paths, permuts_file_path, jig_size=jig_size),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=2\n",
        "        )\n",
        "        val_data_loader = DataLoader(\n",
        "            GetJigsawPuzzleDataset(val_file_paths, permuts_file_path, jig_size=jig_size),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=2\n",
        "        )\n",
        "    print(\"Loaders done\")\n",
        "    # Print sample batches that would be returned by the train_data_loader\n",
        "    # dataiter = iter(train_data_loader)\n",
        "    # X, y, r = dataiter.__next__() # Returns patches, positions, rotations\n",
        "    # print (X.size())\n",
        "    # print (y.size())\n",
        "\n",
        "    # Train required model defined above on CUB200 data\n",
        "    num_outputs = num_permuts_saved#200\n",
        "    epochs = Cepochs\n",
        "    lr = Clr\n",
        "    weight_decay_const = Cweight_decay\n",
        "\n",
        "    # If using Resnet18\n",
        "    # model_to_train = resnet18(num_classes=num_outputs, siamese_deg=jig_size**2, jigsaw_size=jigsaw_puzzle_size)\n",
        "    model_to_train = PretrainedResNet(num_positions=jig_size**2)\n",
        "    print('Model ready')\n",
        "    # Set device on which training is done. Plus optimizer to use.\n",
        "    model_to_train.to(device)\n",
        "    optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
        "    # scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, min_lr=1e-5)\n",
        "\n",
        "    # Start training\n",
        "    print('Started training')\n",
        "    model_train_test_obj = JigsawModelTrainTest(model_to_train, device, model_file_path)\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    for epoch_no in range(epochs):\n",
        "        print(\"Epoch no {} #######################\".format(epoch_no))\n",
        "        print(optimizer)\n",
        "        print(train_data_loader)\n",
        "        print(val_data_loader)\n",
        "        train_loss, train_acc, val_loss, val_acc = model_train_test_obj.train(\n",
        "            optimizer, epoch_no, params_max_norm=4,\n",
        "            train_data_loader = train_data_loader, val_data_loader = val_data_loader\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc.cpu())\n",
        "        val_accs.append(val_acc.cpu())\n",
        "        print(\"Train loss {} \\n Val loss {} \\n Train Acc {} \\n Val Acc {}\".format(train_loss,val_loss,train_acc,val_acc))\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    observations_df = pd.DataFrame()\n",
        "    observations_df['epoch count'] = [i for i in range(1, Cepochs + 1)]\n",
        "    observations_df['train loss'] = train_losses\n",
        "    print(f\"val_losses: {val_losses}\")\n",
        "    print(f\"type val loss: {type(val_losses)}\")\n",
        "    observations_df['val loss'] = val_losses\n",
        "    observations_df['train acc'] = train_accs\n",
        "    observations_df['val acc'] = val_accs\n",
        "    observations_file_path = Cexperiment_name + '_observations.csv'\n",
        "    observations_df.to_csv(observations_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_file_paths)"
      ],
      "metadata": {
        "id": "WrbRVKMY6qmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "584588eb-b40c-4013-9011-f0365c325413"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Final Project/Temp2/extra-image-16012.jpg', '/content/drive/MyDrive/Final Project/Temp2/extra-image-16012 (1).jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lbE1N98iTpV"
      },
      "source": [
        "# Plot loss and accuracy curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XAuZaAkCiTpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "7ee82ae2-f536-4592-c82d-f22cfdac87d4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.title('Loss plots')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "#plt.show()\n",
        "plt.savefig('loss.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "R5VXGhp7iTpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "4c2fd104-c6c2-4895-e002-ea4ac8c90153"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_accs)\n",
        "plt.plot(val_accs)\n",
        "plt.title('Accuracy plots')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "#plt.show()\n",
        "\n",
        "plt.savefig('accuracy.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def get_image_loader():\n",
        "    'Generates one sample of data'\n",
        "    jig_size = 4\n",
        "\n",
        "\n",
        "    data_transform = transforms.Compose([\n",
        "        # transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Select sample\n",
        "    file_path = \"extraimages/extra-image-1.jpg\"\n",
        "    pil_image = Image.open(file_path)\n",
        "\n",
        "    # Convert image to torch tensor\n",
        "    pil_image = pil_image.resize((256, 256))\n",
        "    new_size = 256 - (256 % jig_size) # Ensure that the number of pixels fits the number of jigsaw pieces\n",
        "    pil_image = crop_from_center(pil_image, new_size, new_size)\n",
        "    solution_tensor = data_transform(pil_image)\n",
        "\n",
        "    # Split image into tiles (patches)\n",
        "    crops = get_several_crops(pil_image, jig_size)\n",
        "\n",
        "    # Generate a rotation sequence\n",
        "    rot_config = np.random.randint(4, size=jig_size ** 2)\n",
        "\n",
        "    # Find a single patch in the image\n",
        "    rand_pos = np.random.randint(jig_size ** 2)\n",
        "    rand_rot = np.random.randint(4) # Set to 0 for debugging purposes\n",
        "    patch_im = crops[rand_pos]\n",
        "    patch_im = rotate(patch_im, rand_rot * 90)\n",
        "    patch_tensor = data_transform(patch_im)\n",
        "    pad_size_right = solution_tensor.shape[2] - patch_tensor.shape[2]\n",
        "    pad_size_bottom = solution_tensor.shape[1] - patch_tensor.shape[1]\n",
        "    patch_tensor_extended = torch.nn.functional.pad(patch_tensor, (0, pad_size_right, 0, pad_size_bottom))\n",
        "\n",
        "    # Concanate selected patch along channel to form a 6 channel image\n",
        "    original_plus_patch = torch.cat((solution_tensor, patch_tensor_extended), dim=0)\n",
        "\n",
        "    print(patch_im)\n",
        "\n",
        "\n",
        "    return original_plus_patch, rand_pos, rand_rot, patch_im, pil_image\n",
        "\n",
        "\n",
        "\n",
        "model = PretrainedResNet()       # create an *uninitialized* instance\n",
        "state = torch.load(\"resnet_jigsaw_solver_e1_js_trained.pt\", map_location=\"cpu\")\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "sing_im, pos, rot, patch, solution = get_image_loader()\n",
        "print(f\"Solution is {pos} and {rot}\")\n",
        "plt.subplot(1, 2, 1)\n",
        "# plt.axis((0, 64*4, 0, 64*4))\n",
        "plt.imshow(solution)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(patch)\n",
        "sing_im = sing_im.unsqueeze(0).to(device)\n",
        "pos_out, rot_out = model(sing_im)\n",
        "pos_pred = pos_out.argmax(dim=1)\n",
        "rot_pred = rot_out.argmax(dim=1)\n",
        "print(pos_pred, rot_pred)\n",
        "print(pos_out, rot_out)\n"
      ],
      "metadata": {
        "id": "HhAPPGK8kVHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solve entire puzzle"
      ],
      "metadata": {
        "id": "boI8rFIdcH7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import random\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import rotate\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"extraimages/extra-image-1.jpg\"\n",
        "pil_image = Image.open(file_path)\n",
        "jigsaw_puzzle_size = 4\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def crop_from_center(pil_image, new_h, new_w):\n",
        "\n",
        "    width, height = pil_image.size  # Get dimensions\n",
        "\n",
        "    left = (width - new_w) / 2\n",
        "    top = (height - new_h) / 2\n",
        "    right = (width + new_w) / 2\n",
        "    bottom = (height + new_h) / 2\n",
        "\n",
        "    # Crop the center of the image\n",
        "    pil_image = pil_image.crop((left, top, right, bottom))\n",
        "\n",
        "    return pil_image\n",
        "\n",
        "def get_several_crops(pil_image, jig_size):\n",
        "    \"\"\"\n",
        "    Get several crops for a square pillow image. That is height and width of the image should be same.\n",
        "    :param pil_image: pillow image\n",
        "    :param jig_size: number of rows and columns for jigsaw\n",
        "    :return: List of pillow images. The nine crops\n",
        "    \"\"\"\n",
        "    w, h = pil_image.size\n",
        "    diff = int(w/jig_size)\n",
        "\n",
        "    r_vals = [i * diff for i in range(jig_size)]\n",
        "    c_vals = [i * diff for i in range(jig_size)]\n",
        "\n",
        "    list_patches = []\n",
        "\n",
        "    for r in r_vals:\n",
        "        for c in c_vals:\n",
        "\n",
        "            left = c\n",
        "            top = r\n",
        "            right = c + diff\n",
        "            bottom = r + diff\n",
        "\n",
        "            patch = pil_image.crop((left, top, right, bottom))\n",
        "            list_patches.append(patch)\n",
        "\n",
        "    return list_patches\n",
        "\n",
        "def shuffle_image(file_path):\n",
        "    jig_size = 4\n",
        "\n",
        "\n",
        "    data_transform = transforms.Compose([\n",
        "        # transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Select sample\n",
        "    pil_image = Image.open(file_path)\n",
        "\n",
        "    # Convert image to torch tensor\n",
        "    pil_image = pil_image.resize((256, 256))\n",
        "    new_size = 256 - (256 % jig_size) # Ensure that the number of pixels fits the number of jigsaw pieces\n",
        "    pil_image = crop_from_center(pil_image, new_size, new_size)\n",
        "    solution_tensor = data_transform(pil_image)\n",
        "\n",
        "    # Split image into tiles (patches)\n",
        "    crops = get_several_crops(pil_image, jig_size)\n",
        "\n",
        "    # Generate a rotation sequence\n",
        "    rot_config = np.random.randint(4, size=jig_size ** 2)\n",
        "    # Generate a position sequence\n",
        "    # pos_config = np.random.randint(jig_size ** 2, size=jig_size ** 2)\n",
        "    pos_config = np.arange(jig_size ** 2)\n",
        "    np.random.shuffle(pos_config)\n",
        "\n",
        "    # Shuffle the image\n",
        "    transformed_crops = torch.zeros((jig_size ** 2, 3, crops[0].height, crops[0].width))\n",
        "    for crop, rot, pos in zip(crops, rot_config, pos_config):\n",
        "        rotated_crop = rotate(crop, int(rot * 90))\n",
        "        transformed_crops[pos] = data_transform(rotated_crop)\n",
        "\n",
        "    # Find a single patch in the image\n",
        "    rand_pos = np.random.randint(jig_size ** 2)\n",
        "    rand_rot = np.random.randint(4) # Set to 0 for debugging purposes\n",
        "\n",
        "    list_original_plus_patch = []\n",
        "    for tr_cr in transformed_crops:\n",
        "        # patch_im = crops[rand_pos]\n",
        "        # patch_im = rotate(patch_im, rand_rot * 90)\n",
        "        # patch_tensor = data_transform(patch_im)\n",
        "        pad_size_right = solution_tensor.shape[2] - tr_cr.shape[2]\n",
        "        pad_size_bottom = solution_tensor.shape[1] - tr_cr.shape[1]\n",
        "        patch_tensor_extended = torch.nn.functional.pad(tr_cr, (0, pad_size_right, 0, pad_size_bottom))\n",
        "\n",
        "        # Concanate selected patch along channel to form a 6 channel image\n",
        "        original_plus_patch = torch.cat((solution_tensor, patch_tensor_extended), dim=0)\n",
        "        list_original_plus_patch.append(original_plus_patch)\n",
        "\n",
        "\n",
        "    return list_original_plus_patch, pos_config, rot_config, pil_image\n",
        "\n",
        "def solve(model, tiles):\n",
        "    threshold = 0.5\n",
        "    solution_pos = np.zeros(len(tiles))\n",
        "    solution_rot = np.zeros(len(tiles))\n",
        "    taken_pos = []\n",
        "    taken_rot = []\n",
        "    i = 0\n",
        "    itr = 0\n",
        "    while itr < 1000 and len(taken_pos) < len(tiles):\n",
        "        t = tiles[i]\n",
        "        sing_im = t.unsqueeze(0).to(device)\n",
        "        pos_out_prob, rot_out_prob = model(sing_im)\n",
        "        pos_out_prob = pos_out_prob.squeeze(0)\n",
        "        rot_out_prob = rot_out_prob.squeeze(0)\n",
        "        # print(f\"Pos out prob: {pos_out_prob}\")\n",
        "        # print(f\"Rot out prob: {rot_out_prob}\")\n",
        "        # print(f\"Taken pos: {taken_pos}\")\n",
        "\n",
        "        # # Don't include already taken\n",
        "        # for i, p, r in zip(range(len(taken_pos)), taken_pos, taken_rot):\n",
        "        #     pos_out_prob[p] = -10000\n",
        "        #     rot_out_prob[r] = -10000\n",
        "\n",
        "        top_pos_prob, pos_idx = torch.topk(pos_out_prob, 2)\n",
        "        top_rot_prob, rot_idx = torch.topk(rot_out_prob, 2)\n",
        "\n",
        "        top_pos_prob = top_pos_prob.squeeze(0)\n",
        "        top_rot_prob = top_rot_prob.squeeze(0)\n",
        "        pos_idx = pos_idx.squeeze(0)\n",
        "        rot_idx = rot_idx.squeeze(0)\n",
        "\n",
        "        # print(top_pos_prob, pos_idx)\n",
        "        # print(top_rot_prob, rot_idx)\n",
        "        if top_pos_prob[0] > 3:\n",
        "            solution_pos[i] = pos_idx[0]\n",
        "            solution_rot[i] = rot_idx[0]\n",
        "            taken_pos.append(pos_idx[0])\n",
        "            taken_rot.append(rot_idx[0])\n",
        "\n",
        "        pos_pred = pos_out_prob.argmax(dim=0)\n",
        "        rot_pred = rot_out_prob.argmax(dim=0)\n",
        "        i += 1\n",
        "        itr += 1\n",
        "        i = i % len(tiles)\n",
        "\n",
        "\n",
        "    return solution_pos, solution_rot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tiles = get_several_crops(pil_image, jigsaw_puzzle_size)\n",
        "model_ready, solution_pos, solution_rot, pil_image = shuffle_image(file_path)\n",
        "\n",
        "model = PretrainedResNet()       # create an *uninitialized* instance\n",
        "state = torch.load(\"resnet_jigsaw_solver_e1_js_trained.pt\", map_location=\"cpu\")\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "model_pos, model_rot = solve(model, model_ready)\n",
        "print(f\"Should be {solution_pos } and {solution_rot}\")\n",
        "print(f\"Return {model_pos} and {model_rot}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZBAXLt5gcKfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "num_outputs = num_permuts_saved\n",
        "siamese_deg = jigsaw_puzzle_size ** 2\n",
        "\n",
        "# Use same transforms as training\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.RandomCrop((64, 64)),\n",
        "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "data_loader = GetDataset([\"mountain_Solution.jpg\"], [None], transform=data_transform)\n",
        "jig_loader = GetJigsawPuzzleDataset([\"mountain_Solution.jpg\"], 'selected_permuts.npy', transform=data_transform, jig_size=jigsaw_puzzle_size)\n",
        "\n",
        "\n",
        "model = resnet18(num_classes=num_outputs, siamese_deg=siamese_deg, jigsaw_size=jigsaw_puzzle_size)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"resnet_jigsaw_solver_e1_js_trained.pt\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "X, y = jig_loader[0]\n",
        "X = X.unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model(X)\n",
        "\n",
        "print(\"Output shape: \", output.shape)\n",
        "out_im = transforms.functional.to_pil_image(output)\n",
        "\n",
        "out_im.show()\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "t7bPiDL4x2ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqvSlGHSiTpW"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    pil_img = Image.open(path)\n",
        "    if pil_img.mode == \"L\":\n",
        "        return None\n",
        "    else:\n",
        "        return pil_img\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "    Cmodel_name = 'resnet_trained_ssl_e1_last_b_last_b_ft.pt'\n",
        "    Ctest_compact_bilinear = True\n",
        "    Ctest_imagenet_based = False\n",
        "    Ctest_on = 'test'\n",
        "\n",
        "    # Set device to use to gpu if available and declare model_file_path\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #par_weights_dir = 'weights/'\n",
        "    model_file_path = Cmodel_name\n",
        "\n",
        "    # Data loading and data generators set up\n",
        "    train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels = \\\n",
        "        get_train_test_file_paths_n_labels()\n",
        "\n",
        "    train_image_ids, val_image_ids, train_file_paths, val_file_paths, train_labels, val_labels = \\\n",
        "        split_train_into_train_val(train_image_ids, train_file_paths, train_labels, test_size=0.1)\n",
        "\n",
        "    if Ctest_imagenet_based:\n",
        "        model_to_train = models.resnet18(pretrained=True)\n",
        "        model_to_train.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
        "        model_to_train.fc = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 5),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "    else:\n",
        "        model_to_train = resnet18(num_classes=5, siamese_deg=None, jigsaw_size=jigsaw_puzzle_size)\n",
        "\n",
        "    # Check if saved model exists, and load if it does.\n",
        "    if os.path.exists(model_file_path):\n",
        "        model_to_train.load_state_dict(torch.load(model_file_path))\n",
        "    model_to_train.to(device)\n",
        "\n",
        "    # Setup on which set evaluation is to be carried out\n",
        "    if Ctest_on == 'train':\n",
        "        eval_file_paths, eval_labels = train_file_paths, train_labels\n",
        "    elif Ctest_on == 'val':\n",
        "        eval_file_paths, eval_labels = val_file_paths, val_labels\n",
        "    else:\n",
        "        eval_file_paths, eval_labels = test_file_paths, test_labels\n",
        "\n",
        "    # Start evaluation\n",
        "    model_to_train.eval()\n",
        "    correct = 0\n",
        "    preds = []\n",
        "    for f, label in zip(eval_file_paths, eval_labels):\n",
        "        pil_img = pil_loader(f)\n",
        "        if pil_img is None:\n",
        "            preds.append(0)\n",
        "            continue\n",
        "        data = def_data_transform(pil_img)\n",
        "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
        "        data = Variable(data, volatile=True).to(device)\n",
        "        output = model_to_train(data)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "\n",
        "        x = pred.data #prediction\n",
        "        preds.append(x)\n",
        "\n",
        "        if x == label:\n",
        "            correct += 1\n",
        "\n",
        "    print (correct, len(eval_file_paths), correct * 100 / len(eval_file_paths))\n",
        "    preds = np.array(preds).astype(np.float64)\n",
        "    conf_mat = np.array(confusion_matrix(preds, eval_labels))\n",
        "    conf_df = pd.DataFrame(conf_mat)\n",
        "    conf_df.columns = np.arange(0,5)\n",
        "    conf_df.to_csv('confusion_matrix.csv')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}