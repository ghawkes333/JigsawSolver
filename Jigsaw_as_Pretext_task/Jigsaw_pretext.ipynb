{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Drive"
      ],
      "metadata": {
        "id": "Yzxi1YwvKK5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "BMapp1dWKKXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24cb0601-91e2-4140-b85b-3dd31cc18435"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg7Ot1x70Djr"
      },
      "source": [
        "# Generate permutations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q37yJnYM0Djt",
        "outputId": "b098a497-d846-4ab9-b9bc-214d52c168df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already performed count of iterations with pairs of jigsaw permutations 100\n",
            "Length of set of taken:  82\n",
            "No of iterations it took to build top - 100 permutations array = 120\n",
            "No of permutations 100\n",
            "Sample permutation 0\n",
            "[5 1 8 6 0 4 7 2 3]\n",
            "Sample permutation 1\n",
            "[2 1 3 4 0 8 6 5 7]\n",
            "Sample permutation 2\n",
            "[5 7 8 3 1 4 6 0 2]\n",
            "Sample permutation 3\n",
            "[1 2 8 6 3 7 0 4 5]\n",
            "Sample permutation 4\n",
            "[2 0 6 7 1 4 8 3 5]\n",
            "Sample permutation 5\n",
            "[7 3 2 4 0 6 1 5 8]\n",
            "Sample permutation 6\n",
            "[1 7 0 8 4 3 5 6 2]\n",
            "Sample permutation 7\n",
            "[3 4 0 2 6 5 1 7 8]\n",
            "Sample permutation 8\n",
            "[2 4 6 1 8 7 5 3 0]\n",
            "Sample permutation 9\n",
            "[1 0 8 6 2 4 5 3 7]\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy.spatial.distance import hamming\n",
        "\n",
        "\n",
        "# Build list of all possible permutations\n",
        "permuts_list = list(itertools.permutations(range(9)))\n",
        "permuts_array = np.array(permuts_list)\n",
        "no_permuts = len(permuts_list)\n",
        "\n",
        "\n",
        "# Take top x permutations which have max average hamming distance\n",
        "permuts_to_take = 100#200\n",
        "set_of_taken = set()\n",
        "cnt_iterations = 0\n",
        "while True:\n",
        "    cnt_iterations += 1\n",
        "    x = random.randint(1, no_permuts - 1)\n",
        "    y = random.randint(1, no_permuts - 1)\n",
        "    permut_1 = permuts_array[x]\n",
        "    permut_2 = permuts_array[y]\n",
        "    hd = hamming(permut_1, permut_2)\n",
        "\n",
        "    if hd > 0.9 and (not x in set_of_taken) and (not y in set_of_taken):\n",
        "        set_of_taken.add(x)\n",
        "        set_of_taken.add(y)\n",
        "\n",
        "        if len(set_of_taken) == permuts_to_take:\n",
        "            break\n",
        "\n",
        "    if cnt_iterations % 100 == 0:\n",
        "        print (\"Already performed count of iterations with pairs of jigsaw permutations\", cnt_iterations)\n",
        "        print (\"Length of set of taken: \",len(set_of_taken))\n",
        "\n",
        "print (\"No of iterations it took to build top - {} permutations array = {}\".format(permuts_to_take, cnt_iterations))\n",
        "print (\"No of permutations\", len(set_of_taken))\n",
        "\n",
        "\n",
        "# Build the array for selected permutation indices above\n",
        "selected_permuts = []\n",
        "for ind, perm_id in enumerate(set_of_taken):\n",
        "    if ind < 10:\n",
        "        print (\"Sample permutation {}\".format(ind))\n",
        "        print (permuts_array[perm_id])\n",
        "    selected_permuts.append(permuts_array[perm_id])\n",
        "\n",
        "selected_permuts = np.array(selected_permuts)\n",
        "np.save('selected_permuts.npy', selected_permuts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "N5DPoz-a0Djv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "\n",
        "def crop_from_center(pil_image, new_h, new_w):\n",
        "\n",
        "    width, height = pil_image.size  # Get dimensions\n",
        "\n",
        "    left = (width - new_w) / 2\n",
        "    top = (height - new_h) / 2\n",
        "    right = (width + new_w) / 2\n",
        "    bottom = (height + new_h) / 2\n",
        "\n",
        "    # Crop the center of the image\n",
        "    pil_image = pil_image.crop((left, top, right, bottom))\n",
        "\n",
        "    return pil_image\n",
        "\n",
        "\n",
        "def get_nine_crops(pil_image):\n",
        "    \"\"\"\n",
        "    Get nine crops for a square pillow image. That is height and width of the image should be same.\n",
        "    :param pil_image: pillow image\n",
        "    :return: List of pillow images. The nine crops\n",
        "    \"\"\"\n",
        "    w, h = pil_image.size\n",
        "    diff = int(w/3)\n",
        "\n",
        "    r_vals = [0, diff, 2 * diff]\n",
        "    c_vals = [0, diff, 2 * diff]\n",
        "\n",
        "    list_patches = []\n",
        "\n",
        "    for r in r_vals:\n",
        "        for c in c_vals:\n",
        "\n",
        "            left = c\n",
        "            top = r\n",
        "            right = c + diff\n",
        "            bottom = r + diff\n",
        "\n",
        "            patch = pil_image.crop((left, top, right, bottom))\n",
        "            list_patches.append(patch)\n",
        "\n",
        "    return list_patches\n",
        "\n",
        "\n",
        "def split_train_into_train_val(train_file_ids, train_file_paths, train_labels, test_size=0.1):\n",
        "    \"\"\"\n",
        "    Split train_file_paths and train_labels to train_file_paths, val_file_paths and\n",
        "    train_labels, val_labels\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a mapping between image_id and file_path\n",
        "    image_id_name_map = dict(zip(train_file_ids, train_file_paths))\n",
        "\n",
        "    # Get validation files and validation labels separate\n",
        "    train_file_ids, val_file_ids, train_labels, val_labels = train_test_split(\n",
        "        train_file_ids, train_labels, test_size=test_size, random_state=5, shuffle=True\n",
        "    )\n",
        "    train_file_paths = [image_id_name_map[image_id] for image_id in train_file_ids]\n",
        "    val_file_paths = [image_id_name_map[image_id] for image_id in val_file_ids]\n",
        "\n",
        "    print (\"Length of train files list\", len(train_file_paths))\n",
        "    print (\"Length of train labels\", len(train_labels))\n",
        "    print (\"Length of val files list\", len(val_file_paths))\n",
        "    print (\"Length of val labels\", len(val_labels))\n",
        "\n",
        "    return train_file_ids, val_file_ids, train_file_paths, val_file_paths, train_labels, val_labels\n",
        "\n",
        "def get_paths(data_dir):\n",
        "    file_paths_to_return = []\n",
        "\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(\".jpg\"):\n",
        "                file_paths_to_return.append(data_dir+'/'+file)\n",
        "\n",
        "    return file_paths_to_return\n",
        "\n",
        "def get_train_test_file_paths_n_labels():\n",
        "    \"\"\"\n",
        "    Get array train_file_paths, train_labels, test_file_paths and test_labels\n",
        "    \"\"\"\n",
        "\n",
        "    # Data loading and data generators set up\n",
        "    #par_data_dir = 'train'\n",
        "    images_data_dir = 'train'\n",
        "    train_test_split_file = 'train_test_split.txt'\n",
        "    images_file = 'images.txt'\n",
        "    labels_file = 'image_class_labels.txt'\n",
        "\n",
        "    # Read the images_file which stores image-id and image-name mapping\n",
        "    image_file_id_df = pd.read_csv(images_file, sep=' ', header=None)\n",
        "    image_file_id_mat = image_file_id_df.values\n",
        "    image_id_name_map = dict(zip(image_file_id_mat[:, 0], image_file_id_mat[:, 1]))\n",
        "\n",
        "    # Read the train_test_split file which stores image-id and train-test split mapping\n",
        "    image_id_train_test_split_df = pd.read_csv(train_test_split_file, sep=' ', header=None)\n",
        "    image_id_train_test_split_mat = image_id_train_test_split_df.values\n",
        "    image_id_train_test_split_map = dict(zip(image_id_train_test_split_mat[:, 0],\n",
        "                                             image_id_train_test_split_mat[:, 1]))\n",
        "\n",
        "    # Read the image class labels file\n",
        "    image_id_label_df = pd.read_csv(labels_file, sep=' ', header=None)\n",
        "    image_id_label_mat = image_id_label_df.values\n",
        "    image_id_label_map = dict(zip(image_id_label_mat[:, 0], image_id_label_mat[:, 1]))\n",
        "\n",
        "    # Put together train_files train_labels test_files and test_labels lists\n",
        "    train_image_ids, test_image_ids = [], []\n",
        "    train_file_paths, test_file_paths = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    for file_id in image_id_name_map.keys():\n",
        "        file_name = image_id_name_map[file_id]\n",
        "        is_train = image_id_train_test_split_map[file_id]\n",
        "        label = image_id_label_map[file_id] - 1  # To ensure labels start from 0\n",
        "\n",
        "        if is_train:\n",
        "            train_image_ids.append(file_id)\n",
        "            train_file_paths.append(os.path.join(images_data_dir, file_name))\n",
        "            train_labels.append(label)\n",
        "        else:\n",
        "            test_image_ids.append(file_id)\n",
        "            test_file_paths.append(os.path.join(images_data_dir, file_name))\n",
        "            test_labels.append(label)\n",
        "\n",
        "    print (\"Length of train files list\", len(train_file_paths))\n",
        "    print (\"Length of train labels list\", len(train_labels))\n",
        "    print (\"Length of test files list\", len(test_file_paths))\n",
        "    print (\"Length of test labels list\", len(test_labels))\n",
        "\n",
        "    return train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7UIXFNq0Djw"
      },
      "source": [
        "# Generate Jigsaw from permutations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8SFOvvMU0Djw"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "#from dataset_helpers import crop_from_center, get_nine_crops\n",
        "\n",
        "\n",
        "class GetDataset(Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        'Initialization'\n",
        "        self.imgs = [(img_path, label) for img_path, label in zip(file_paths, labels)]\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "\n",
        "        # Select sample\n",
        "        file_path = self.file_paths[index]\n",
        "        label = self.labels[index]\n",
        "        pil_image = Image.open(file_path)\n",
        "\n",
        "        # Check if image has only single channel. If True, then swap with 0th image\n",
        "        # Assumption 0th image has got 3 number of channels\n",
        "        if len(pil_image.getbands()) != 3:\n",
        "            file_path = self.file_paths[0]\n",
        "            label = self.labels[0]\n",
        "            pil_image = Image.open(file_path)\n",
        "\n",
        "        # Convert image to torch tensor\n",
        "        tr_image = self.transform(pil_image)\n",
        "\n",
        "        return tr_image, label\n",
        "\n",
        "\n",
        "class GetJigsawPuzzleDataset(Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, file_paths, avail_permuts_file_path, range_permut_indices=None, transform=None):\n",
        "        'Initialization'\n",
        "        self.file_paths = file_paths\n",
        "        self.transform = transform\n",
        "        self.permuts_avail = np.load(avail_permuts_file_path)\n",
        "        self.range_permut_indices = range_permut_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "\n",
        "        # Select sample\n",
        "        file_path = self.file_paths[index]\n",
        "        pil_image = Image.open(file_path)\n",
        "\n",
        "        #DEBUG\n",
        "        # plt.subplot(3,4,1)\n",
        "        # plt.title(\"Original\")\n",
        "        # plt.imshow(pil_image)\n",
        "\n",
        "        # Check if image has only single channel. If True, then swap with 0th image\n",
        "        # Assumption 0th image has got 3 number of channels\n",
        "        if len(pil_image.getbands()) != 3:\n",
        "            file_path = self.file_paths[0]\n",
        "            pil_image = Image.open(file_path)\n",
        "\n",
        "        # Convert image to torch tensor\n",
        "        pil_image = pil_image.resize((192, 192))\n",
        "\n",
        "\n",
        "        #DEBUG\n",
        "        # plt.subplot(3,4,2)\n",
        "        # plt.title(\"Resized\")\n",
        "        # plt.imshow(pil_image)\n",
        "\n",
        "        # Permut the 9 patches obtained from the image\n",
        "        if self.range_permut_indices:\n",
        "            permut_ind = random.randint(self.range_permut_indices[0], self.range_permut_indices[1])\n",
        "        else:\n",
        "            permut_ind = random.randint(0, len(self.permuts_avail) - 1)\n",
        "\n",
        "        rot_ind = random.randint(0, 3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # pil_image = crop_from_center(pil_image, 225, 225)\n",
        "\n",
        "        # Get nine crops for the image\n",
        "        nine_crops = get_nine_crops(pil_image)\n",
        "\n",
        "        # Rotate\n",
        "        nine_crops = [\n",
        "          crop.rotate(90 * rot_ind, expand=False) for crop in nine_crops\n",
        "        ]\n",
        "\n",
        "        permutation_config = self.permuts_avail[permut_ind]\n",
        "\n",
        "        permuted_patches_arr = [None] * 9\n",
        "        for crop_new_pos, crop in zip(permutation_config, nine_crops):\n",
        "            permuted_patches_arr[crop_new_pos] = crop\n",
        "\n",
        "\n",
        "        # Apply data transforms\n",
        "        temp = torch.zeros(9, 3, 64, 64)\n",
        "        for ind, jigsaw_patch in enumerate(permuted_patches_arr):\n",
        "            temp[ind] = torch.tensor(np.array(jigsaw_patch)).permute(2, 0, 1)\n",
        "\n",
        "        # Apply data transforms\n",
        "        tensor_patches = torch.zeros(9, 3, 64, 64)\n",
        "        for ind, jigsaw_patch in enumerate(permuted_patches_arr):\n",
        "            jigsaw_patch_tr = self.transform(jigsaw_patch)\n",
        "            tensor_patches[ind] = jigsaw_patch_tr\n",
        "\n",
        "\n",
        "\n",
        "        #DEBUG\n",
        "        # plt.subplot(3,4,3)\n",
        "        # plt.title(\"Transformed\")\n",
        "        # patch_tensor = tensor_patches\n",
        "        # rows = (torch.cat(tuple(patch_tensor[0:3]), dim=2), torch.cat(tuple(patch_tensor[3:6]), dim=2), torch.cat(tuple(patch_tensor[6:9]), dim=2))\n",
        "        # patch_tensor = torch.cat(rows, dim=1)\n",
        "        # patch_tensor = patch_tensor.permute(1, 2, 0)\n",
        "        # plt.imshow(patch_tensor)\n",
        "\n",
        "\n",
        "        return tensor_patches, permut_ind * 4 + rot_ind\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R30hrWv0Djx"
      },
      "source": [
        "# Defining Resnet model\n",
        "Credit: https://github.com/aniket03/self_supervised_bird_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gMNaA-Q80Djx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None, siamese_deg=9, train_contrastive=False):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.siamese_deg = siamese_deg\n",
        "        self.train_contrastive = train_contrastive\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
        "\n",
        "        if self.siamese_deg is None:\n",
        "            self.fc = nn.Linear(2048 * block.expansion, num_classes)\n",
        "        else:\n",
        "            self.fc = nn.Linear(2048 * block.expansion * self.siamese_deg, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def get_feature_vectors(self, input_batch):\n",
        "        # Each input_batch would be of shape (batch_size, color_channels, h, w)\n",
        "        x = self.conv1(input_batch)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x\n",
        "\n",
        "    def forward(self, input_batch):\n",
        "\n",
        "        # Data returned by data loaders is of the shape (batch_size, no_patches, h_patch, w_patch)\n",
        "        # That's why named input to patches_batch\n",
        "\n",
        "        if self.siamese_deg is None:\n",
        "            final_feat_vectors = self.get_feature_vectors(input_batch)\n",
        "            x = F.dropout(final_feat_vectors)\n",
        "            x = F.log_softmax(self.fc(x), dim=1)\n",
        "        elif not self.train_contrastive:\n",
        "            final_feat_vectors = None\n",
        "            for patch_ind in range(self.siamese_deg):\n",
        "                # Each patch_batch would be of shape (batch_size, color_channels, h_patch, w_patch)\n",
        "                patch_batch = input_batch[:, patch_ind, :, :, :]\n",
        "                patch_batch_features = self.get_feature_vectors(patch_batch)\n",
        "\n",
        "                if patch_ind == 0:\n",
        "                    final_feat_vectors = patch_batch_features\n",
        "                else:\n",
        "                    final_feat_vectors = torch.cat([final_feat_vectors, patch_batch_features], dim=1)\n",
        "            x = F.dropout(final_feat_vectors)\n",
        "            x = F.log_softmax(self.fc(x), dim=1)# Shape is [4, 100]\n",
        "        else:\n",
        "            q_img_batch = input_batch[:, 0, :, :, :]\n",
        "            p_img_batch = input_batch[:, 1, :, :, :]\n",
        "            n_img_batch = input_batch[:, 2, :, :, :]\n",
        "\n",
        "            q_img_batch_feats = self.get_feature_vectors(q_img_batch)\n",
        "            p_img_batch_feats = self.get_feature_vectors(p_img_batch)\n",
        "            n_img_batch_feats = self.get_feature_vectors(n_img_batch)\n",
        "\n",
        "            pos_sq_dist = torch.norm(q_img_batch_feats - p_img_batch_feats, p=2, dim=1) ** 2\n",
        "            neg_sq_dist = torch.norm(q_img_batch_feats - n_img_batch_feats, p=2, dim=1) ** 2\n",
        "\n",
        "            x = pos_sq_dist - neg_sq_dist\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "def _resnet(block, layers, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(**kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    \"\"\"\n",
        "    return _resnet(BasicBlock, [2, 2, 2, 2], **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hdr6VxdF0Djy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "\n",
        "def get_count_correct_preds(network_output, target):\n",
        "\n",
        "    output = network_output\n",
        "    pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "    pred.data = pred.data.view_as(target.data)\n",
        "    correct = target.eq(pred).sum().item()\n",
        "\n",
        "    return correct\n",
        "\n",
        "\n",
        "class ModelTrainTest():\n",
        "\n",
        "    def __init__(self, network, device, model_file_path, threshold=1e-4):\n",
        "        super(ModelTrainTest, self).__init__()\n",
        "        self.network = network\n",
        "        self.device = device\n",
        "        self.model_file_path = model_file_path\n",
        "        self.threshold = threshold\n",
        "        self.train_loss = 1e9\n",
        "        self.val_loss = 1e9\n",
        "\n",
        "    def train(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader):\n",
        "        self.network.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        cnt_batches = 0\n",
        "\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
        "            data, target = Variable(data).to(self.device), Variable(target).to(self.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = self.network(data)\n",
        "\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "\n",
        "            clip_grad_norm_(self.network.parameters(), params_max_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            correct += get_count_correct_preds(output, target)\n",
        "            train_loss += loss.item()\n",
        "            cnt_batches += 1\n",
        "\n",
        "            del data, target, output\n",
        "\n",
        "        train_loss /= cnt_batches\n",
        "        val_loss, val_acc = self.test(epoch, val_data_loader)\n",
        "\n",
        "        if val_loss < self.val_loss - self.threshold:\n",
        "            self.val_loss = val_loss\n",
        "            torch.save(self.network.state_dict(), self.model_file_path)\n",
        "\n",
        "        train_acc = correct / len(train_data_loader.dataset)\n",
        "\n",
        "        print('\\nAfter epoch {} - Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, train_loss, correct, len(train_data_loader.dataset),\n",
        "            100. * correct / len(train_data_loader.dataset)))\n",
        "\n",
        "        return train_loss, train_acc, val_loss, val_acc\n",
        "\n",
        "    def test(self, epoch, test_data_loader):\n",
        "        self.network.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(test_data_loader):\n",
        "            data, target = Variable(data).to(self.device), Variable(target).to(self.device)\n",
        "            output = self.network(data)\n",
        "            test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
        "\n",
        "            correct += get_count_correct_preds(output, target)\n",
        "\n",
        "            del data, target, output\n",
        "\n",
        "        test_loss /= len(test_data_loader.dataset)\n",
        "        test_acc = correct / len(test_data_loader.dataset)\n",
        "        print('\\nAfter epoch {} - Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, test_loss, correct, len(test_data_loader.dataset),\n",
        "            100. * correct / len(test_data_loader.dataset)))\n",
        "\n",
        "        return  test_loss, test_acc\n",
        "\n",
        "\n",
        "class JigsawModelTrainTest():\n",
        "\n",
        "    def __init__(self, network, device, model_file_path, threshold=1e-4):\n",
        "        super(JigsawModelTrainTest, self).__init__()\n",
        "        self.network = network\n",
        "        self.device = device\n",
        "        self.model_file_path = model_file_path\n",
        "        self.threshold = threshold\n",
        "        self.train_loss = 1e9\n",
        "        self.val_loss = 1e9\n",
        "\n",
        "    def train(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader):\n",
        "        self.network.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        cnt_batches = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
        "\n",
        "            data, target = Variable(data).to(self.device), Variable(target).to(self.device)\n",
        "            optimizer.zero_grad()\n",
        "            output = self.network(data)\n",
        "\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            clip_grad_norm_(self.network.parameters(), params_max_norm)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            correct += get_count_correct_preds(output, target)\n",
        "            train_loss += loss.item()\n",
        "            cnt_batches += 1\n",
        "\n",
        "            del data, target, output\n",
        "\n",
        "        train_loss /= cnt_batches\n",
        "        val_loss, val_acc = self.test(epoch, val_data_loader)\n",
        "\n",
        "        if val_loss < self.val_loss - self.threshold:\n",
        "            self.val_loss = val_loss\n",
        "            torch.save(self.network.state_dict(), self.model_file_path)\n",
        "\n",
        "        train_acc = correct / len(train_data_loader.dataset)\n",
        "\n",
        "        print('\\nAfter epoch {} - Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, train_loss, correct, len(train_data_loader.dataset),\n",
        "            100. * correct / len(train_data_loader.dataset)))\n",
        "\n",
        "        return train_loss, train_acc, val_loss, val_acc\n",
        "\n",
        "    def test(self, epoch, test_data_loader):\n",
        "        self.network.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(test_data_loader):\n",
        "            data, target = Variable(data).to(self.device), Variable(target).to(self.device)\n",
        "            output = self.network(data)\n",
        "            test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
        "\n",
        "            correct += get_count_correct_preds(output, target)\n",
        "\n",
        "            del data, target, output\n",
        "\n",
        "        test_loss /= len(test_data_loader.dataset)\n",
        "        test_acc = correct / len(test_data_loader.dataset)\n",
        "        print('\\nAfter epoch {} - Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            epoch, test_loss, correct, len(test_data_loader.dataset),\n",
        "            100. * correct / len(test_data_loader.dataset)))\n",
        "\n",
        "        return  test_loss, test_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlmHNV6o0Djy"
      },
      "source": [
        "# Jigsaw as pretext task training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "noZzi5Bw0Djy",
        "outputId": "f4d23acd-5990-4538-85ab-946b502b1c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaders done\n",
            "torch.Size([512, 9, 3, 64, 64])\n",
            "torch.Size([512])\n",
            "Model ready\n",
            "Started training\n",
            "Epoch no 0 #######################\n",
            "\n",
            "After epoch 0 - Test set: Average loss: 1.8685, Accuracy: 7408/12600 (59%)\n",
            "\n",
            "\n",
            "After epoch 0 - Train set: Average loss: 4.6555, Accuracy: 21286/113350 (19%)\n",
            "\n",
            "Train loss 4.655525078644624 \n",
            " Val loss 1.8685493880983384 \n",
            " Train Acc 0.1877900308778121 \n",
            " Val Acc 0.587936507936508\n",
            "Epoch no 1 #######################\n",
            "\n",
            "After epoch 1 - Test set: Average loss: 1.7532, Accuracy: 7388/12600 (59%)\n",
            "\n",
            "\n",
            "After epoch 1 - Train set: Average loss: 1.5258, Accuracy: 74424/113350 (66%)\n",
            "\n",
            "Train loss 1.5257800497987248 \n",
            " Val loss 1.753203125 \n",
            " Train Acc 0.6565857962064402 \n",
            " Val Acc 0.5863492063492064\n",
            "Epoch no 2 #######################\n",
            "\n",
            "After epoch 2 - Test set: Average loss: 1.2309, Accuracy: 9039/12600 (72%)\n",
            "\n",
            "\n",
            "After epoch 2 - Train set: Average loss: 0.8603, Accuracy: 89673/113350 (79%)\n",
            "\n",
            "Train loss 0.8603325700974679 \n",
            " Val loss 1.2309095982142857 \n",
            " Train Acc 0.7911160123511248 \n",
            " Val Acc 0.7173809523809523\n",
            "Epoch no 3 #######################\n",
            "\n",
            "After epoch 3 - Test set: Average loss: 2.1253, Accuracy: 6733/12600 (53%)\n",
            "\n",
            "\n",
            "After epoch 3 - Train set: Average loss: 0.5403, Accuracy: 97729/113350 (86%)\n",
            "\n",
            "Train loss 0.5403277797473444 \n",
            " Val loss 2.1252640206473212 \n",
            " Train Acc 0.8621879135421262 \n",
            " Val Acc 0.5343650793650794\n",
            "Epoch no 4 #######################\n",
            "\n",
            "After epoch 4 - Test set: Average loss: 2.3649, Accuracy: 6212/12600 (49%)\n",
            "\n",
            "\n",
            "After epoch 4 - Train set: Average loss: 0.4024, Accuracy: 101607/113350 (90%)\n",
            "\n",
            "Train loss 0.40237028997492147 \n",
            " Val loss 2.3649147154792907 \n",
            " Train Acc 0.8964005293339214 \n",
            " Val Acc 0.493015873015873\n",
            "Epoch no 5 #######################\n",
            "\n",
            "After epoch 5 - Test set: Average loss: 1.6355, Accuracy: 8218/12600 (65%)\n",
            "\n",
            "\n",
            "After epoch 5 - Train set: Average loss: 0.3282, Accuracy: 103559/113350 (91%)\n",
            "\n",
            "Train loss 0.32817623905233434 \n",
            " Val loss 1.6355499219137524 \n",
            " Train Acc 0.9136215262461402 \n",
            " Val Acc 0.6522222222222223\n",
            "Epoch no 6 #######################\n",
            "\n",
            "After epoch 6 - Test set: Average loss: 0.1963, Accuracy: 11986/12600 (95%)\n",
            "\n",
            "\n",
            "After epoch 6 - Train set: Average loss: 0.1772, Accuracy: 108042/113350 (95%)\n",
            "\n",
            "Train loss 0.17722001366384393 \n",
            " Val loss 0.19629043942406063 \n",
            " Train Acc 0.9531715924128804 \n",
            " Val Acc 0.9512698412698413\n",
            "Epoch no 7 #######################\n",
            "\n",
            "After epoch 7 - Test set: Average loss: 0.2107, Accuracy: 11926/12600 (95%)\n",
            "\n",
            "\n",
            "After epoch 7 - Train set: Average loss: 0.1549, Accuracy: 108677/113350 (96%)\n",
            "\n",
            "Train loss 0.15488896247100187 \n",
            " Val loss 0.2107098530966138 \n",
            " Train Acc 0.9587737097485663 \n",
            " Val Acc 0.9465079365079365\n",
            "Epoch no 8 #######################\n",
            "\n",
            "After epoch 8 - Test set: Average loss: 0.1906, Accuracy: 12032/12600 (95%)\n",
            "\n",
            "\n",
            "After epoch 8 - Train set: Average loss: 0.1467, Accuracy: 108965/113350 (96%)\n",
            "\n",
            "Train loss 0.14668931046853195 \n",
            " Val loss 0.19058074830070373 \n",
            " Train Acc 0.9613145125716807 \n",
            " Val Acc 0.954920634920635\n",
            "Epoch no 9 #######################\n",
            "\n",
            "After epoch 9 - Test set: Average loss: 0.1752, Accuracy: 12054/12600 (96%)\n",
            "\n",
            "\n",
            "After epoch 9 - Train set: Average loss: 0.1381, Accuracy: 109155/113350 (96%)\n",
            "\n",
            "Train loss 0.13808396854647645 \n",
            " Val loss 0.17524094627017067 \n",
            " Train Acc 0.962990736656374 \n",
            " Val Acc 0.9566666666666667\n",
            "Epoch no 10 #######################\n",
            "\n",
            "After epoch 10 - Test set: Average loss: 0.2145, Accuracy: 11933/12600 (95%)\n",
            "\n",
            "\n",
            "After epoch 10 - Train set: Average loss: 0.1348, Accuracy: 109241/113350 (96%)\n",
            "\n",
            "Train loss 0.13475405003640567 \n",
            " Val loss 0.21454453544011193 \n",
            " Train Acc 0.9637494486104985 \n",
            " Val Acc 0.947063492063492\n",
            "Epoch no 11 #######################\n",
            "\n",
            "After epoch 11 - Test set: Average loss: 0.1855, Accuracy: 12032/12600 (95%)\n",
            "\n",
            "\n",
            "After epoch 11 - Train set: Average loss: 0.1297, Accuracy: 109394/113350 (97%)\n",
            "\n",
            "Train loss 0.1296699605546556 \n",
            " Val loss 0.18546060652959914 \n",
            " Train Acc 0.9650992501102779 \n",
            " Val Acc 0.954920634920635\n",
            "Epoch no 12 #######################\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1389656056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_no\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch no {} #######################\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         train_loss, train_acc, val_loss, val_acc = model_train_test_obj.train(\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_max_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-667187504.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mcnt_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#for jigsaw ssl task\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import ConcatDataset\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    Cexperiment_name = 'e1_js'\n",
        "    Cdataset_config = 'js_d1'\n",
        "    Cweight_decay = 5e-4 # 5e-4\n",
        "    Clr = 1e-2 # originally 1e-2\n",
        "    Cepochs = 11\n",
        "    Cbatch_size = 512\n",
        "\n",
        "    dataset_path = \"/content/drive/MyDrive/Final Project/extraimages2/extraimages\"\n",
        "\n",
        "    # Data files which will get referred\n",
        "    permuts_file_path = 'selected_permuts.npy'\n",
        "\n",
        "    # Set device to use to gpu if available and declare model_file_path\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #par_weights_dir = 'weights/'\n",
        "    model_file_path = 'resnet_jigsaw_solver_{}_trained.pt'.format(Cexperiment_name)\n",
        "\n",
        "    all_file_paths = get_paths(dataset_path)\n",
        "\n",
        "    # Get validation files separate\n",
        "    train_file_paths, val_file_paths = train_test_split(all_file_paths, test_size=0.1, shuffle=True, random_state=3)\n",
        "\n",
        "    # Compute channel means\n",
        "    channel_means = np.array([124.09, 127.67, 110.50]) / 256.0\n",
        "\n",
        "    # Define data transforms\n",
        "    data_transform = transforms.Compose([\n",
        "        transforms.RandomCrop((64, 64)),\n",
        "        transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Define data loaders\n",
        "    batch_size = Cbatch_size\n",
        "\n",
        "    if Cdataset_config == 'js_d1':\n",
        "        train_data_loader = DataLoader(\n",
        "            ConcatDataset(\n",
        "                [GetJigsawPuzzleDataset(train_file_paths, permuts_file_path,\n",
        "                                        range_permut_indices=[st_perm_ind, st_perm_ind+9], transform=data_transform)\n",
        "                 for st_perm_ind in range(0, 100, 10)\n",
        "                ]\n",
        "            ),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=8\n",
        "        )\n",
        "        val_data_loader = DataLoader(\n",
        "            ConcatDataset(\n",
        "                [GetJigsawPuzzleDataset(val_file_paths, permuts_file_path,\n",
        "                                        range_permut_indices=[st_perm_ind, st_perm_ind + 9], transform=data_transform)\n",
        "                 for st_perm_ind in range(0, 100, 10)\n",
        "                 ]\n",
        "            ),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=8\n",
        "        )\n",
        "    else:\n",
        "        train_data_loader = DataLoader(\n",
        "            GetJigsawPuzzleDataset(train_file_paths, permuts_file_path, transform=data_transform),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=8\n",
        "        )\n",
        "        val_data_loader = DataLoader(\n",
        "            GetJigsawPuzzleDataset(val_file_paths, permuts_file_path, transform=data_transform),\n",
        "            batch_size=batch_size, shuffle=True, num_workers=8\n",
        "        )\n",
        "    print(\"Loaders done\")\n",
        "    # Print sample batches that would be returned by the train_data_loader\n",
        "    dataiter = iter(train_data_loader)\n",
        "    X, y = dataiter.__next__()\n",
        "    print (X.size())\n",
        "    print (y.size())\n",
        "\n",
        "    # Train required model defined above on CUB200 data\n",
        "    num_outputs = 100 * 4 #200\n",
        "    epochs = Cepochs\n",
        "    lr = Clr\n",
        "    weight_decay_const = Cweight_decay\n",
        "\n",
        "    # If using Resnet18\n",
        "    model_to_train = resnet18(num_classes=num_outputs, siamese_deg=9)\n",
        "    print('Model ready')\n",
        "    # Set device on which training is done. Plus optimizer to use.\n",
        "    model_to_train.to(device)\n",
        "    optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, min_lr=1e-5)\n",
        "\n",
        "    # Start training\n",
        "    print('Started training')\n",
        "    model_train_test_obj = JigsawModelTrainTest(model_to_train, device, model_file_path)\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    for epoch_no in range(epochs):\n",
        "        print(\"Epoch no {} #######################\".format(epoch_no))\n",
        "        train_loss, train_acc, val_loss, val_acc = model_train_test_obj.train(\n",
        "            optimizer, epoch_no, params_max_norm=4,\n",
        "            train_data_loader = train_data_loader, val_data_loader = val_data_loader\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        print(\"Train loss {} \\n Val loss {} \\n Train Acc {} \\n Val Acc {}\".format(train_loss,val_loss,train_acc,val_acc))\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    observations_df = pd.DataFrame()\n",
        "    observations_df['epoch count'] = [i for i in range(1, Cepochs + 1)]\n",
        "    observations_df['train loss'] = train_losses\n",
        "    observations_df['val loss'] = val_losses\n",
        "    observations_df['train acc'] = train_accs\n",
        "    observations_df['val acc'] = val_accs\n",
        "    observations_file_path = Cexperiment_name + '_observations.csv'\n",
        "    observations_df.to_csv(observations_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvg2Vwjb0Djz"
      },
      "source": [
        "# Plot loss and accuracy curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "w--w8SfV0Djz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "75defb3a-7743-4bf3-d3fb-8dc7e4655307"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.title('Loss plots')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "#plt.show()\n",
        "plt.savefig('loss.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PamM29zi0Djz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "68055ae5-1681-454e-81f6-09ea2417a9a4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_accs)\n",
        "plt.plot(val_accs)\n",
        "plt.title('Accuracy plots')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "#plt.show()\n",
        "plt.savefig('accuracy.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cGivjmg0Djz"
      },
      "source": [
        "# Downstream classification training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U77ExY9s0Djz"
      },
      "outputs": [],
      "source": [
        "\n",
        "#for downstream classification\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from torchvision import transforms, utils, models\n",
        "torch.manual_seed(3)\n",
        "\n",
        "\n",
        "def visualize(sample_data_loader):\n",
        "\n",
        "    def imshow(img, mean=0.0, std=1.0):\n",
        "        \"\"\"\n",
        "        Parameters passed:\n",
        "        img: Image to display\n",
        "        mean: Mean that was subtracted while normalizing the images\n",
        "        std: Standard deviation that was used for division while normalizing the image\n",
        "        \"\"\"\n",
        "        img = img * std + mean  # unnormalize\n",
        "        npimg = img.numpy()\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "        plt.show()\n",
        "\n",
        "    dataiter = iter(sample_data_loader)\n",
        "    images, labels = dataiter.__next__()\n",
        "    imshow(utils.make_grid(images))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "    Cbatch_size = 32\n",
        "    Cepochs = 20\n",
        "    Coptim = 'adam'\n",
        "    Clr = 1e-4\n",
        "    Cweight_decay = 5e-4\n",
        "    Cjigsaw_task_weights = 'resnet_jigsaw_solver_e1_js_trained.pt'\n",
        "    Cmodel_file_name = 'resnet_trained_for_classification.pt'\n",
        "    Cexperiment_name = 'e1_last_b'\n",
        "    Ctrain_imagenet_based = False\n",
        "    Ctrain_ssl_block_4_ft = True\n",
        "    Ctrain_ssl_block_3_ft = False\n",
        "    Ctrain_ssl_full_ft = False\n",
        "    Ctrain_wo_ssl = False\n",
        "\n",
        "    # Set device to use to gpu if available and declare model_file_path\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #par_weights_dir = 'weights/'\n",
        "    jigsaw_pre_trained_weights_path =  Cjigsaw_task_weights\n",
        "\n",
        "    # Data loading and data generators set up\n",
        "    train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels = \\\n",
        "        get_train_test_file_paths_n_labels()\n",
        "\n",
        "    # Get validation files and validation labels separate\n",
        "    train_image_ids, val_image_ids, train_file_paths, val_file_paths, train_labels, val_labels = \\\n",
        "        split_train_into_train_val(train_image_ids, train_file_paths, train_labels, test_size=0.1)\n",
        "\n",
        "    # Compute channel means\n",
        "    channel_means = np.array([124.09, 127.67, 110.50]) / 256.0\n",
        "\n",
        "    # Define data loaders\n",
        "    batch_size = Cbatch_size\n",
        "    train_data_loader = DataLoader(\n",
        "        ConcatDataset(\n",
        "            [GetDataset(train_file_paths, train_labels, def_data_transform),\n",
        "             GetDataset(train_file_paths, train_labels, hflip_data_transform),\n",
        "             GetDataset(train_file_paths, train_labels, darkness_jitter_transform),\n",
        "             GetDataset(train_file_paths, train_labels, lightness_jitter_transform),\n",
        "             GetDataset(train_file_paths, train_labels, rotations_transform),\n",
        "             GetDataset(train_file_paths, train_labels, all_in_transform)]\n",
        "        ),\n",
        "        batch_size = batch_size, shuffle = True, num_workers = 8\n",
        "    )\n",
        "    val_data_gen = GetDataset(val_file_paths, val_labels, def_data_transform)\n",
        "    val_data_loader = DataLoader(\n",
        "        val_data_gen, batch_size=batch_size, shuffle=True, num_workers=8\n",
        "    )\n",
        "    test_data_gen = GetDataset(test_file_paths, test_labels, def_data_transform)\n",
        "    test_data_loader = DataLoader(\n",
        "        test_data_gen, batch_size=batch_size, shuffle=True, num_workers=8\n",
        "    )\n",
        "\n",
        "    # Visualize a batch of images\n",
        "    # visualize(train_data_loader)\n",
        "\n",
        "    # Train required model defined above on CUB200 data\n",
        "    num_classes = 5\n",
        "    epochs = Cepochs\n",
        "    lr = Clr\n",
        "    weight_decay_const = Cweight_decay\n",
        "\n",
        "    if Ctrain_imagenet_based:\n",
        "        model_to_train = models.resnet18(pretrained=True)\n",
        "        model_to_train.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
        "\n",
        "        model_to_train.fc = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 5),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "        model_file_path = 'resnet_imagenet_based.pt'\n",
        "\n",
        "    elif Ctrain_wo_ssl:\n",
        "        model_to_train = resnet18(num_classes=num_classes, siamese_deg=None)\n",
        "        model_file_path = 'resnet_trained_from_scratch.pt'\n",
        "\n",
        "    else:\n",
        "        model_to_train = resnet18(num_classes=num_classes, siamese_deg=None)\n",
        "        model_to_train.fc = nn.Linear(2048 * 9, 100)  # 2048 is the last resnet layer output length which gets\n",
        "        # multiplied with degree of siamese net, which for jigsaw puzzle solving was 9\n",
        "\n",
        "        # Load state dict for pre trained model weights\n",
        "        model_to_train.load_state_dict(torch.load(jigsaw_pre_trained_weights_path))\n",
        "\n",
        "        # Redefine the last linear layer\n",
        "        model_to_train.fc = nn.Linear(2048, 5)\n",
        "\n",
        "        print('Model loaded successfully')\n",
        "\n",
        "        if Ctrain_ssl_block_4_ft:\n",
        "            model_file_path = 'resnet_trained_ssl_{}_last_a_ft.pt'.format(Cexperiment_name)\n",
        "            for name, param in model_to_train.named_parameters():\n",
        "                if name[:6] == 'layer4' or name in ['fc.0.weight', 'fc.0.bias']:\n",
        "                    param.requires_grad = True\n",
        "                else:\n",
        "                    param.requires_grad = False\n",
        "        elif Ctrain_ssl_block_3_ft:\n",
        "            model_file_path = 'resnet_trained_ssl_{}_last_b_ft.pt'.format(Cexperiment_name)\n",
        "            for name, param in model_to_train.named_parameters():\n",
        "                if name[:6] == 'layer4' or name[:6] == 'layer3' or name in ['fc.0.weight', 'fc.0.bias']:\n",
        "                    param.requires_grad = True\n",
        "                else:\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        else:\n",
        "            model_to_train.fc = nn.Linear(2048, 5)\n",
        "            model_file_path = 'resnet_trained_ssl_{}_full_ft.pt'.format(Cexperiment_name)\n",
        "\n",
        "\n",
        "    # Set device on which training is done. Plus optimizer to use.\n",
        "    model_to_train.to(device)\n",
        "    sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
        "    adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
        "\n",
        "    if Coptim == 'sgd':\n",
        "        optimizer = sgd_optimizer\n",
        "    else:\n",
        "        optimizer = adam_optimizer\n",
        "\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)\n",
        "\n",
        "    # Start training\n",
        "    model_train_test_obj = ModelTrainTest(model_to_train, device, model_file_path)\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    print('Training started')\n",
        "    for epoch_no in range(epochs):\n",
        "        train_loss, train_acc, val_loss, val_acc = model_train_test_obj.train(\n",
        "            optimizer, epoch_no, params_max_norm=4,\n",
        "            train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    observations_df = pd.DataFrame()\n",
        "    observations_df['epoch count'] = [i for i in range(1, Cepochs + 1)]\n",
        "    observations_df['train loss'] = train_losses\n",
        "    observations_df['val loss'] = val_losses\n",
        "    observations_df['train acc'] = train_accs\n",
        "    observations_df['val acc'] = val_accs\n",
        "    observations_file_path = Cexperiment_name + '_observations.csv'\n",
        "    observations_df.to_csv(observations_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W23_wiUw0Dj0"
      },
      "source": [
        "# Plot loss and accuracy curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIGCtep_0Dj0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.title('Loss plots')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "#plt.show()\n",
        "plt.savefig('e1_last_b_classification_loss.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44iHEyNR0Dj0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_accs)\n",
        "plt.plot(val_accs)\n",
        "plt.title('Accuracy plots')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "#plt.show()\n",
        "plt.savefig('e1_last_b_classification_acc.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTK-UlOv0Dj0"
      },
      "source": [
        "# Show confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E_RCccA0Dj0"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    pil_img = Image.open(path)\n",
        "    if pil_img.mode == \"L\":\n",
        "        return None\n",
        "    else:\n",
        "        return pil_img\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "    Cmodel_name = 'resnet_trained_ssl_e1_last_b_last_b_ft.pt'\n",
        "    Ctest_compact_bilinear = True\n",
        "    Ctest_imagenet_based = False\n",
        "    Ctest_on = 'test'\n",
        "\n",
        "    # Set device to use to gpu if available and declare model_file_path\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #par_weights_dir = 'weights/'\n",
        "    model_file_path = Cmodel_name\n",
        "\n",
        "    # Data loading and data generators set up\n",
        "    train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels = \\\n",
        "        get_train_test_file_paths_n_labels()\n",
        "\n",
        "    train_image_ids, val_image_ids, train_file_paths, val_file_paths, train_labels, val_labels = \\\n",
        "        split_train_into_train_val(train_image_ids, train_file_paths, train_labels, test_size=0.1)\n",
        "\n",
        "    if Ctest_imagenet_based:\n",
        "        model_to_train = models.resnet18(pretrained=True)\n",
        "        model_to_train.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
        "        model_to_train.fc = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 5),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "    else:\n",
        "        model_to_train = resnet18(num_classes=5, siamese_deg=None)\n",
        "\n",
        "    # Check if saved model exists, and load if it does.\n",
        "    if os.path.exists(model_file_path):\n",
        "        model_to_train.load_state_dict(torch.load(model_file_path))\n",
        "    model_to_train.to(device)\n",
        "\n",
        "    # Setup on which set evaluation is to be carried out\n",
        "    if Ctest_on == 'train':\n",
        "        eval_file_paths, eval_labels = train_file_paths, train_labels\n",
        "    elif Ctest_on == 'val':\n",
        "        eval_file_paths, eval_labels = val_file_paths, val_labels\n",
        "    else:\n",
        "        eval_file_paths, eval_labels = test_file_paths, test_labels\n",
        "\n",
        "    # Start evaluation\n",
        "    model_to_train.eval()\n",
        "    correct = 0\n",
        "    preds = []\n",
        "    for f, label in zip(eval_file_paths, eval_labels):\n",
        "        pil_img = pil_loader(f)\n",
        "        if pil_img is None:\n",
        "            preds.append(0)\n",
        "            continue\n",
        "        data = def_data_transform(pil_img)\n",
        "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
        "        data = Variable(data, volatile=True).to(device)\n",
        "        output = model_to_train(data)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "\n",
        "        x = pred.data #prediction\n",
        "        preds.append(x)\n",
        "\n",
        "        if x == label:\n",
        "            correct += 1\n",
        "\n",
        "    print (correct, len(eval_file_paths), correct * 100 / len(eval_file_paths))\n",
        "    preds = np.array(preds).astype(np.float64)\n",
        "    conf_mat = np.array(confusion_matrix(preds, eval_labels))\n",
        "    conf_df = pd.DataFrame(conf_mat)\n",
        "    conf_df.columns = np.arange(0,5)\n",
        "    conf_df.to_csv('confusion_matrix.csv')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}